# Spatial Statistics: Gaussian Process
## Definition and properties
The Gaussian process can be seen as an extension of multivariate Gaussian distribution from finite-dimensional case to infinite-dimensional case. It is a stochastic process or a random field (a collection of random variables indexed by time or space) such that the joint distribution of every finite collection of those random variables is Gaussian.

**Definition** (Gaussian process). Given a probability space $(\Omega,\mathcal{F},\mathbb{P})$ and an index set $\mathcal{D},$ a random field $\left\lbrace Z(s)\in L_2(\Omega):\ s\in\mathcal{D}\right\rbrace$ is called a Gaussian process, if for every finite set of indices $\lbrace s_1,\cdots,s_n\rbrace \subset \mathcal{D},$ the joint distribution of random variables $Z(s_1),\cdots,Z(s_n)$ is a multivariate Gaussian distribution.

The mean and covariance function of a Gaussian process is defined by
<p>
  $$\mu(s):=\mathbb{E}[Z(s)],\ k(s,t):=\mathrm{Cov}\left\lbrace Z(s),z(t)\right\rbrace,$$
</p>

and they completely determine a Gaussian process $\mathcal{GP}\left(\mu(\cdot),k(\cdot,\cdot)\right).$

**Property of Gaussian processes** 
+ A Gaussian process can be seen as a distribution over real-valued functions $\lbrace f:\mathcal{D}\to\mathbb{R}\rbrace.$ Suppose that $f\sim\mathcal{GP}\left(\mu(\cdot),k(\cdot,\cdot)\right),$ then $\forall n\in\mathbb{N}^*,\ x_1,\cdots,x_n\in\mathcal{D},$ the joint distribution of $f(x_1),\cdots,f(x_n)$ is given by
  
<p>$$\begin{pmatrix} f(x_1) \\ \vdots\\ f(x_n) \end{pmatrix} \sim N\left\lbrace
  \begin{pmatrix} \mu(x_1) \\ \vdots\\ \mu(x_n) \end{pmatrix},
  \begin{pmatrix} k(x_1,x_1) & \cdots & k(x_1,x_n) \\ \vdots & \ddots & \vdots\\ k(x_n, x_1) & \cdots & k(x_n,x_n) \end{pmatrix}\right\rbrace.$$
  </p>

+ The covariance function $k$ is a kernel which is symmetric and positive definite. A wide range of kernels can be selected as the covariance function, such as Gaussian RBF and MatÃ©rn kernels.

+ If a Gaussian process $Z(\cdot)$ is (weakly) stationary, i.e. it has constant mean $\mu$, and the covariance $k(s,t)$ depends on only the difference between locations $s-t$, then $\forall n\in\mathbb{N}^*,\ s_1,\cdots,s_n\in\mathcal{D},$ and $\forall h$ such that $s_1+h,\cdots,s_n+h\in\mathcal{D}$, then
  
  $$\left(Z(s_1),\cdots,Z(s_n)\right) \overset{d}{=} \left(Z(s_1 + h),\cdots,Z(s_n + h)\right).$$
  
  In a nutshell, weak stationarity implies strict stationarity in Gaussian processes.

Some Gaussian processes with zero mean and different covariance kernels are visualized below.
  
![avatar](https://github.com/JurrivhLeon/JurrivhLeon.github.io/raw/main/figs/rbf.png)
![avatar](https://github.com/JurrivhLeon/JurrivhLeon.github.io/raw/main/figs/lap.png)
  
## Hierarchical model for geostatistical process

In practice, we often apply a hierarchical model to simulate spatial or geostatistical data. A hierarchical model has two components: a process model, which sets up some latent variable with covariance structure, and a data model, which generates observations from latent variables with measurement error.

**Process Model.** Suppose that $\mathbf{m}(\cdot)\in\mathbb{R}^p$ is a column vector of covariates related to the mean function. Given regression coefficients $\beta\in\mathbb{R}^p$ and kernel $k(\cdot,\cdot),$ let

$$Z(\cdot)\sim\mathcal{GP}\left(\mathbf{m}(\cdot)^\top\beta, k(\cdot,\cdot)\right).$$

**Data Model.** Conditioning on process $Z(\cdot),$ the observation at location $s\in\mathcal{D}$ is

$$Y(s)|Z(\cdot) \sim N(Z(s), \sigma^2),\ \sigma^2>0;$$

Equivalently, for $n$ locations $s_1,\cdots,s_n,$

$$Y(s_i) = Z(s_i) + e_i,\ e_i \overset{\textrm{i.i.d.}}{\sim} N(0,\sigma^2),\ i=1,\cdots,n. $$

Hence we can use an error process $\epsilon(\cdot)$ to model our observational data:

<p>
  $$Y(s_i) = \mathbf{m}(s_i)^\top\beta + \epsilon(s_i),\ \begin{pmatrix}\epsilon(s_1)\\ \vdots \\ \epsilon(s_n)\end{pmatrix}\sim N(0,\mathbf{K} + \sigma^2\mathbf{I}_n),$$
</p>

where $\mathbf{K} = \lbrace k(s_i,s_j)\rbrace_{i,j=1}^n.$
