# Structural Causal Models
## Definition
**Definition 1** (Structural causal model; Pearl, 2009). A structural causal model (SCM) is a 4-tuple $\mathcal{M}=\langle U,V,\mathcal{F},\mathbb{P}\rangle$ where
+ $U$ is a set of exogenous variables that are determined by factors outside the model.
+ $V = \lbrace V_1, \cdots , V_n\rbrace$ is a set of endogenous variables that are determined by factors in the model.
+ $\mathcal{F}$ is a set of functions $\lbrace f_1, \cdots , f_n\rbrace$ such that each $f_i$ is a mapping from  (the respective domains of) $U_i\cup Pa_i$ to $V_i,$ where $U_i\subseteq U$ is some subset of $U$ whose elements are related to the variation of $V_i,$ $Pa_i\subseteq V\backslash V_i$ includes the parents of $V_i$ in the underlying causal DAG, and entire set of $F$ forms a mapping from $U$ to $V.$ In other words, $f_i$ assigns a value to the corresponding $V_i\in V,\ v_i\gets f(u_i,pa_i).$
+ $\mathbb{P}$ is a probability measure defined over the domain of $U,$ which creates variation in the endogenous variables $V$.

Every SCM $\mathcal{M}$ defines a directed acyclic graph (DAG) $\mathcal{G}(\mathcal{M}) = (V,E)$ (denoted as $\mathcal{G}$ for simplicity). Node in $\mathcal{G}$ correspond to endogenous variables in $V,$ and directed edges $E$ emit from the set of parent nodes $Pa_i$ towards $V_i.$ This causal DAG specifies the causal mechanism according to which the data are generated.

**Remark.** In a fully specfied SCM, any counterfactual quantity can be immediately constructed explicitly by variables from the underlying causal mechanism. These quantities are taken as axiomatic primitves in the potential outcome framework.

**Definition 2** (Intervention). Interventions in structural causal models are carried out by removing individual functions in $F$ from the model and fixing their left-hand side variables at some constant value. Mathematically, such an action is denoted by the operator $\mathrm{do}(\cdot).$

**Analytical Example.** Consider the directed acyclic graphs representing structural causal models. 

<div align=center>
   <img src='https://github.com/JurrivhLeon/JurrivhLeon.github.io/raw/main/figs/causalDAG1.png' width='648.9'/>
</div>

The structural causal model $\mathcal{M}$ underlying in (a) can be formulated as
<p>
  $$\begin{align}
  Z &\gets f_Z(U_Z)\\
  X &\gets f_X(Z, U_X)\\
  Y &\gets f_Y(X,Z,U_Y).
  \end{align} \tag{1}$$
</p>

Naturally, we can explicitly write the counterfactual $Y_x$ as

$$Y_x \gets f_Y(x,Z,U_Y), \tag{2}$$

which would specify the value of $Y$ if $X$ had been $x$.

Now if we intervene on $X$ so that $X=x_0,$ then we can get another SCM $\mathcal{M}_{x_0}$ underlying in (b):
<p>
  $$\begin{align}
  Z &\gets f_Z(U_Z)\\
  X &\gets x_0\\
  Y &\gets f_Y(X,Z,U_Y).
  \end{align} \tag{3}$$
</p>

Furthermore, the post-intervention distribution of Y can also be denoted in counterfactual notation as

$$\mathbb{P}(Y\in A\ |\ \mathrm{do}(X=x_0)) = \mathbb{P}(Y_{x_0}\in A), \tag{4}$$

where $A$ is any measurable set in the domain of $Y.$

Given interventions $\mathrm{do}(X=x_0)$ (control) and $\mathrm{do}(X=x_1)$ (treatment), any difference between two probability distributions associated with $\mathcal{M}_ {x_0}$ and $\mathcal{M}_ {x_1}$ captures the variation of $Y$ resulted by the causal effect of $\Delta x = x_1-x_0.$

**Definition 3** (Observational identifiability). Let $Q(\mathcal{M})$ be any computable quantity of a model $\mathcal{M}$. Then $Q$ is identifiable from distribution $P(v)$ compatible with a causal DAG $\mathcal{G}$, if for any two (fully specified) model $\mathcal{M}_0$ and $\mathcal{M}_1$ that satisfy the assumptions of $\mathcal{G}$, we have

$$P_0(v) = P_1(v)\ \Rightarrow\ Q(\mathcal{M}_0)=Q(\mathcal{M}_1). \tag{5}$$

This definition states that for any two unobserved SCMs $\mathcal{M}_0$ and $\mathcal{M}_1$ with their induced distributions $P_0(v)$ and $P_1(v)$ coincided, then they provide the same answers to query $Q$. 

**Remark.** If $Q$ is identifiable, then it depends only on $P(v)$ and the assumptions in $\mathcal{G}$, and furthermore, can be uniquely expressed in terms of the observed distribution.

## Confounding Bias
**Notations.** Given a causal DAG $\mathcal{G}$ includes node set $X$. We use $\mathcal{G}_ {\underline{X}}$ to denote the graph obtained by removing all edges emitted by $X$ in $\mathcal{G}.$ We use $\mathcal{G}_ {\overline{X}}$ to denote the graph obtained by removing all edges pointed towards $X$ in $\mathcal{G}.$

### Backdoor criterion
**Definition 4** (Admissible Sets). Given a causal DAG $\mathcal{G}$ with treatment variable set $X$ and outcome variable set $Y$ assigned, a set $X$ is called backdoor-admissible if it blocks every path between $X$ and $Y$ in graph $\mathcal{G}_{\underline{X}}.$

The following theorem states that the causal effect of $X$ on $Y$ can be estimated by adjustment if a backdoor-admissible set exists.

**Theorem 1** (Backdoor adjustment criterion). If a set of variables $Z$ satisfies the backdoor criterion relative to $(X,Y),$ then the causal effect of $X$ on $Y$ can be identified from observational data by adjustment formula:

$$\mathbb{P}(Y\in A\ |\ \mathrm{do}(X=x)) = \int \mathbb{P}(Y\in A\ |\ X=x,Z=z)\mathrm{d}\mu(z),\tag{6}$$

here $\mu(z)$ is a probability measure over the domain of $Z$ induced by $\mathcal{G}$, In discrete case, we can write (6) as 

$$\mathbb{P}(Y\in A\ |\ \mathrm{do}(X=x)) = \sum_z \mathbb{P}(Y\in A\ |\ X=x,Z=z)\cdot\mathbb{P}(Z=z).\tag{7}$$

**Remark.** This conclusion has a counterfactual interpretation: For all $x$ in the domain of $X,$ the counterfactual $Y_x$ is conditionally independent of $X$ given $Z,$ i.e. $Y_x\perp X\ \vert\ Z.$

### Frontdoor criterion
**Definition 5** (Conditional frontdoor criterion). In causal DAG $\mathcal{G}$ set of variables $M$ is said to satisfy the conditional frontdoor criterion relative to a triplet $(X, Y, W)$ if: 
+ $M$ intercepts all directed paths from $X$ to $Y$;
+ There is no unblocked backdoor path from $X$ to $M$ (paths in $\mathcal{G}_{\underline{X}}$) given $W$;
+ All the backdoor paths from $M$ to $Y$ are blocked by $\lbrace X, W\rbrace$.

An example is given below.

<div align=center>
   <img src='https://github.com/JurrivhLeon/JurrivhLeon.github.io/raw/main/figs/causalDAG2.png' width='320'/>
</div>

**Theorem 2** (Conditional frontdoor adjustment). If a set $M$ satisfies the conditional frontdoor criterion related to $(X,Y,W),$ then the causal effect of $X$ on $Y$ can be indentified by the frontdoor formula

$$\begin{align}\mathbb{P}(Y\in A\ |\ \mathrm{do}(X=x)) &= \sum_w\sum_m \mathbb{P}(M=m\ |\ X=x, w)\mathbb{P}(W=w)\\
&\times \sum_{x'}\mathbb{P}(Y\in A\ |\ X=x',m,w)\mathbb{P}(X=x'|w)\end{align}\tag{8}$$

**Remark.** The frontdoor adjustment can be seen as a sequential application of the backdoor criterion.

### Symbolic engine: do-calculus
Let $X, Y, $Z$ and $W$ be arbitrary disjoint sets of nodes in $\mathcal{G}. We use $p$ to stand for probabilisty distribution. Do-calculus states the follwoing three rules:
+ (Insertion/deletion of observations)
  <p>$$p(y\vert \mathrm{do}(x), z, w) = p(y\vert\mathrm{do}(x),z)\ \ \ \textsf{if}\ (Y\perp Z\vert X,W)_{\mathcal{G}_{\overline{X}}};$$</p>
+ (Action/observation exchange)
  <p>$$p(y\vert \mathrm{do}(x),\mathrm{do}(z), w) = p(y\vert\mathrm{do}(x),z, w)\ \ \ \textsf{if}\ (Y\perp Z\vert X,W)_{\mathcal{G}_{\overline{X}\underline{Z}}};$$</p>
+ (Insertion/deletion of actions)
  <p>$$p(y\vert \mathrm{do}(x),\mathrm{do}(z), w) = p(y\vert\mathrm{do}(x), w)\ \ \ \textsf{if}\ (Y\perp Z\vert X,W)_{\mathcal{G}_{\overline{XZ(W)}}};$$</p>

