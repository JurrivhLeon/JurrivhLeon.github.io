# Concentration: Self-Normalized Tail Inequality for Vector-Valued Martingales
**Setting.** We fix our discussion on a probability space $(\Omega,\mathcal{F},\mathbb{P}).$ If a stochatic process $\lbrace Y_t\rbrace_ {t=1}^\infty$ is a martingale adapted to the filtration $\lbrace\mathcal{F}_ t\rbrace_ {t=0}^\infty,$ then for any $t,$
<p>
  $$\begin{align*}
  &\mathbb{E}\vert Y_t\vert < \infty,\\
  &\mathbb{E}[Y_t|\mathcal{F}_{t-1}] = Y_{t-1}\ \mathrm{a.s.}.
  \end{align*}$$
</p>

Now, let $\lbrace\mathcal{F}_ t\rbrace_ {t=0}^\infty$ be a filtration and $\lbrace\eta_ t\rbrace$ a real-valued stochastic process such that $\eta_ t$ is $\mathcal{F}_ t$-measurable. Moreover, let $\lbrace X_t\rbrace_ {t=1}^\infty$ be an $\mathbb{R}^d$-valued stochastic process such that $X_ t$ is $\mathcal{F}_ {t-1}$-measurable.

**Assumption 1** (Conditional sub-Gaussianity) There exists some $\sigma\geq0$ such that for any $t,$ $\eta_ t$ is conditionally $\sigma$-sub-Gaussian, i.e. $\forall\lambda\in\mathbb{R},$
<p>
  $$\mathbb{E}[\exp(\lambda\eta_t)|\mathcal{F}_{t-1}] = \exp\left(\frac{\lambda^2\sigma^2}{2}\right).$$
</p>

## A Supermartingale Statement
**Lemma 1.** For an arbitrary $\lambda\in\mathbb{R}^d$ and $t\geq 0,$ define
<p>$$
  M_t^\lambda = \exp\left(\sum_{s=1}^t \left[\frac{\eta_s\lambda^\top X_s}{\sigma} - \frac{1}{2}(\lambda^\top X_s)^2\right]\right).
  $$</p>

Let $\tau$ be a stopping time with respect to the filtration $\lbrace\mathcal{F}_ t\rbrace_ {t=0}^\infty.$ Then $M_ \tau^\lambda$ is almost surely well-defined and
<p>$$\mathbb{E}[M_\tau^\lambda]\leq 1.$$</p>

**Proof.** We claim that $\lbrace M_t^\lambda\rbrace_ {t=0}^\infty$ is a supermartingale. Let
<p>$$\begin{align*}
  D_t^\lambda = \exp\left(\frac{\eta_t\lambda^\top X_t}{\sigma} - \frac{1}{2}(\lambda^\top X_t)^2\right).
\end{align*}$$</p>

From the sub-Gaussianity of $\eta_t,$ we immediately have
<p>$$\mathbb{E}[D_t^\lambda|\mathcal{F}_{t-1}]\leq 1.$$</p>

Obviously, $D_ t^\lambda$ is $\mathcal{F}_ t$ is measurable, as is $M_ t^\lambda.$ Moreover,
<p>
  $$\begin{align*}
  \mathbb{E}[M_ t^\lambda|\mathcal{F}_{t-1}] &= \mathbb{E}[D_1^\lambda\cdots D_{t-1}^\lambda D_ t^\lambda|\mathcal{F}_{t-1}] \\
  &= D_1^\lambda\cdots D_{t-1}^\lambda \mathbb{E}[D_ t^\lambda|\mathcal{F}_{t-1}] \leq M_{t-1}^\lambda.
  \end{align*}$$
</p>

Hence $\lbrace M_ t^\lambda\rbrace_ {t=0}^\infty$ is a supermartingale with $0\leq\mathbb{E}[M_ t^\lambda\vert\mathcal{F}_ {t-1}]\leq 1.$

By the convergence theorem for nonnegative supermartingales, $M_ \infty^\lambda = \lim_ {t\to\infty}M_ t^\lambda$ is almost surely well-defined. Hence $M_ \tau^\lambda$ is well-defined independently of whether $\tau <\infty$ or not. Furthermore, let $Q_ t^\lambda := M_ {\tau\wedge t}^\lambda$ be a stopped version of $(M_ t^\lambda)_ t.$ By Fatou's Lemma,
<p>$$\begin{align*}
  \mathbb{E}[M_\tau^\lambda] = \mathbb{E}[\liminf_{t\to\infty} Q_t^\lambda] \leq \liminf_{t\to\infty}\mathbb{E}[Q_t^\lambda] \leq 1,
\end{align*}$$</p>

which concludes the proof.

## Self-normalized bound for vector-valued martingales
Based on the properties of $\lbrace\eta_ t\rbrace_ {t=1}^\infty$ and $\lbrace X_ t\rbrace_ {t=1}^\infty,$ we can construct a vector-valued martingale
<p>$$S_t=\sum_{s=1}^t\eta_s X_s$$</p>

with respect to the filtration $\lbrace\mathcal{F}_ t\rbrace_ {t=1}^\infty.$

Assume that $V_ 0$ is a $d\times d$ positive definite matrix. For any $t\geq 0,$ let
<p>$$V_t = V_0 + \sum_{s=1}^t X_sX_s^\top.$$</p>

**Lemma 2.** Let $\tau$ be a stopping time with respect to the filtration $\lbrace\mathcal{F}_ t\rbrace_ {t=0}^\infty.$ Then, for $\delta >0,$ the following inequality holds with probability $1-\delta:$
<p>$$
  \Vert S_\tau\Vert_{V_\tau^{-1}}^2 \leq 2\sigma^2\log\left(\frac{\det(V_\tau)^{1/2}\det(V_0)^{-1/2}}{\delta}\right).
$$</p>

**Proof.** Let $H_t = V_t-V_0 = \sum_{s=1}^t X_sX_s^\top.$ By definition, $M_ t^\lambda$ can be represented as
<p>$$M_t^\lambda = \exp\left(\frac{\lambda^\top S_t}{\sigma} - \frac{1}{2}\Vert\lambda\Vert_{H_t}^2\right).$$</p>

Let $\Lambda\sim N(0,V_ 0^{-1})$ be a Gaussian variable which is independent of other variables. Define
<p>$$M_t=\mathbb{E}[M_t^\Lambda | \mathcal{F}_\infty],$$</p>

where $\mathcal{F}_ \infty = \bigcup_ {t=0}^\infty\mathcal{F}_ t.$ Clearly, $\mathbb{E}[M_ \tau] = \mathbb{E}\left[\mathbb{E}[M_ \tau^\Lambda\vert\Lambda]\right] \leq 1.$

Now we are going to compute $M_t.$ For a $d\times d$ positive definite matrix $P$ let $c(P) = \int \exp\left(-x^\top Px/2\right)\mathrm{d}x = \sqrt{(2\pi)^d/\det(P)},$ then
<p>$$\begin{align*}
  M_t &= \int \exp\left(\frac{\lambda^\top S_t}{\sigma} - \frac{1}{2}\Vert\lambda\Vert_{H_t}^2\right)\phi(\lambda;0,V_0^{-1})\mathrm{d}\lambda\\
  &= \int \exp\left(-\frac{1}{2}\left\Vert\lambda - \sigma^{-1}H_t^{\dagger}S_t\right\Vert_{H_t}^2 + \frac{1}{2}\Vert \sigma^{-1}S_t\Vert_{H_t^{\dagger}}^2\right)\phi(\lambda;0,V_0^{-1})\mathrm{d}\lambda\\
  &= \frac{1}{c(V_0)}\exp\left(\frac{1}{2}\Vert \sigma^{-1}S_t\Vert_{H_t^{\dagger}}^2\right)\int\exp\left(-\frac{1}{2}\left\lbrace\left\Vert\lambda - \sigma^{-1}H_t^{\dagger}S_t\right\Vert_{H_t}^2 + \Vert\lambda\Vert_{V_0}^2\right\rbrace\right)\mathrm{d}\lambda.
\end{align*}$$</p>

It can be verified that
<p>$$\begin{align*}
  &\left\Vert\lambda - \sigma^{-1}H_t^{\dagger}S_t\right\Vert_{H_t}^2 + \Vert\lambda\Vert_{V_0}^2 = \lambda^\top (V_0+H_t)\lambda - 2\sigma^{-1}\lambda^\top S_t + \sigma^{-2}S_t^\top H_t^{\dagger} S_t\\
  &= \Vert \lambda - \sigma^{-1}V_t^{-1}S_t\Vert_{V_t}^2 + \Vert \sigma^{-1}S_t\Vert_{H_t^{\dagger}}^2 - \Vert \sigma^{-1}S_t\Vert_{V_t^{-1}}^2,
  \end{align*}$$</p>

then
<p>$$\begin{align*}
  M_t &= \frac{1}{c(V_0)}\exp\left(\frac{1}{2}\Vert \sigma^{-1}S_t\Vert_{V_t^{-1}}^2\right)\int\exp\left(-\frac{1}{2}\Vert \lambda - \sigma^{-1}V_t^{-1}S_t\Vert_{V_t}^2\right)\mathrm{d}\lambda\\
  &= \frac{c(V_t)}{c(V_0)}\exp\left(\frac{1}{2}\Vert \sigma^{-1}S_t\Vert_{V_t^{-1}}^2\right)\\
  &= \sqrt{\frac{\det(V_0)}{\det(V_t)}}\exp\left(\frac{1}{2}\Vert \sigma^{-1}S_t\Vert_{V_t^{-1}}^2\right).
\end{align*}$$</p>

Since $\mathbb{E}[M_ \tau] \leq 1,$ apply the Markov's inequality:
<p>$$\begin{align*}
  \delta \geq \frac{\mathbb{E}[M_\tau]}{1/\delta} &\geq \mathbb{P}\left\lbrace {M_\tau} \geq {1/\delta}  \right\rbrace\\
  &= \mathbb{P}\left\lbrace \sqrt{\frac{\det(V_0)}{\det(V_\tau)}}\exp\left(\frac{1}{2}\Vert \sigma^{-1}S_\tau\Vert_{V_\tau^{-1}}^2\right) \geq {1/\delta}  \right\rbrace\\
  &= \mathbb{P}\left\lbrace \Vert S_\tau\Vert_{V_\tau^{-1}}^2 \geq 2\sigma^2\log\left(\frac{\det(V_\tau)^{1/2}\det(V_0)^{-1/2}}{\delta}\right)\right\rbrace.
\end{align*}$$</p>

Then we concludes the proof.


