# f-Divergences
## Definition and Properties
**Definition.** Let $P$ and $Q$ be two probability measures on a non-empty set $\mathcal{X}.$ Then for any convex function $f:\mathbb{R}^+\to\mathbb{R}$ such that $f(1)=0$ and $f$ is strictly convex at $1.$ Suppose that $Q$ is absolutely continuous with respect to $P.$ Then the $f$-divergence of $Q$ with respect to $P$ is defined as
<p>$$D_f(Q\Vert P) := \int f\left(\frac{\mathrm{d}Q}{\mathrm{d}P}\right)\mathrm{d}P(x),$$</p>

where the notation $\frac{\mathrm{d}Q}{\mathrm{d}P}$ stands for the Radon-Nikodym derivative of $Q$ with respect to $P.$

**Remark.** In practice, there are two more convenient forms of $f$-divergence.
+ When $\mathcal{X}$ is discrete,
  <p>$$D_f(Q\Vert P) = \sum_{x\in\mathcal{X}}f\left(\frac{Q(x)}{P(x)}\right)P(x).$$</p>
  
+ When $P$ and $Q$ are specified by density functions $p$ and $q,$ respectively, then
  <p>$$D_f(q\Vert p) = \int f\left(\frac{q(x)}{p(x)}\right)p(x)\mathrm{d}x.$$</p>

### Properties of $f$-divergences
+ **(Non-negativity).** $D_f(Q\Vert P)\geq 0$ with equality holds if and only if $P=Q.$
  
  *Proof.* From Jensen's inequality, the convexity of $f$ implies
  <p>$$D_f(Q\Vert P) = \mathbb{E}_P\left[f\left(\frac{\mathrm{d}Q}{\mathrm{d}P}\right)\right] \geq f\left(\mathbb{E}_P\left[\frac{\mathrm{d}Q}{\mathrm{d}P}\right]\right) = f(1) = 0.$$</p>
  Plus the strict convexity of $f$ at $1,$ the equality holds if and only if $P=Q.$

+ **(Joint convexity).** $(Q,P)\mapsto D_f(Q\Vert P)$ is a jointly convex function.
+ **(Conditional increment).** Define the conditional $f$-divergence:
  <p>$$D_f(Q_{Y|X}\Vert P_{Y|X}|P_X):= \mathbb{E}_{X\sim P_X}\left[D_f(Q_{Y|X}\Vert P_{Y|X})\right].$$ </p>

  Let $P_Y = P_{Y\vert X}P_X,$ $Q_Y = Q_{Y\vert X}P_X,$  then
  <p>$$D_f(Q_Y\Vert P_Y)\leq D_f(Q_{Y|X}\Vert P_{Y|X}|P_X).$$</p>

## Variational Representation
The variational form of $f$-divergence is based on the Fenchel conjugate of $f,$ which is defined as $f^*(t) = \sup_{x\in\mathbb{R}^+}\lbrace tx - f(x)\rbrace,\ t\in\mathbb{R}.$ The $f$-divergence admits the following variational formulation.

**Lemma 1** (Variational representation of $f$-divergence). Let $\Phi$ be a convex class of measurable functions $\phi:\mathcal{X}\to\mathbb{R}.$ Suppose $f$ is differentiable. Then
<p>$$D_f(Q\Vert P) \geq \sup_{\phi\in\Phi} \left\lbrace\mathbb{E}_{Z\sim Q}[\phi(Z)] - \mathbb{E}_{X\sim P}[f^*(\phi(X))]\right\rbrace,$$</p>

where the equality holds if and only if $f'(\mathrm{d}Q/\mathrm{d}P)\in\Phi$ and the supremum is reached at $\phi^* = f'(\mathrm{d}Q/\mathrm{d}P).$

*Proof.* We fix the measurable function $\phi\in\Phi.$ By Fenchel's duality, we have
<p>$$\phi(x)\frac{\mathrm{d}Q(x)}{\mathrm{d}P(x)} - f\left(\frac{\mathrm{d}Q(x)}{\mathrm{d}P(x)}\right)\leq f^*(\phi(x)).$$</p>

Take integration with respect to $P$ on both sides of the equation above, we have
<p>$$\mathbb{E}_{Z\sim Q}[\phi(Z)] - D_f(Q\Vert P) \leq \mathbb{E}_{X\sim P}[f^*(\phi(X))].$$</p>

Since $\phi$ is arbitrarily chosen, we immediately conclude the inequality in Lemma 1. 
  
## Inequalities between $f$-divergences
