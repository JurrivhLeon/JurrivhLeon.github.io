\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{bbm}
\usepackage{booktabs}
\usepackage{dsfont}
\usepackage{enumitem}
\usepackage{extarrows}
\usepackage{float} 
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{inconsolata}
\usepackage{listings}
\usepackage{makecell}
\usepackage{mathrsfs}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{subfigure} 
\usepackage{threeparttable}
\usepackage[dvipsnames]{xcolor}
\setitemize[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=0pt}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}
\newcommand{\E}{\mathbb{E}}
\newcommand{\supp}{\mathrm{supp}\,}
\newcommand{\esssup}{\mathrm{ess}\sup}
\newcommand{\Gr}{\mathrm{Gr}\,}
\newcommand{\ind}{\perp\!\!\!\perp}
\renewcommand{\Re}{\mathrm{Re}}
\renewcommand{\Im}{\mathrm{Im}}
\renewcommand{\i}{\mathrm{i}}
\renewcommand{\P}{\mathbb{P}}
\renewcommand{\proofname}{\textit{Proof}}
\renewcommand*{\thesubfigure}{(\arabic{subfigure})}
\renewcommand{\baselinestretch}{1.20}
\title{\bf Lecture Notes for Functional Analysis (MATH130011)}
\usepackage{geometry}
\geometry{a4paper, scale=0.80}
\author{\textsc{Jyunyi Liao}}
\date{}
\begin{document}
\maketitle
\tableofcontents
\newpage

\setcounter{section}{-1}
\section{Notations}
\begin{description}
	\item[$m$ and $m_d$]: The Lebesgue measures on $\mathbb{R}$ and $\mathbb{R}^d$
	\item[$f\underset{m}{\overset{\cdot}{=}}g$]: $f=g$ almost everywhere in sense of the Lebesgue measure
	\item[$f_n\rightrightarrows f$]: The sequence $(f_n)$ of functions converges uniformly to $f$
	\item[$C(X)$ or $C^0(X)$]: The set of all continuous real-valued functions on $X$
	\item[$C^k(X)$]: The set of all $k$-differentiable real-valued functions on $X$ with the $k$-th derivative continuous
	\item[$C^\infty(X)$]: The set of all infinitely differentiable real-valued functions on $X$
	\item[$C_0(X)$]: The set of all uniformly continuous real-valued functions on $X$
	\item[$C_c(X)$]: The set of all compactly supported continuous real-valued functions on $X$
	\item[$\supp f$]: The support $\overline{\{f\neq 0\}}$ of $f$, which is the smallest closed set containing all points not mapped to zero
	\item[$\esssup$]: The essential supremum
	\item[$\amalg$]: The union of disjoint sets
\end{description}

\newpage
\section{Metric Spaces}
\subsection{Metric Spaces}
\paragraph{Definition 1.1\label{def:1.1}} (Metric spaces). Let $X$ be a nonempty set. A map $d:X\times X\to\mathbb{R}_+$ is said to be a \textbf{\it metric} on $X$, if it satisfies the following conditions:
\begin{itemize}
	\item[(i)] (Positive-definiteness). For each pair of points $x,y$ of $X$, $d(x,y)\geq 0$; $d(x,y)=0$ if and only if $x=y$.
	\item[(ii)] (Symmetry). For each pair of points $x,y$ of $X$, $d(x,y)= d(y,x)$.
	\item[(iii)] (Triangle inequality). For any $x,y,z\in X$,
	\begin{align*}
		d(x,y) + d(y,z)\geq d(x,z).
	\end{align*}
\end{itemize}
The set together with the metric $(X,d)$ is called a \textit{metric space}.

\paragraph{Remark.} The metric $d:X\times X\to\mathbb{R}_+$ is a continuous map. To see this, we fix $\epsilon >0$ and let $(x_0,y_0)\in X\times X$. Then for all $(x,y)\in O(x_0,\epsilon/3)\times O(y_0,\epsilon/3)$, we have $\vert d(x,y) - d(x_0,y_0)\vert\leq d(x,x_0) + d(y,y_0) \leq 2\epsilon/3 < \epsilon$.

\paragraph{Example 1.2.\label{example:1.2}} The following are some instances of metric spaces.
\vspace{0.1cm}
\begin{itemize}
	\item[(i)] On the real line $\mathbb{R}$, define $d(x,y)=\vert x-y\vert,\ x,y\in\mathbb{R}$. Then $(\mathbb{R},d)$ is a metric space.
	\vspace{0.1cm}
	\item[(ii)] On the $n$-dimensional real space $\mathbb{R}^n$, for two points $\mathbf{x}=(x_1,\cdots,x_n),\mathbf{y}=(y_1,\cdots,y_n)$, define
	\begin{align*}
		\rho_p(\mathbf{x},\mathbf{y}) \left(\sum_{i=1}^n \vert x_n-y_n\vert^p\right)^{1/p},\ 
		\rho_\infty(\mathbf{x},\mathbf{y}) = \max_{i\in[n]} \vert x_n-y_n\vert.
	\end{align*}
    Then for every $1\leq p<\infty$, $(\mathbb{R}^n,\rho_p)$ is a metric space. To check this, we only need to verify the triangle inequality, which is a special case of the Minkowski's inequality.
    Also, $(\mathbb{R},\rho_\infty)$ is a metric space.
    \vspace{0.1cm}
    \item[(iii)] (Discrete space). On a nonempty set $X$, define the discrete metric
    \begin{align*}
    	d_0(x,y)=\begin{cases}
    		0,\ x=y,\\
    		1,\ x\neq y.
    	\end{cases}
    \end{align*}
    Then $(X,d_0)$ becomes a metric space called \textit{discrete space}.
    \vspace{0.1cm}
    \item[(iv)] (Subspace). Let $(X,d)$ be a metric space, and let $A$ be a nonempty subset of $X$. We define on $A$ the \textit{restricted metric} $d_A(x,y)=d(x,y)$ for each pair of points $x,y$ in $A$. Then $(A,d_A)$ is a metric space, and we call it a \textit{subspace} of $X$.
    \vspace{0.1cm}
    \item[(v)] Let $(X,d)$ be a metric space. Let $f:\mathbb{R}_+\to\mathbb{R}_+$ be a function such that (a) $f$ is well-defined on $[0,\infty)$; (b) $f$ is non-decreasing on $[0,\infty)$, strictly increasing at $0$, and $f(0)=0$; and (c) $f$ is concave on $[0,\infty)$, i.e. for all $x,y\in[0,\infty)$ and all $\alpha\in[0,1]$,
    \begin{align*}
    	f(\alpha x+(1-\alpha)y)\geq \alpha f(x) + (1-\alpha)f(y).\tag{1.1}\label{eq:1.1}
    \end{align*}
    Then the composition
    \begin{align*}
    	d_f(x,y)=f\left(d(x,y)\right),\ x,y\in X
    \end{align*}
    is a metric on $X$. Moreover, it induces the same topology on $X$ as $d$ does.
    
    \begin{proof}
    To check that $d_f$ is a metric on $X$, it suffices to show the triangle inequality. Given $x,y,z\in X$, we want to show
    \begin{align*}
    	f(d(x,y)) + f(d(y,z)) \geq f(d(x,z)).\tag{1.2}\label{eq:1.2}
    \end{align*}
    We show that for all $s,t\geq 0$, $f(s)+f(t)\geq f(s+t)$, which implies \hyperref[eq:1.2]{(1.2)}. Without loss of generality, we assume $s,t >0$. Then
    \begin{align*}
    	f(s) + f(t) &= f\left(\frac{s}{s+t}\cdot(s+t) + \frac{t}{s+t}\cdot 0\right) + f\left(\frac{t}{s+t}\cdot(s+t) + \frac{s}{s+t}\cdot 0\right)\\
    	&\overset{\hyperref[eq:1.1]{(1.1)}}{\geq} \frac{s}{s+t}f(s+t) + \frac{t}{s+t}f(0) + \frac{t}{s+t}f(s+t) + \frac{s}{s+t}f(0)\\
    	&= f(s+t).
    \end{align*}
    Since $f$ is strictly increasing at $0$, there exists some $\delta > 0$ such that $f$ is strictly increasing on $(0,\delta)$. Given $x_0$ be a point of $X$, let $O_d(x_0,r):=\{x\in X:d(x,x_0) < r\}$ be the open ball of radius $r$ centered at $x_0$. When $f(r)<\delta$, we have $O_d(x_0,r)=O_{d_f}(x_0,f(r)):=\{x\in X:d_f(x,x_0) < f(r)\}$.
    
    To show that $d_f$ induces the same topology on $X$ as $d$ does, note that the collection 
    $$\left\{O_d(x,r):x\in X,r<f^{-1}\left(\frac{\delta}{2}\right)\right\}$$
    is a basis for the topology on $X$ induced by $d$, which coincides with the basis 
    $$\left\{O_{d_f}(x,r):x\in X,r<\frac{\delta}{2}\right\}$$
    for the topology induced by $f$.
    \end{proof}
    When $f(t)=\min\{t,1\}$, we obtain the standard bounded metric $\bar{d}(x,y)=\min\{d(x,y),1\}$ on $X$.
\end{itemize} 

\paragraph{Definition 1.3\label{def:1.3}} (Limit). Let $(X,d)$ be a metric space, and let $\{x_n\}_{n=1}^\infty$ be a sequence of points of $X$. Let $p\in X$. If for each $\epsilon > 0$, there exists a positive integer $N$ such that $d(x_n,p)<\epsilon$ for all $n\geq N$, then we say that the sequence $\{x_n\}_{n=1}^\infty$ \textit{converges to} $p$, or that $p$ is the \textit{limit} of $\{x_n\}_{n=1}^\infty$. We write $x_n\to p$, or
\begin{align*}
	\lim_{n\to\infty} x_n=p.
\end{align*}
\paragraph{Remark.} By definition, convergence in metric space $(X,d)$ equals convergence in the metric topology induced by $d$. Then if two metrics, for example, $d$ and $d_f$ in \hyperref[example:1.2]{Example 1.2 (v)}, induce the same topology, we can establish the equivalence of convergence in the two corresponding metric spaces. The uniqueness of the limit is ensured by the following lemma.

\paragraph{Lemma 1.4\label{lemma:1.4}} (The uniqueness of limit). Let $(X,d)$ be a metric space, and let $\{x_n\}_{n=1}^\infty$ be a sequence of points of $X$. If $x_n\to x$, and $x_n\to y$, then $x=y$.
\begin{proof}
By the properties, we have for all $n\in\mathbb{N}$ that
\begin{align*}
	0\leq d(x,y) \leq d(x_n,x) + d(x_n,y).
\end{align*}
Let $n\to \infty$, we have $d(x,y)=0$, hence $x=y$.
\end{proof}

Now we introduce the definition of complete metric spaces.

\paragraph{Definition 1.5\label{def:1.5}} (Cauchy sequences and completeness). Let $(X,d)$ be a metric space. A sequence $\{x_n\}_{n=1}^\infty$ of points of $X$ is said to be a \textit{Cauchy sequence} if for any $\epsilon > 0$, there exists $N$ such that $d(x_n,x_m) < \epsilon$ for all $n,m\geq N$. If every Cauchy sequence in $(X,d)$ converges to some point of $X$, then $(X,d)$ is said to be a \textit{complete metric space}.

\paragraph{Remark.} For the metric space $(\mathbb{R},d)$ where $d(x,y)=\vert x-y\vert$, the statement of completeness is in fact the Cauchy's criterion for convergence.

\paragraph{Lemma 1.6.\label{lemma:1.6}} Let $(X,d)$ be a metric space.
If $(X,d)$ is complete, $A$ is a closed subspace of $X$, and $d_A$ is the restricted metric of $A$, i.e. $d_A(x,y)=d(x,y)\ \forall x,y\in A$, then $(A,d_A)$ is a complete metric space.
\begin{proof}
Let $(x_n)$ be a Cauchy sequence in $A$ under $d_A$. Then $(x_n)$ is also a Cauchy sequence in $X$ under $d$, and it converges to some $x\in X$. By definition, any neighborhood $U$ of $x$ contains infinitely many points of $(x_n)$. Hence $x$ is a limit point of $A$. Since $A$ is closed, $x\in A$, and $(x_n)$ converges with respect to $d_A$.
\end{proof}

Now we introduce a criterion for a metric space to be complete.

\paragraph{Lemma 1.7\label{lemma:1.7}} (Subsequence criterion).  A metric space $(X,d)$ is complete if every Cauchy sequence in $X$ has a convergent subsequence.
\begin{proof}
	Let $(x_n)$ be a Cauchy sequence in $X$, and let $(x_{n_k})$ be a convergent subsequence of $(x_n)$. Fix $\epsilon > 0$. We first choose a positive integer $N$ such that $n,m\geq N$ implies $d(x_n,x_m)<\epsilon / 2$.
	
	Suppose that the subsequence $(x_{n_k})$ converges to $x\in X$. We choose a sufficiently large integer $K$ so that $n_K\geq N$ and $k\geq K$ implies $d(x_{n_k},x)<\epsilon/2$. Then for any $n\geq N$, we have
	\begin{align*}
		d(x_n,x) \leq d(x_{n_k},x_n) + d(x_{n_k},x) < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon.
	\end{align*}
	Since $\epsilon$ is arbitrarily chosen, $(x_n)$ converges to $x$.
\end{proof}

\paragraph{Example 1.8\label{example:1.8}} (Metrization of pointwise convergence). Let $\mathbb{R}^\infty=\{\mathbf{x}=(x_1,x_2,\cdots):x_n\in\mathbb{R}\ \forall n\in\mathbb{N}\}$ be the set of all real sequences. We define the metric
\begin{align*}
	d(\mathbf{x},\mathbf{y}) = \sum_{n=1}^\infty \frac{1}{2^n}\cdot\frac{\vert x_n-y_n\vert}{1+\vert x_n-y_n\vert},\ \mathbf{x}=(x_1,x_2,\cdots),\ \mathbf{y}=(y_1,y_2,\cdots).
\end{align*}
Then $(\mathbb{R}^\infty,d)$ is a metric space. Furthermore, convergence of sequence $\left\{\mathbf{x}^{(k)}\right\}$ to $\mathbf{x}$ in metric space $(X,d)$ is equivalent to pointwise convergence (or coordinate-wise convergence), i.e. $\lim_{k\to\infty}x_n^{(k)}=x_n$ for all $n\in\mathbb{N}$.
\begin{proof}
``$\Leftarrow$'': If $\mathbf{x}^{(k)}$ converges to $\mathbf{x}$ pointwise, then for any $\epsilon > 0$, we choose a positive integer $N_\epsilon$ such that 
\begin{align*}
	N_\epsilon > \frac{1+\log(1/\epsilon)}{\log 2}.
\end{align*}
Then we have for all $k\in\mathbb{N}$ that
\begin{align*}
	\sum_{n=N_\epsilon+1}^\infty \frac{1}{2^n}\cdot\frac{\bigl\vert x_n^{(k)}-x\bigr\vert}{1+\bigl\vert x_n^{(k)}-x\bigr\vert} \leq \sum_{n=N_\epsilon+1}^\infty \frac{1}{2^n} < \frac{\epsilon}{2}.\tag{1.3}\label{eq:1.3}
\end{align*}
Moreover, for each $n=1,\cdots,N_\epsilon$, we can choose $K_n$ such that $\bigl\vert x^{(k)}_n-x_n\bigr\vert < \epsilon/N_\epsilon$ for all $k\geq K_n$. Let $K$ be the largest of $K_n$. Then for all $k\geq K$, we have
\begin{align*}
	\sum_{n=1}^{N_\epsilon}\frac{1}{2^n}\cdot\frac{\bigl\vert x_n^{(k)}-x\bigr\vert}{1+\bigl\vert x_n^{(k)}-x\bigr\vert}\leq \sum_{n=1}^{N_\epsilon}\frac{1}{2}\bigl\vert x_n^{(k)}-x\bigr\vert < \frac{\epsilon}{2}.\tag{1.4}\label{eq:1.4}
\end{align*}
Combining \hyperref[eq:1.3]{(1.3)} and \hyperref[eq:1.4]{(1.4)}, we conclude that $\mathbf{x}^{(k)}$ converges to $\mathbf{x}$ under $d$.
\vspace{0.12cm}

``$\Rightarrow$'':  For any $n\in\mathbb{N}$ and sufficiently large $k$, note that\\

$\hspace{5cm}\displaystyle\bigl\vert x_n^{(k)}-x_n\bigr\vert \leq \frac{2^n\cdot d(\mathbf{x}^{(k)},\mathbf{x})}{1-2^n\cdot d(\mathbf{x}^{(k)},\mathbf{x})}\to 0.$
\end{proof}

\paragraph{Example 1.9\label{example:1.9}} (Metrization of convergence in measure). Let $\mathcal{G}$ be the set of all Lebesgue measurable functions on $[a,b]$ that is bounded almost everywhere. We define an equivalence relation $\sim$ on $\mathcal{G}$ as follows: $f\sim g$ if $f=g$ almost everywhere. Let $G=\mathcal{G}/\sim$. For $f,g\in G$, define
\begin{align*}
	d(f,g)=\int_{[a,b]}\frac{\vert f(t)-g(t)\vert}{1+\vert f(t)-g(t)\vert} dm(t).
\end{align*}
Then $(G,d)$ is a metric space. Furthermore, convergence of sequence $(f_n)$ to $f$ in metric space $(G,d)$ is equivalent to convergence in measure, i.e. $m(\vert f_n - f\vert \geq \epsilon)\to 0$ for all $\epsilon > 0$.
\begin{proof}
``$\Leftarrow$'': Given $\epsilon > 0$, define 
\begin{align*}
	E_n = \left\{x\in[a,b]:\vert f_n(x)-f(x)\vert\geq \frac{\epsilon}{2(b-a)}\right\}.\tag{1.5}\label{1.5}
\end{align*}
Then there exists $N$ such that $m(E_n)<\epsilon/2$ for all $n \geq N$. As a result, for all $n\geq N$, we have
\begin{align*}
	d(f_n,f) &= \int_{[a,b]\backslash E_n}\frac{\vert f(t)-g(t)\vert}{1+\vert f(t)-g(t)\vert} dm(t) + \int_{E_n}\frac{\vert f(t)-g(t)\vert}{1+\vert f(t)-g(t)\vert} dm(t)\\
	&\leq \int_{[a,b]\backslash E_n}\vert f(t)-g(t)\vert dm(t) + \int_{E_n} dm(t)\\
	&\leq (b-a)\cdot \frac{\epsilon}{2(b-a)} + m(E_n) < \epsilon.
\end{align*}
``$\Rightarrow$'': For any $\epsilon > 0$, we have
\begin{align*}
	m(\vert f_n-f\vert \geq\epsilon) &= m\left(\frac{\vert f_n-f\vert}{1+\vert f_n-f\vert} \geq\frac{\epsilon}{1+\epsilon}\right)\\
	&\leq \frac{1+\epsilon}{\epsilon}\int_{[a,b]}\frac{\vert f_n-f\vert}{1+\vert f_n-f\vert}dm\to 0.\tag{1.6}
\end{align*}
Hence $f_n$ converges in measure to $f$.
\end{proof}

\newpage
\subsection{Banach Spaces and Hilbert Spaces}
\subsubsection{The Hamel Basis}
\paragraph{Definition 1.10\label{def:1.10}} (Vector spaces, linearly independent subsets). A \textit{vector space} over a scalar field $\mathbb{F}$ is a non-empty set $X$ together with a binary operation $+:X\times X\to X$ called \textit{vector addition}, and a binary function $\mathbb{F}\times X\to X$ called \textit{scalar multiplication}. Let $x,y,z$ be any elements of $X$, and $\alpha,\beta$ be any scalar in $\mathbb{F}$. A vector space satisfies the following axioms:
\begin{itemize}
	\item[(i)] (Associativity of vector addition). $(x+y)+z=x+(y+z)$.
	\item[(ii)] (Commutativity of vector addition). $x+y=y+x$.
	\item[(iii)] (Identity element of vector addition). There exists an  element $\mathbf{0}\in X$ called the \textit{zero vector} such that $x+\mathbf{0}=x$ for all $x\in X$.
	\item [(iv)] (Inverse elements of vector addition). For each $x\in X$, There exists an element $-x\in X$ called the \textit{additive inverse} of $x$ such that $x+(-x)=0$.
	\item[(v)] (Compatibility of scalar multiplication with field multiplication). $\alpha(\beta x)=(\alpha\beta)x$.
	\item[(vi)] (Identity element of scalar multiplication). $1x=x$, where $1$ is the multiplicative identity in $\mathbb{F}$. 
	\item[(vii)] (Distributivity of scalar multiplication with respect to vector addition). $\alpha(x+y) = \alpha x + \alpha y$.
	\item[(vii)] (Distributivity of scalar multiplication with respect to field addition). $(\alpha + \beta)x = \alpha x + \beta x$.
\end{itemize}

A finite subset $\{x_1,\cdots,x_n\}$ of $X$ is said to be \textit{linearly independent}, if it satisfies following: $\sum_{i=1}^n \alpha_i x_i=\mathbf{0}$ if and only if $\alpha_1=\alpha_2=\cdots=\alpha_n= 0$, i.e. there exists no nontrivial linear combination of $x_1,\cdots,x_n$ that equals the zero vector. An infinite subset $A$ of $X$ is said to be \textit{linearly independent}, if every nonempty finite subset of $A$ is linearly independent.

\paragraph{Remark.} When the field $\mathbb{F}$ is chosen to be the real field $\mathbb{R}$ (or the complex field $\mathbb{C}$), we say that $X$ is a real vector space (or a complex vector space).

\paragraph{Definition 1.11\label{def:1.11}} (Basis). Let $X$ be a vector space. A collection $B$ of vectors in $X$ is said to be a \textit{basis} of $X$, if $B$ is linearly independent, and every vector $x\in X$ can be obtained as a linear combination of vectors in $B$. 

\paragraph{} A natural question arises: does every vector space has a basis?

\paragraph{Theorem 1.12\label{thm:1.12}} (Hamel basis). Let $X$ be a vector space. Let $A$ be a linearly independent subset of $X$. Then there exists a \textit{maximal linearly independent subset} $B$ of $X$ such that $A\subset B$, and there exists no linearly independent subset of $X$ that includes $B$ properly. Furthermore, $B$ is a basis of $X$, called a \textit{Hamel basis}.
\begin{proof}
We use Zorn's lemma: Suppose a partially ordered set $P$ has the property that every totally ordered subset of $P$ has an upper bound in $P$, then $P$ has at least one maximal element.

Let $\mathscr{C}$ be the set of all linearly independent subsets of $X$ that contains $A$. We order the elements of $\mathscr{C}$ by proper inclusion. For any totally ordered subset $\{A_\lambda,\lambda\in\Lambda\}$ of $\mathscr{C}$, where $\Lambda$ is an index set, the union
\begin{align*}
	C=\bigcup_{\lambda\in\Lambda} A_\lambda
\end{align*}
is an upper bound of $\{A_\lambda,\lambda\in\Lambda\}$. We verify that $C\in\mathscr{C}$. Clearly, $A\subset C$, then we show that $C$ is linearly independent. For any finite subset $\{x_1,\cdots,x_n\}$ of $C$, there exists $A_{\lambda_i}\ni x_i$ for each $i$. Since $A_{\lambda_1},\cdots,A_{\lambda_n}$ are totally ordered, we can find $A_{\lambda_k}$ that contains all of them. Hence $\{x_1,\cdots,x_n\}$ as a finite subset of the linearly independent subset $A_{\lambda_k}$ is linearly independent, and $C$ is linearly independent.

By Zorn's lemma, there exists a maximal linearly independent subset $B$ in $\mathscr{C}$, and $B$ is a basis of $X$. In fact, if $B$ is not a basis for $X$, we can choose $x\in X$ not lying in the span of $B$. Then $B\cup\{x\}$ is an linearly independent subset of $X$, which contradicts the maximality of $B$!
\end{proof}

\subsubsection{Normed Spaces and Banach Spaces}
\paragraph{Definition 1.13\label{def:1.13}} (Normed spaces). A \textit{seminorm} on a real (or complex) vector space $X$ is a function $\Vert\cdot\Vert:X\to\mathbb{R}_+$ satisfying the following conditions:
\begin{itemize}
	\item[(i)] (Positive semi-definiteness). For all $x\in X$, $\Vert x\Vert\geq 0$; 
	\item[(ii)] (Homogeneity). For all $\alpha\in\mathbb{R}$ (or $\mathbb{C}$) and all $x\in X$, $\Vert\alpha x\Vert = \vert\alpha\vert\Vert x\Vert$; 
	\item[(iii)] (Triangle inequality). For all $x,y\in X$, $\Vert x+y\Vert\leq \Vert x\Vert + \Vert y\Vert$.
\end{itemize}
A \text{norm} on $X$ is a seminorm $\Vert\cdot\Vert$ that satisfies the following: $\Vert x\Vert=0$ only if $x=0$. A vector space together with a norm $(X,\Vert\cdot\Vert)$ is called a \textit{normed vector space}, or briefly, a \textit{normed space}.

\paragraph{Remark.} A norm $\Vert\cdot\Vert$ on a vector space $X$ automatically induces a metric on $X$ defined as $d(x,y)=\Vert x-y\Vert$. By equipping a norm, we introduce a topological structure to a vector space, which is an algebraic structure.

The norm $\Vert\cdot\Vert$ is a continuous map in space $(X,\Vert\cdot\Vert)$, which is implied by the triangle inequality. To see this, fix $\epsilon > 0$ and $x_0\in X$. Then for all $x\in O(x_0,\epsilon)$, we have
\begin{align*}
	\left\vert\Vert x\Vert - \Vert x_0\Vert\right\vert \leq \Vert x-x_0\Vert < \epsilon,
\end{align*}
which meets the definition of continuity.

\paragraph{Example 1.14.\label{example:1.14}} Following are some instances for normed spaces.
\vspace{0.1cm}
\begin{itemize}
\item[(i)] Let $C([a,b])$ be the set of all real-valued continuous functions on $[a,b]$. Define
\begin{align*}
	\Vert f\Vert_\infty = \max_{x\in[a,b]} \vert f(x)\vert,\ f\in C([a,b]).
\end{align*}
Then $(C([a,b]),\Vert\cdot\Vert_\infty)$ is a normed space.
\vspace{0.1cm}
\item[(ii)] Let $k$ be a positive integer. Let $C^k([a,b])$ be the set of all functions $f$ on $[a,b]$ such that $f$ is $k$-differentiable, and the $k$-th derivative $f^{(k)}$ is continuous. Define
\begin{align*}
	\Vert f\Vert_{k,\infty} = \max_{0\leq j\leq k}\max_{x\in[a,b]} \vert f^{(j)}(x)\vert,\ f\in C^k([a,b]).
\end{align*}
Then $(C([a,b]),\Vert\cdot\Vert_\infty)$ is a normed space.
\vspace{0.1cm}
\item[(iii)] Let $(X,\mathscr{A},\mu)$ be a measurable space. For $1\leq p<\infty$, define $\mathcal{L}^p(X,\mathscr{A},\mu)$ to be the set of all measurable functions $f$ such that $\vert f\vert^p$ is integrable, i.e. $\int_X\vert f\vert^p d\mu < \infty$. We define
\begin{align*}
	\Vert f\Vert_p = \left(\int_X\vert f\vert^p d\mu\right)^{1/p},\ f\in\mathcal{L}^p(X,\mathscr{A},\mu).
\end{align*}
Then $\Vert\cdot\Vert_p$ is a seminorm on $\mathcal{L}^p(X,\mathscr{A},\mu)$. To check this, it suffices to prove the following two inequalities.
\begin{itemize}
	\item[$\bullet$] (Hölder's inquality). For all $p,q>1$ with $p^{-1}+q^{-1}=1$, it holds
	\begin{align*}
		\int\left\vert fg\right\vert d\mu \leq \Vert f\Vert_p\Vert g\Vert_q.
	\end{align*}
    \begin{proof}
    Without loss of generality, suppose $\Vert f\Vert_p=\Vert g\Vert_q = 1$. We use Young's inequality:
    \begin{align*}
    	\underbrace{\log\left(\frac{a^p}{p} + \frac{b^q}{q}\right)\geq \frac{1}{p}\log(a^p) +\frac{1}{q}\log(b^q)}_{\text{Concavity of the logarithmic function}}\ \Rightarrow\ ab \leq \frac{a^p}{p} + \frac{b^q}{q}.
    \end{align*}
    Then we have
    \begin{align*}
    	\vert f(x)g(x)\vert\leq \frac{\vert f(x)\vert^p}{p} + \frac{\vert g(x)\vert^q}{q}\ \overset{\text{Integration}}{\Rightarrow}\ \int \left\vert fg\right\vert d\mu \leq \frac{\Vert f\Vert^p}{p} + \frac{\Vert g\Vert^q}{q} = 1,
    \end{align*}
    which concludes the proof.
    \end{proof}
	\item[$\bullet$] (Minkowski's inquality). For all $p\geq 1$, we have
	\begin{align*}
		\Vert f+g\Vert_p \leq \Vert f\Vert_p + \Vert g\Vert_p.
	\end{align*}
    \begin{proof}
    We only prove the case $p>1$. Let $q=\frac{p}{p-1}$, then
    \begin{align*}
    	\Vert f+g\Vert_p^p &\leq \int_X\left\vert f\right\vert\cdot\left\vert f+g\right\vert^{p-1} d\mu + \int_X\left\vert g\right\vert\cdot\left\vert f+g\right\vert^{p-1} d\mu \\
    	&\leq (\Vert f\Vert_p+\Vert g\Vert_p)\left(\int_X \vert f+g\vert^{(p-1)q}d\mu\right)^{1/q}\tag{By Hölder's inquality}\\
    	&\leq (\Vert f\Vert_p+\Vert g\Vert_p)\cdot\Vert f+g\Vert_p^{p/q}.
    \end{align*}
    Note that $p-p/q = 1$, then we conclude the proof.
    \end{proof}
\end{itemize}
\vspace{0.1cm}
\item[(iv)]
Let $f\sim g\overset{\mathrm{def.}}{\Leftrightarrow} f\underset{\mu}{\overset{\cdot}{=}}g$ be a equivalence relation on $\mathcal{L}^p(X,\mathscr{A},\mu)$. We define the $L^p$ space as $L^p(X,\mathscr{A},\mu)=\mathcal{L}^p(X,\mathscr{A},\mu)/\sim$, and maintain the norm $\Vert[f]\Vert_p=\Vert f\Vert_p$. This is a well-defined norm, since $\Vert f\Vert_p = \Vert g\Vert_p$ if $f\sim g$. For simplicity, we drop the brackets and use $f$ to denote its corresponding equivalence class $[f]$ in $L^p(X,\mathscr{A},\mu)$. Then the space $(L^p(X,\mathscr{A},\mu),\Vert\cdot\Vert_p)$ is a normed space.
\vspace{0.1cm}
\item[(v)] Let $p=\infty$ in (ii), then we obtain the set of \textit{essentially bounded} functions on $X$, which is
\begin{align*}
	\mathcal{L}^\infty(X,\mathscr{A},\mu)=\{f:X\to\mathbb{R}\ |\ \exists M>0,\ \mu(\vert f\vert\geq M)=0\}.
\end{align*}
The seminorm $\Vert\cdot\Vert_\infty$ on $\mathcal{L}^\infty(X)$ is the essential supremum:
\begin{align*}
	\Vert f\Vert_\infty = \esssup\vert f\vert := \inf_{\mu(E)=0}\sup_{x\in X\backslash E} \vert f(x)\vert.
\end{align*}
Also, we define $L^\infty(X,\mathscr{A},\mu)=\mathcal{L}^\infty(X,\mathscr{A},\mu)/\sim$. Then $(L^\infty(X,\mathscr{A},\mu),\Vert\cdot\Vert_\infty)$ is a normed space.
\end{itemize}

\paragraph{Definition 1.15\label{def:1.15}} (Banach spaces). Let $(X,\Vert\cdot\Vert)$ be a normed space. If $X$ is complete given the metric induced by $\Vert\cdot\Vert$, then $(X,\Vert\cdot\Vert)$ is said to be a \textit{Banach space}.

\paragraph{Remark.} A Banach space is a complete normed space. Let $(x_n)$ be a Cauchy sequence in a Banach space $(X,\Vert\cdot\Vert)$, i.e. $\Vert x_n - x_m\Vert \to 0$ as $n,m\to\infty$, then $(x_n)$ converges to some point of $X$.

As a result of \hyperref[lemma:1.6]{Lemma 1.6}, a closed subspace $A$ of a Banach space $(X,\Vert\cdot\Vert)$ is also a Banach space under the restricted norm. Note that when we use the term ``subspace'' in discussions of vector spaces, we refer to a vector subspace.

\paragraph{} Following are some instances of Banach spaces.

\paragraph{Example 1.16.\label{example:1.16}} Recall \hyperref[example:1.14]{Example 1.14 (i) and (ii)}.

(i) The normed space $(C([a,b]),\Vert\cdot\Vert_\infty)$ is a Banach space; 

(ii) For each $k\in\mathbb{N}$, the normed space $(C^k([a,b]),\Vert\cdot\Vert_{k,\infty})$ is a Banach space.

\begin{proof}
(i) We pick a Cauchy sequence $f_n$ in $C([a,b])$, i.e. $\forall \epsilon>0$, $\exists N\in\mathbb{N}$ such that $\Vert f_n-f_m\Vert_\infty <\epsilon$ for all $n,m\geq N$. Then for each $x\in[a,b]$, $f_n(x)$ is a Cauchy sequence in $\mathbb{R}$, which converges to some $f(x)\in\mathbb{R}$ by completeness of real numbers. Thus we obtain a function $f$ on $[a,b]$.

Now we prove that $f$ is continuous. Fix $\epsilon>0$. Then for all $x\in X$, we have
\begin{align*}
	\vert f_n(x) - f_m(x)\vert \leq \Vert f_n - f_m\Vert_\infty < \epsilon,\ \forall n,m\geq N.
\end{align*}
Let $m\to\infty$, then we get $\vert f_n(x)-f(x)\vert \leq \epsilon$ for all $x\in X$. Hence $f_n$ converges to $f$ uniformly. Since $f_n$ is continuous on $[a,b]$, so is $f$.
\vspace{0.12cm}

(ii) We first prove the case $k=1$. We pick a Cauchy sequence $f_n$ in $C^1([a,b])$. Then both $f_n$ and $f_n^\prime$ are Cauchy sequences in $(C([a,b]),\Vert\cdot\Vert_\infty)$, which converge uniformly to some continuous functions $f$ and $g$, respectively, by (i). We need to show that $f$ is differentiable, and that $g$ is the derivative of $f$.

By fundamental theorem of calculus, we have
\begin{align*}
	f_n(x) - f_n(a) = \int_a^x f_n^\prime(t)\,dt,\ \forall n\in\mathbb{N}.
\end{align*}
Let $\epsilon>0$ be given. Since $f_n^\prime$ converges to $g$ uniformly on $[a,b]$, there exists $N$ such that $\vert f_n^\prime(x) - g(x)\vert <\epsilon$ for all $n\geq N$ and $x\in [a,b]$. Hence
\begin{align*}
	\left\vert \int_a^x f_n^\prime(t)\,dt - \int_a^x g(t)\,dt\right\vert \leq  \int_a^x \left\vert f_n^\prime(t)-g(t)\right\vert dt \leq \epsilon(x-a),\ \forall n\geq N.
\end{align*}
Hence $\int_a^x f_n^\prime(t)\,dt \to \int_a^x g(t)\,dt$. As a result,
\begin{align*}
	f(x) - f(a) = \lim_{n\to\infty} \left(f_n(x) - f_n(a)\right) = \lim_{n\to\infty} \int_a^x f_n^\prime(t)\,dt = \int_a^x g(t)\,dt,
\end{align*}
which implies $f^\prime=g$.

For the general case $k\in\mathbb{N}$, let $f_n$ be a Cauchy sequence in $C^k([a,b])$. Similar to the above procedure, we can show that the sequence $f_n^{(j)}$ converges to some continuous function uniformly on $[a,b]$ for each $j=0,1,\cdots,k$, and that $\lim_{n\to\infty} f_n^{(j)}$ is the derivative of $\lim_{n\to\infty} f_n^{(j-1)}$.
\end{proof}

\paragraph{Example 1.17} (Riesz-Fisher). Let $(X,\mathscr{A},\mu)$ be measure space. Then for each $1\leq p <\infty$, the space $(L^p(X,\mathscr{A},\mu),\Vert\cdot\Vert_p)$ is a Banach space.
\begin{proof}
We pick a Cauchy sequence $f_n$ in $L^p(X,\mathscr{A},\mu)$, i.e. $\forall \epsilon>0$, $\exists N$ such that $\Vert f_n-f_m\Vert_p <\epsilon$ for all $n,m\geq N$. By Chebyshev's inequality, for any $\eta > 0$, we have
\begin{align*}
	\mu\left(\vert f_n - f_m\vert \geq \eta\right) \leq \frac{1}{\eta^p}\int_X\vert f_n - f_m\vert^p d\mu = \frac{1}{\eta^p}\Vert f_n - f_m\Vert_p^p.
\end{align*}
Hence $f_n$ is a Cauchy sequence in measure. Starting from $k=1$, we choose an integer $n_k > n_{k-1}$ such that $\mu(\vert f_n - f_m\vert \geq 2^{-k}) < 2^{-k}$ for all $n,m\geq n_k$. Then we obtain a subsequence $f_{n_k}$ such that
\begin{align*}
	\mu(E_k) < 2^{-k},\ \text{where}\ E_k = \left\{\vert f_{n_{k+1}} - f_{n_k}\vert \geq 2^{-k}
	\right\}.
\end{align*}
Let $F_N=\bigcup_{k=N}^\infty E_k$, and $E=\bigcap_{N=1}^\infty F_N$. Then $\mu(F_N) < 2^{-N+1}$, and $\mu(E) = 0$. For every $x\in X\backslash E$, there exists $N$ such that $x\notin F_N$. Then for all $k>N$, $\vert f_{n_{k+1}}(x) - f_{n_k}(x)\vert < 2^{-k}$. and $\vert f_{n_l}(x)-f_{n_k}(x)\vert < 2^{-k+1}$ for all $l > k > N$. Hence $f_{n_k}(x)$ is a Cauchy sequence, which converges to some $f(x)\in\mathbb{R}$. Define $f(E)=\{0\}$, then the subsequence $f_{n_k}$ converges to $f$ almost everywhere. 

Fix $\epsilon >0$, and find $N$ such that $\Vert f_{n_k}-f_m\Vert_p < \epsilon$ for all $n_k,m\geq N$. Given $m\geq N$, apply Fatou's lemma:
\begin{align*}
	\int_X\left\vert f - f_m\right\vert^p d\mu = \int_X\lim_{k\to\infty}\left\vert f_{n_k} - f_m\right\vert^p d\mu \leq \liminf_{k\to\infty} \left\Vert f_{n_k} - f_m\right\Vert_p^p < \epsilon^p.\tag{1.7}\label{1.7}
\end{align*}
Hence $f-f_m\in L^p(X,\mathscr{A},\mu)$, and $f=(f-f_m) + f_m\in L^p(X,\mathscr{A},\mu)$. Furthermore, since $\epsilon$ is arbitrary, we have $\Vert f - f_n\Vert_p^p\to 0$, i.e. $f$ is the limit of $f_n$ in $L^p(X,\mathscr{A},\mu)$.
\end{proof}

\paragraph{Remark.} In this example, we also prove that every Cauchy sequence $f_n$ in measure has a subsequence $f_{n_k}$ that converges almost everywhere. In fact, we can prove that $f_n$ converges in measure. In the above proof, we have for all $x\in X\backslash F_k$ that
\begin{align*}
	\vert f(x) - f_{n_k}(x)\vert \leq \sum_{j=k}^\infty  \vert f_{n_{j+1}}(x) - f_{n_j}(x)\vert < 2^{-k+1}.
\end{align*}
Fix $\epsilon>0$, and choose $N$ such that $2^{-N+1}\leq\epsilon$. Then for all $k\geq N$, we have
\begin{align*}
	\mu(\vert f_{n_k}-f\vert \geq\epsilon) \leq \mu(\vert f_{n_k}-f\vert \geq 2^{-k+1}) \leq \mu(F_k) < 2^{-k+1}\to 0.
\end{align*}
Hence $f_{n_k}$ converges in measure to $f$. Now given $\eta > 0$ and $\epsilon >0$, choose $K$ such that $\mu(\vert f_{n_k}-f\vert \geq\eta/2) < \epsilon/2$ for all $k\geq K$, and $N$ such that $\mu(\vert f_{n}-f_m\vert \geq\eta/2) < \epsilon/2$ for all $n,m\geq N$. Then for all $n\geq\max\{n_K,N\}$, choose $k$ such that $n_k\geq n$, we have
\begin{align*}
	\mu(\vert f_n - f\vert \geq \eta) &\leq \mu(\vert f_{n_k} - f_n\vert + \vert f_{n_k} - f\vert \geq \eta)\\
	&\leq \mu\left(\vert f_{n_k} - f_n\vert \geq \frac{\eta}{2}\right) + \mu\left(\vert f_{n_k} - f\vert \geq \frac{\eta}{2}\right) < \epsilon.
\end{align*}
Therefore $f_n$ converges in measure.

\paragraph{Example 1.18.\label{example:1.18}} Let $(X,\mathscr{A},\mu)$ be measure space. Then the space $(L^\infty(X,\mathscr{A},\mu),\Vert\cdot\Vert_\infty)$ is a Banach space.
\begin{proof}
We pick a Cauchy sequence $f_n$ in $L^\infty(X,\mathscr{A},\mu)$, i.e. $\forall \epsilon>0$, $\exists N\in\mathbb{N}$ such that $\Vert f_n-f_m\Vert_\infty <\epsilon$ for all $n,m\geq N$. Now for each pair $m,n\in\mathbb{N}$, we define the set $E_{m,n}$ of measure zero as
\begin{align*}
	E_{m,n}=\left\{x\in X: \vert f_n(x) - f_m(x)\vert > \Vert f_n - f_m\Vert_\infty\right\},\ \mu(E_{m,n})=0.
\end{align*}
Then the union

\vspace{0.30cm}
$\displaystyle E=\bigcup_{n,m\in\mathbb{N}} E_{m,n}$\quad
\vspace{0.30cm}
of countably many sets of measure zero also has measure zero. 

For each $x\in X\backslash E$, $\vert f_n(x)-f_m(x)\vert\leq\Vert f_n-f_m\Vert_\infty$, $f_n(x)$ is a Cauchy sequence in $\mathbb{R}$, which converges to some $f(x)=\lim_{n\to\infty} f_n(x)\in\mathbb{R}$. Now fix $\epsilon >0$. By defining $f(E)=\{0\}$, we obtain a function on $f:X\to\mathbb{R}$.

Now fix $\epsilon >0$, and choose $N$ such that $\Vert f_n - f_m\Vert_\infty < \epsilon$ for all $n,m\geq N$. Then for all $x\in X\backslash E$, it holds
\begin{align*}
	\vert f_n(x) - f_m(x)\vert\leq \Vert f_n - f_m\Vert_\infty < \epsilon,\ \forall n,m\geq N
\end{align*}
Let $m\to\infty$, we have $\vert f_n(x)-f(x)\vert\leq \epsilon$ for all $x\in X\backslash E$ and $n\geq N$. Then $\Vert f_n-f\Vert_\infty \leq \epsilon$. Moreover,
\begin{align*}
	\sup_{x\in X\backslash E} \vert f(x)\vert\leq \sup_{x\in X\backslash E} \vert f(x)-f_n(x)\vert + \sup_{x\in X\backslash E} \vert f_n(x)\vert \leq \epsilon + \Vert f_n\Vert_\infty < \infty.
\end{align*}
Hence $f\in L^\infty(X,\mathscr{A},\mu)$. Since $\epsilon$ is arbitrary, $\Vert f_n-f\Vert_\infty\to 0$, and $f_n$ converges to $f$ in $L^\infty(X,\mathscr{A},\mu)$.
\end{proof}

\newpage
\subsubsection{Inner Product Spaces and Hilbert Spaces}
\paragraph{Definition 1.19\label{def:1.19}} (Inner product spaces). Let $H$ be a real (or complex) vector space. A \textit{semi-inner product} on $H$ is defined as a function $\langle\cdot,\cdot\rangle:H\times H\to\mathbb{R}$ (or $\mathbb{C}$) satisfying the following conditions:
\begin{itemize}
	\item[(i)] (Positive semi-definiteness). $\langle x,x\rangle\geq 0$ for all $x\in H$;
	\item[(ii)] (Linearity for the first variable). For all $\alpha,\beta\in\mathbb{R}$ (or $\mathbb{C}$) and all $x,y,z\in H$, \vspace{0.30cm}
	
	$\hspace{5.9cm}\langle\alpha x+\beta y,z\rangle = \alpha\langle x,z\rangle + \beta\langle y,z\rangle;$
	
	\vspace{0.30cm}
    \item[(iii)] (Conjugate symmetry). $\langle x,y\rangle = \overline{\langle y,x\rangle}$ for all $x,y\in H$.
\end{itemize}
Furthermore, if $\langle\cdot,\cdot\rangle$ satisfies positive-definiteness, i.e. $\langle x,x\rangle = 0$ only if $x=0$, then it becomes an \textit{inner product} on $H$. A real (or complex) vector space $H$ equipped with an inner product $\langle\cdot,\cdot\rangle$ is called a real (or complex) \textit{inner product space}, or a \textit{pre-Hilbert space}.

\paragraph{Remark.} If $H$ is a real inner product space, we can drop the conjugate in (iii) and obtain the linearity for both variables. If $H$ is complex, by (ii) and (iii), we have anti-linearity for the second variable: \vspace{0.30cm}

$\hspace{5.9cm}\langle z,\alpha x+\beta y\rangle = \overline{\alpha}\langle z,x\rangle + \overline{\beta}\langle z,y\rangle.$

\paragraph{Example 1.20.\label{example:1.20}} Following are some instances for inner product spaces.
\begin{itemize}
	\item[(i)] Let $\mathbf{x}=(x_1,\cdots,x_n),\mathbf{y}=(y_1,\cdots,y_n)\in\mathbb{C}^n$. Define
	\begin{align*}
		\langle\mathbf{x},\mathbf{y}\rangle = \sum_{j=1}^n x_j\overline{y}_j.
	\end{align*}
    Then $\langle\cdot,\cdot\rangle$ is an inner product on $\mathbb{C}^n$.
    \item[(ii)] Let $(X,\mathscr{A},\mu)$ be a measure space. For $f,g\in L^2(X,\mathscr{A},\mu)$, define
    \begin{align*}
    	\langle f,g\rangle = \int_X f(x)\overline{g(x)}\,d\mu(x).
    \end{align*}
    Then $\langle\cdot,\cdot\rangle$ is an inner product on $(X,\mathscr{A},\mu)$.
\end{itemize}

\paragraph{Lemma 1.21\label{lemma:1.21}} (Cauchy-Schwarz inequality). Let $\langle\cdot,\cdot\rangle$ be a semi-inner product on a vector space $H$. Then for all $x,y\in H$, it holds
\begin{align*}
	\vert\langle x,y\rangle\vert^2\leq\langle x,x\rangle \langle y,y\rangle.
\end{align*}
\begin{proof}
Let $x,y\in H$. Then for all $t\in\mathbb{R}$ (or $\mathbb{C}$),
\begin{align*}
	0\leq\langle x+ty, x+ty\rangle = \langle x, x\rangle + 2\Re(t\langle y,x\rangle) + \vert t\vert^2\langle y, y\rangle.
\end{align*}
If $\langle y,y\rangle\neq 0$, set $t=-\frac{\langle x,y\rangle}{\langle y,y\rangle}$. Then
\begin{align*}
	\langle x, x\rangle - 2\frac{\vert\langle x,y\rangle\vert^2}{\langle y, y\rangle} + \frac{\vert\langle x,y\rangle\vert^2}{\langle y, y\rangle} \geq 0\ \Rightarrow\ \vert\langle x,y\rangle\vert^2\leq\langle x,x\rangle \langle y,y\rangle.
\end{align*}
If $\langle y,y\rangle\geq 0$, set $t=-\frac{1}{2}\beta\langle x,y\rangle$, where $\beta>0$. Then
\begin{align*}
	\langle x, x\rangle - \beta\vert\langle y,x\rangle\vert^2\geq 0,\ \forall\beta > 0,
\end{align*}
which implies $\langle x,y\rangle=0$. Since $x$ is arbitrary, we have $\langle x,y\rangle=0$ for all $x\in H$.
\end{proof}

\paragraph{Lemma 1.22\label{lemma:1.22}} (Induced norm). Let $\langle\cdot,\cdot\rangle$ be an inner product on $H$. Define $\Vert x\Vert=\sqrt{\langle x,x\rangle}$ for all $x\in H$, then $\Vert\cdot\Vert$ is a norm on $H$.
\begin{proof}
	Check the four properties in \hyperref[def:1.13]{Definition 1.13}.
\end{proof}

\paragraph{Remark.} Following \hyperref[lemma:1.22]{Lemma 1.22}, we can rewrite Cauchy-Schwarz inequality (\hyperref[lemma:1.21]{Lemma 1.21}) as
\begin{align*}
	\vert\langle x,y\rangle\vert \leq \Vert x\Vert\left\Vert y\right\Vert.
\end{align*}
Using this inequality, we can obtain continuity of inner products.

\paragraph{Lemma 1.23\label{lemma:1.23}} (Continuity of inner products). Let $\langle\cdot,\cdot\rangle:H\times H\to\mathbb{R}$ (or $\mathbb{C}$) be an inner product on $H$. Then $\langle\cdot,\cdot\rangle$ is a continuous map.

\begin{proof}
	Let $(x_n)$ and $(y_n)$ be sequences of points of $H$ that converge to $x\in H$ and $y\in H$, respectively. Then
	\begin{align*}
		\left\vert\langle x_n,y_n\rangle - \langle x,y\rangle\right\vert &\leq \left\vert\langle x_n,y_n\rangle - \langle x,y_n\rangle\right\vert + \left\vert\langle x,y_n\rangle - \langle x,y\rangle\right\vert\\
		&\leq \left\Vert x_n - x\right\Vert\left\Vert y_n\right\Vert + \left\Vert x\right\Vert\left\Vert y_n - y\right\Vert\to 0.
	\end{align*}
    Thus we complete the proof.
\end{proof}

It is seen that in a vector space, an inner product automatically determines a norm. Conversely, if a norm is induced by an inner product, we can also recover the inner product from the norm.

\paragraph{Lemma 1.24\label{lemma:1.24}} (Polarization identity). Let $H$ be an inner product space.
\begin{itemize}
	\item[(i)] If $H$ is real, then for all $x,y\in H$,
	\begin{align*}
		\langle x,y\rangle = \frac{1}{4}\left(\Vert x+y\Vert^2 - \Vert x-y\Vert^2\right);\tag{1.8}\label{eq:1.8}
	\end{align*}
	\item[(ii)] If $H$ is complex, then for all $x,y\in H$,
	\begin{align*}
		\langle x,y\rangle = \frac{1}{4}\left(\Vert x+y\Vert^2 + \i\Vert x+\i y\Vert^2 - \Vert x-y\Vert^2 - \i\Vert x-\i y\Vert^2\right) = \frac{1}{4}\sum_{k=0}^3\i^k\Vert x+\i^k y\Vert^2.\tag{1.9}\label{eq:1.9}
	\end{align*}
\end{itemize}
\begin{proof}
	By direct calculation.
\end{proof}

We also introduce a necessary and sufficient condition for a norm to be induced by an inner product.
\paragraph{Lemma 1.25\label{lemma:1.25}} (Parallelogram law). Let $(X,\Vert\cdot\Vert)$ be a normed space. Then $\Vert\cdot\Vert$ is induced by an inner product on $X$ if and only if the parallelogram law holds for $\Vert\cdot\Vert$:
\begin{align*}
	\Vert x+y\Vert^2 + \Vert x-y\Vert^2 = 2\left(\Vert x\Vert^2 + \Vert y\Vert^2\right).\tag{1.10}\label{eq:1.10}
\end{align*}
\begin{proof}
``$\Rightarrow$'': By direct calculation.

``$\Leftarrow$'': We use the polarization identity (\hyperref[lemma:1.24]{Lemma 1.24}) to define a binary operation $\langle\cdot,\cdot\rangle$ on $X$, and verify that $\langle\cdot,\cdot\rangle$ is an inner product. We work with the complex case, and define $\langle\cdot,\cdot\rangle$ by \hyperref[eq:1.9]{(1.9)}. Let $x,y\in X$. Then we can obtain positive definiteness and conjugate symmetry:
\begin{align*}
	\langle x,x\rangle = \frac{1}{4}\left(\Vert 2x\Vert^2 + \i\Vert(1+\i)x\Vert^2 -\Vert 0x\Vert^2 - \i\Vert (1-\i)x\Vert^2 \right) = \Vert x\Vert^2,
\end{align*}
\begin{align*}
	\overline{\langle y,x\rangle} &= \frac{1}{4}\left(\Vert y+x\Vert^2 - \i\Vert y+\i x\Vert^2 - \Vert y-x\Vert^2 + \i\Vert y-\i x\Vert^2\right)\\
	&= \frac{1}{4}\left(\Vert x+y\Vert^2 - \i\Vert x-\i y\Vert^2 - \Vert x-y\Vert^2 + \i\Vert x +\i y\Vert^2\right) = \langle x,y\rangle.
\end{align*}
Now we verify the additivity. For $x,y,z\in X$, by \hyperref[eq:1.10]{(1.10)}, we have
\begin{align*}
	\Vert x+y+z\Vert^2 &= \frac{1}{2}\left(\Vert (x+z)+y\Vert^2 + \Vert (y+z)+x\Vert^2\right)\\
	&= \Vert x+z\Vert^2 + \Vert y\Vert^2 - \frac{1}{2}\Vert x+z-y\Vert^2 + \Vert y+z\Vert^2 + \Vert x\Vert^2 - \frac{1}{2}\Vert y+z-x\Vert^2.\tag{1.11}\label{eq:1.11}
\end{align*}
Replace $z$ by $-z$ in \hyperref[eq:1.11]{(1.11)}, then we have
\begin{align*}
	\Vert x+y+z\Vert^2 - \Vert x+y-z\Vert^2 = \Vert x+z\Vert^2 - \Vert x-z\Vert^2 - \Vert y+z\Vert^2 - \Vert y-z\Vert^2 \tag{1.12}\label{eq:1.12}
\end{align*}
Replace $z$ by $\i z$ in \hyperref[eq:1.12]{(1.12)}, then we have
\begin{align*}
	\Vert x+y+\i z\Vert^2 - \Vert x+y-\i z\Vert^2 = \Vert x+\i z\Vert^2 - \Vert x-\i z\Vert^2 - \Vert y + \i z\Vert^2 - \Vert y-\i z\Vert^2 \tag{1.13}\label{eq:1.13}
\end{align*}
Combining \hyperref[eq:1.12]{(1.12)} and \hyperref[eq:1.13]{(1.13)}, we obtain
\begin{align*}
	\langle x + y, z\rangle &= \frac{1}{4}\left(\Vert x+y+z\Vert^2  -\Vert x+y-z\Vert^2 +\i\Vert x+y+\i z\Vert^2 - \i\Vert x+y-\i z\Vert^2 \right)\\
	&= \frac{1}{4}\sum_{k=1}^3 \i^k\Vert x+\i^k z\Vert^2 + \frac{1}{4}\sum_{k=1}^3 \i^k\Vert y+\i^k z\Vert^2 = \langle x,z\rangle + \langle y,z\rangle.
\end{align*}
Now it remains to show the scalar multiplicativity. Given the additivity, we have that for every $n,m\in\mathbb{N}$,
\begin{align*}
	\langle nx, z\rangle = \underbrace{\langle x,z\rangle + \cdots + \langle x,z\rangle}_{n} = n\langle x,z\rangle\ \Rightarrow\ \langle m^{-1} x,z\rangle = \frac{1}{m}\langle x,z\rangle\ \Rightarrow\  \left\langle\frac{n}{m}x,z\right\rangle = \frac{n}{m}\left\langle x,z\right\rangle.
\end{align*}
Clearly, we have $\langle\i x,z\rangle = \i\langle x,z\rangle$. Then for every $\lambda\in\mathbb{Q}+\i\mathbb{Q}=\{p+\i q:p,q\in\mathbb{Q}\}$, we have $\langle\lambda x,z\rangle = \lambda\langle x,z\rangle$. 
\vspace{0.12cm}

Next we prove the Cauchy-Schwarz inequality. For $x,z\in X$ and $\lambda\in\mathbb{Q}+\i\mathbb{Q}$,
\begin{align*}
	0\leq\langle x+\lambda z,x+\lambda z\rangle\langle z,z\rangle &= \Vert x\Vert^2\Vert z\Vert^2 + 2\Re\left(\lambda\left\langle z,x\right\rangle\Vert z\Vert^2\right) + \vert \lambda\vert^2\Vert z\Vert^4\\
	&= \Vert x\Vert^2\Vert z\Vert^2 - \vert\langle x,z\rangle\vert^2 + \left\vert\lambda\Vert z\Vert^2 - \langle x,z\rangle\right\vert^2,
\end{align*}
which implies
\begin{align*}
	\vert\langle x,z\rangle\vert^2 - \Vert x\Vert^2\Vert z\Vert^2\leq \inf_{\lambda\in\mathbb{Q}+\i\mathbb{Q}}\left\vert\lambda\Vert z\Vert^2 - \langle x,z\rangle\right\vert^2 = 0.\tag{1.14}\label{eq:1.14}
\end{align*}
Now fix $\alpha\in\mathbb{C}=\mathbb{R}+\i\mathbb{R}$. For all $\lambda\in\mathbb{Q}+\i\mathbb{Q}$, we have
\begin{align*}
	\vert\langle \alpha x,z\rangle - \alpha\langle x,z\rangle\vert = \vert\langle (\alpha-\lambda)x,z\rangle - (\alpha-\lambda)\langle x,z\rangle\vert\leq 2\left\vert \alpha - \lambda\right\vert\left\Vert x\right\Vert\left\Vert z\right\Vert,
\end{align*}
where the inequality follows from \hyperref[eq:1.14]{(1.14)}. By taking infimum of the right hand side, which is zero, we have $\langle \alpha x,z\rangle = \alpha\langle x,z\rangle$. Then we complete the proof.
\end{proof}

\paragraph{Review.} Let $H$ be an inner product space, then we obtain a norm $\Vert\cdot\Vert$ on $H$ by defining $\Vert x\Vert = \sqrt{\langle x,x\rangle}$ for all $x\in H$. Following this, a metric $d$ is determined by $d(x,y)=\Vert x-y\Vert$ for all $x,y\in H$. This metric automatically induces a metric topology on $H$ for which the basis is the collection of all open balls in $H$.

\paragraph{Definition 1.26\label{def:1.26}} (Hilbert spaces). Let $H$ be an inner product space. If $H$ is complete under the metric induced by its inner product, then $H$ is said to be a \textit{Hilbert space}.

\paragraph{Remark.} In other words, a complete inner product space is Hilbert. That is, every Cauchy sequence in $H$, in sense of the induced norm $\Vert\cdot\Vert=\sqrt{\langle\cdot,\cdot\rangle}$, converges in $H$.

\paragraph{} Now we introduce the definition of orthogonality in inner product spaces.

\paragraph{Definition 1.27\label{def:1.27}} (Orthogonality). Let $H$ be a inner product space.
\begin{itemize}
	\item[(i)] Let $x$ and $y$ be two vectors in $H$. Then $x$ is said to be \textit{orthogonal to} $y$ if $\langle x,y\rangle = 0$, and we write $x\perp y$. By direct calculation, we have the Pythagorean theorem for $x\perp y$:
	\begin{align*}
		\Vert x+y\Vert^2 = \Vert x\Vert^2 + \Vert y\Vert^2.
	\end{align*}
	\item[(ii)] Let $\mathscr{H}$ be a collection of non-zero vectors in $H$. If for each pair of distinct vectors $x\neq y$ in $\mathscr{H}$, we have $x\perp y$, then $\mathscr{H}$ is said to be an \textit{orthogonal system}.
	\item[(iii)] Furthermore, if $\Vert x\Vert=1$ for all $x\in\mathscr{H}$, then $\mathscr{H}$ is said to be an \textit{orthonormal system}.
	\item[(iv)] Let $\mathscr{H}$ be an orthonormal system in $H$. Then the set of numbers
	\begin{align*}
		\left\{\langle x,e\rangle,e\in\mathscr{H}\right\}
	\end{align*}
    is said to be the \textit{Fourier coefficients} of $x$ relative to $\mathscr{H}$. If $e\in\mathscr{H}$, then $\langle x,e\rangle$ is called the Fourier coefficient of $x$ relative to $e$.
\end{itemize}

\paragraph{Example 1.28\label{example:1.28}} Following are some examples of orthogonal families.
\vspace{0.1cm}
\begin{itemize}
\item[(i)] Consider the $n$-dimensional Euclidean space $\mathbb{R}^n$. The vectors
\begin{align*}
	e_1=(1,0,\cdots,0),\ e_2=(0,1,\cdots,0),\ \cdots,\ e_n=(0,0,\cdots,1)
\end{align*}
form an orthonormal system on $\mathbb{R}^n$.
\vspace{0.1cm}
\item[(ii)] Consider the space $L^2([0,2\pi])$ of real-valued square-integrable functions on $[0,2\pi]$. Define inner product $$\langle f,g\rangle =\frac{1}{2\pi}\int_0^{2\pi} f(x)g(x)\,dx,\ f,g\in L^2([0,2\pi]).$$ The functions
\begin{align*}
	\left\{1,\sqrt{2}\cos x,\sqrt{2}\sin x,\sqrt{2}\cos 2x,\sqrt{2}\sin 2x,\cdots,\sqrt{2}\cos nx,\sqrt{2}\sin nx,\cdots\right\}
\end{align*}
form an orthonormal system on $L^2([0,2\pi])$. Furthermore, for a function $f\in L^2([0,2\pi])$, the Fourier coefficients are
\begin{align*}
	a_0 &= \langle f,1\rangle = \frac{1}{2\pi}\int_0^{2\pi} f(t)\,dt,\\ a_n &= \langle f,\sqrt{2}\cos nx\rangle = \frac{1}{\sqrt{2}\pi}\int_0^{2\pi} f(t)\cos nx\,dt,\ n\geq 1,\\
	b_n &= \langle f,\sqrt{2}\sin nx\rangle = \frac{1}{\sqrt{2}\pi}\int_0^{2\pi} f(t)\sin nx\,dt,\ n\geq 1.
\end{align*}
\vspace{0.1cm}
\item[(iii)] Consider the space $L^2([0,2\pi],\mathbb{C})$ of complex-valued square-integrable functions on $[0,2\pi]$. Define inner product $$\langle f,g\rangle =\frac{1}{2\pi}\int_0^{2\pi} f(x)g(x)\,dx,\ f,g\in L^2([0,2\pi],\mathbb{C}).$$ The functions $\{\mathrm{e}^{\i nx},n\in\mathbb{Z}\}$ form an orthonormal basis on $L^2([0,2\pi],\mathbb{C})$. Furthermore, the Fourier coefficients of $f\in L^2([0,2\pi],\mathbb{C})$ are
\begin{align*}
	c_n = \int_0^{2\pi}\mathrm{e}^{-\i nx}f(x)\,dx,\ n\in\mathbb{Z}.
\end{align*}
\end{itemize}

\paragraph{Review: Summation over arbitrary index sets.} Let $\Lambda$ be an index set, and let $\{c_\lambda:\lambda\in\Lambda\}$ be a collection such that $c_\lambda\geq 0$ for all $\lambda\geq\Lambda$. We pick a set $\mathscr{F}(\Lambda)=\{F\subset\Lambda: F\ \text{is finite}\}$, and we define a preorder on $\mathscr{F}$ by inclusion: $F_1\preceq F_2\overset{\mathrm{def.}}{\Leftrightarrow} F_1\subset F_2$. Then $\mathscr{F}$ becomes a directed set since every pair $F_1,F_2$ of elements of $\mathscr{F}$ has an upper bound $F_1\cup F_2\in \mathscr{F}$. The general definition of the summation $\sum_{\lambda\in\Lambda} c_\lambda$ is given by the following limit, provided it exists:
\begin{align*}
	\sum_{\lambda\in\Lambda} c_\lambda = \lim_{F\in\mathscr{F}(\Lambda)}\sum_{\lambda\in F} c_\lambda.
\end{align*}
That is,
\begin{align*}
	\sum_{\lambda\in\Lambda} c_\lambda = c\ \Leftrightarrow\ \forall\epsilon > 0,\ \exists F_0\in\mathscr{F}(\Lambda)\ \text{such that}\ \forall F\in\mathscr{F}(\Lambda)\ \text{and}\ F\supset F_0,\ \left\vert\sum_{\lambda\in F}c_\lambda - c\right\vert\leq\epsilon.
\end{align*}
\paragraph{Claim 1.29.\label{claim:1.29}} If $\sum_{\lambda\in\Lambda}c_\lambda$ converges, then $\{c_\lambda:\lambda\in\Lambda\}$ has at most countably many non-zeros.

\begin{proof}
Let $\sum_{\lambda\in\Lambda}c_\lambda = c$. For all $n\in\mathbb{N}$, consider the set
\begin{align*}
	F_n:=\left\{\lambda\in\Lambda:c_\lambda\geq\frac{1}{n}\right\},
\end{align*}
Then $F_1\subset F_2\subset\cdots\subset F_n\subset F_{n+1}\subset\cdots$ form a chain on $\mathscr{F}$, and $\sum_{\lambda\in F_n}c_\lambda$ is increasing. Moreover,
\begin{align*}
	c\geq \sum_{\lambda\in F_n} c_\lambda \geq \frac{1}{n}\vert F_n\vert\ \Rightarrow\ \vert F_n\vert \leq nc < \infty.
\end{align*}
Note that the set of all non-zero elements is given by
\begin{align*}
	\left\{\lambda\in\Lambda:c_\lambda\neq 0\right\} = \bigcup_{n=1}^\infty F_n,
\end{align*}
which is at most countable.
\end{proof}

\paragraph{Theorem 1.29\label{thm:1.29}} (Bessel's inequality). Let $H$ be an inner product space, and let $\mathscr{H}=\{e_\lambda:\lambda\in\Lambda\}$ be an orthonormal system on $H$. Then for all $x\in H$,
\begin{align*}
	\sum_{\lambda\in\Lambda}\left\vert\left\langle x,e_\lambda\right\rangle\right\vert^2\leq \Vert x\Vert^2.
\end{align*}
\begin{proof}
Let $F$ be a finite subset of $\Lambda$. Consider
\begin{align*}
	x=\underbrace{\left(x - \sum_{\lambda\in F}\left\langle x,e_\lambda\right\rangle e_\lambda\right)}_{=:y} + \underbrace{\sum_{\lambda\in F}\left\langle x,e_\lambda\right\rangle e_\lambda}_{=:z},
\end{align*}
we have
\begin{align*}
	\langle y,z\rangle = \sum_{\lambda\in F}\left\vert\left\langle x,e_\lambda\right\rangle\right\vert^2 - \sum_{\lambda\in F}\sum_{\nu\in F}\left\langle x,e_\lambda\right\rangle\overline{\left\langle x,e_\nu\right\rangle}\underbrace{\left\langle e_\lambda,e_\nu\right\rangle}_{=\delta_{\lambda\nu}} = 0.
\end{align*}
By Pythagorean theorem, $\Vert x\Vert^2 = \Vert y\Vert^2 + \Vert z\Vert^2 \geq \Vert z\Vert^2$, that is,
\begin{align*}
	\sum_{\lambda\in F}\left\vert\left\langle x,e_\lambda\right\rangle\right\vert^2\leq \Vert x\Vert^2.
\end{align*}
By \hyperref[claim:1.29]{Claim 1.29}, the set $F_n=\left\{\lambda\in\Lambda:\left\vert\left\langle x,e_\lambda\right\rangle\right\vert\geq n^{-1}\right\}$ has no more than $n^2\Vert x\Vert^2$ elements, and the set of nonzero Fourier coefficients $F_\infty=\bigcup_{n=1}^\infty F_n = \left\{\lambda\in\Lambda:\langle x,e_\lambda\rangle\neq 0\right\}$ is at most countable. Hence
\begin{align*}
	\sum_{\lambda\in \Lambda}\left\vert\left\langle x,e_\lambda\right\rangle\right\vert^2 = \sum_{\lambda\in F_\infty}\left\vert\left\langle x,e_\lambda\right\rangle\right\vert^2 = \lim_{n\to\infty}\sum_{\lambda\in F_n}\left\vert\left\langle x,e_\lambda\right\rangle\right\vert^2\leq\Vert x\Vert^2,
\end{align*}
which is the desired result.
\end{proof}

\paragraph{Corollary 1.30.\label{cor:1.30}} Let $\{e_n,n\in\mathbb{N}\}$ be an orthonormal system on $H$. Then for all $x\in H$,
\begin{align*}
	\lim_{n\to\infty}\langle x,e_n\rangle = 0.
\end{align*}

\paragraph{Remark.} Now we let $H$ be a Hilbert space. Fix $x\in H$, we proved that $\left\{e_\lambda\in\mathscr{H}:\langle x,e_\lambda\rangle\neq 0\right\}$ is at most countable. If it is countable, we can write it as a sequence $\{e_{\lambda_1},e_{\lambda_2},\cdots,e_{\lambda_n},\cdots\}$. According to Bessel's inequality, we have $\sum_{n=1}^\infty\left\vert\left\langle x,e_{\lambda_n}\right\rangle\right\vert^2 < \infty$. Then for $m,n\in\mathbb{N}$,
\begin{align*}
	\left\Vert\sum_{k=m+1}^n\left\langle x,e_{\lambda_k}\right\rangle e_{\lambda_k}\right\Vert^2 = \sum_{k=m+1}^n\left\vert\left\langle x,e_{\lambda_k}\right\rangle\right\vert^2\to 0\ \ \text{as}\ \ n,m\to\infty.
\end{align*}
Thus we obtain a Cauchy sequence $\left\{\sum_{k=1}^n\left\langle x,e_{\lambda_k}\right\rangle e_{\lambda_k}\right\}_{n=1}^\infty$ in $H$, which converges to some vector $y$ in $H$. Intuitively, the vector does not depend on our choice of permutation $\{\lambda_1,\lambda_2,\cdots,\lambda_n,\cdots\}$.

Let $\{e_{\sigma_1},e_{\sigma_2},\cdots,e_{\sigma_n},\cdots\}$ be another permutation of $\{e_\lambda\in\mathscr{H}:\langle x,e_\lambda\rangle\neq 0\}$. Following the above procedure, $\{\sum_{k=1}^n\langle x,e_{\sigma_k}\rangle e_{\sigma_k}\}_{n=1}^\infty$ is a Cauchy sequence in $H$, which converges to some $y^\prime\in H$. We fix $\epsilon >0$, and choose $N$ such that $\sum_{n=N+1}^\infty\left\vert\left\langle x,e_{\lambda_n}\right\rangle\right\vert^2 < \epsilon^2/4$. Since $\{e_{\sigma_1},e_{\sigma_2},\cdots,e_{\sigma_n},\cdots\}=\{e_{\lambda_1},e_{\lambda_2},\cdots,e_{\lambda_n},\cdots\}$, there exists $M\geq N$ such that $\Lambda_N:=\{\lambda_1,\cdots,\lambda_N\}\subset\{\sigma_1,\cdots,\sigma_M\}$. Then
\begin{align*}
	\left\Vert y - \sum_{m=1}^M\left\langle x,e_{\sigma_m}\right\rangle e_{\sigma_m}\right\Vert &\leq \left\Vert y - \sum_{n=1}^N\left\langle x,e_{\lambda_n}\right\rangle e_{\lambda_n}\right\Vert + \left\Vert\sum_{m=1}^M\left\langle x,e_{\sigma_m}\right\rangle e_{\sigma_m} - \sum_{n=1}^N\left\langle x,e_{\lambda_n}\right\rangle e_{\lambda_n}\right\Vert\\
	&= \sqrt{\sum_{n=N+1}^\infty\left\vert\left\langle x,e_{\lambda_n}\right\rangle\right\vert^2} + \sqrt{\sum_{m=1,\sigma_m\notin\Lambda_N}^M\left\vert\left\langle x,e_{\sigma_m}\right\rangle\right\vert^2}\\
	&\leq 2\sqrt{\sum_{n=N+1}^\infty\left\vert\left\langle x,e_{\lambda_n}\right\rangle\right\vert^2} < \epsilon.
\end{align*}
Let $M\to\infty$, then $\Vert y-y^\prime\Vert < \epsilon$. Since $\epsilon$ is arbitrary, we have $\Vert y-y^\prime\Vert = 0$, which implies $y=y^\prime$. As a result, we can define
\begin{align*}
	\sum_{\lambda\in\Lambda}\left\langle x,e_\lambda\right\rangle e_\lambda := \lim_{n\to\infty}\sum_{k=1}^n \left\langle x,e_{\lambda_k}\right\rangle e_{\lambda_k}.
\end{align*}
By definition, we have
\begin{align*}
	\left\Vert\sum_{\lambda\in\Lambda}\left\langle x,e_\lambda\right\rangle e_\lambda\right\Vert = \lim_{n\to\infty}\sum_{k=1}^n \left\vert\left\langle x,e_{\lambda_k}\right\rangle\right\vert^2 = \sum_{\lambda\in\Lambda}\left\vert\left\langle x,e_{\lambda}\right\rangle\right\vert^2.
\end{align*}
We use
\begin{align*}
	\mathrm{span}\left\{e_\lambda,\lambda\in\Lambda\right\} := \left\{\sum_{k=1}^n \alpha_k e_{\lambda_k}:n\in\mathbb{N},\ \alpha_1,\cdots,\alpha_n\in\mathbb{C},\ \lambda_1,\cdots,\lambda_n\in\Lambda\right\}
\end{align*}
to denote the vector space spanned by orthonormal system $\{e_\lambda,\lambda\in\Lambda\}$, and use $\overline{\mathrm{span}}\left\{e_\lambda,\lambda\in\Lambda\right\}$ to denote its closure. By the above discussion, $\sum_{\lambda\in\Lambda}\left\langle x,e_\lambda\right\rangle e_\lambda\in\overline{\mathrm{span}}\left\{e_\lambda,\lambda\in\Lambda\right\}$.

\paragraph{Theorem 1.31\label{thm:1.31}} (Orthonormal basis). Let $H$ be a Hilbert space, and let $\mathscr{H}=\{e_\lambda:\lambda\in\Lambda\}$ be an orthonormal system on $H$. The following are equivalent:
\begin{itemize}
	\item[(i)] For all $x\in H$, $x=\sum_{\lambda\in\Lambda}\left\langle x,e_\lambda\right\rangle e_\lambda$;
	\item[(ii)] $\overline{\mathrm{span}}\left\{e_\lambda,\lambda\in\Lambda\right\}=H$;
	\item[(iii)] For $x\in H$, $x\perp e_\lambda$ for all $\lambda\in\Lambda$ only if $x=0$;
	\item[(iv)] (Parseval equality). For all $x\in H$, $\Vert x\Vert^2 = \sum_{\lambda\in\Lambda}\left\vert\left\langle x,e_{\lambda}\right\rangle\right\vert^2$.
\end{itemize}
If $\mathscr{H}$ satisfies the above conditions, then $\mathscr{H}$ is said to be an \textit{orthonormal basis} of $H$.
\begin{proof}
(i) $\Rightarrow$ (ii): Clearly, $\overline{\mathrm{span}}\left\{e_\lambda,\lambda\in\Lambda\right\}\subset H$. The other direction follows from the above Remark.
\vspace{0.1cm}

(ii) $\Rightarrow$ (iii): Let $x\in H$ be such that $\langle x,e_\lambda\rangle=0$ for all $\lambda\in\Lambda$. Since $x\in H=\overline{\mathrm{span}}\left\{e_\lambda,\lambda\in\Lambda\right\}$, there exists sequence $x_n$ of vectors in $\mathrm{span}\left\{e_\lambda,\lambda\in\Lambda\right\}$ such that $x_n\to x$. By continuity of inner product,
\begin{align*}
	\langle x,x\rangle = \lim_{n\to\infty}\langle x,x_n\rangle = 0.
\end{align*}

(iii) $\Rightarrow$ (i): Given $x\in H$, let $y=\sum_{\lambda\in\Lambda}\left\langle x,e_\lambda\right\rangle e_\lambda$. Then $x-y\perp e_\lambda$ for all $\lambda\in\Lambda$, which implies $x-y=0$.
\vspace{0.1cm}

(i) $\Leftrightarrow$ (iv): We only prove (iv) $\Rightarrow$ (i), the other direction is clear. Given $x\in H$, let $y=\sum_{\lambda\in\Lambda}\left\langle x,e_\lambda\right\rangle e_\lambda$. Then $\langle x-y,y\rangle = 0$. By Pythagorean theorem, $\Vert x-y\Vert^2 = \Vert x\Vert^2 - \Vert y\Vert^2 = 0$, which implies $x=y$.
\end{proof}

Following are some examples for orthonormal basis.

\paragraph{Example 1.32.\label{example:1.32}} Recall \hyperref[example:1.28]{Example 1.28 (ii)}. The set $$\mathscr{H}=\left\{1,\sqrt{2}\cos x,\sqrt{2}\sin x,\sqrt{2}\cos 2x,\sqrt{2}\sin 2x,\cdots,\sqrt{2}\cos nx,\sqrt{2}\sin nx,\cdots\right\}$$ is an orthonormal basis of $L^2([0,2\pi])$.
\begin{proof}
Following \hyperref[thm:1.31]{Theorem 1.31}, it suffices to show that $\overline{\mathrm{span}}\,\mathscr{H} = L^2([0,2\pi])$. Denote by
\begin{align*}
	C_c^\infty(0,2\pi):= \left\{f\in C([0,2\pi]):f\ \text{is smooth},\overline{\{f\neq 0\}}\subset(0,2\pi)\right\}
\end{align*}
the set of all smooth functions that have compact support in $(0,2\pi)$. Clearly, $C_c^\infty(0,2\pi)\subset L^2([0,2\pi])$. Furthermore, for any $f\in C_c^\infty(0,2\pi)$, the Fourier coefficients are given by
\begin{align*}
	a_n(f) &= \frac{1}{2\pi}\int_0^{2\pi} f(t)\sqrt{2}\cos nt\,dt = -\frac{1}{\sqrt{2}\pi}\int_0^{2\pi} f^{\prime\prime}(t)\cos nt\,dt\ \Rightarrow\ \vert a_n(f)\vert\leq\frac{\Vert f^{\prime\prime}\Vert_\infty}{n^2},\\
	b_n(f) &= \frac{1}{2\pi}\int_0^{2\pi} f(t)\sqrt{2}\sin nt\,dt = -\frac{1}{\sqrt{2}\pi}\int_0^{2\pi} f^{\prime\prime}(t)\sin nt\,dt,\ \Rightarrow\ \vert b_n(f)\vert\leq\frac{\Vert f^{\prime\prime}\Vert_\infty}{n^2}.
\end{align*}
Then the partial sum
\begin{align*}
	(S_nf)(x) = \frac{1}{2\pi}\int_0^{2\pi}f(t)\,dt + \sum_{k=1}^n\left(a_n(f)\sqrt{2}\cos nx + b_n(f)\sqrt{2}\sin nx\right)
\end{align*}
converges uniformly on $[0,2\pi]$. By Dini-Lipschitz criterion, $S_nf$ converges uniformly to $f$, and $\Vert f-S_nf\Vert_2\to 0$. Hence $f\in\overline{\mathrm{span}}\,\mathscr{H}$, and $L^2([0,2\pi]) = \overline{C_c^\infty(0,2\pi)} \subset\overline{\mathrm{span}}\,\mathscr{H}$.
\end{proof}

The following theorem reveals the existence of an orthonormal basis for a Hilbert space.
\paragraph{Theorem 1.33.\label{thm:1.33}} Suppose $A$ is an orthonormal system on a Hilbert space $H$. Then there exists an orthonormal basis of $\mathscr{H}$ such that $\mathscr{H}\supset A$. In other words, $A$ can be expanded to an orthonormal basis of $H$.
\begin{proof}
As you can imagine, we use Zorn's lemma. Denote
\begin{align*}
	\mathcal{F} = \left\{B:B\ \text{is an orthonormal system on}\ H,\ B\supset A\right\},
\end{align*}
and order the elements of $\mathcal{F}$ by inclusion: $B\preceq B^\prime$ if $B\subset B^\prime$. Let $\mathcal{M}=\{B_\lambda,\lambda\in\Lambda\}$ be a totally ordered subset of $\mathcal{F}$. Then the union
\begin{align*}
	B=\bigcup_{\lambda\in\Lambda} B_\lambda
\end{align*}
is an orthonormal system on $H$. To see this, choose distinct $x,y\in B$, and assume $f\in B_{\lambda_1},g\in B_{\lambda_2}$. Since $\mathcal{M}$ is totally ordered, we have either $B_{\lambda_1}\subset B_{\lambda_2}$ or $B_{\lambda_1}\supset B_{\lambda_2}$, which implies that $f$ and $g$ belongs to the same orthonormal system. Clearly, $B\supset A$. Then $B$ is an upper bound of $\mathcal{M}$ in $\mathcal{F}$, and we can apply Zorn's lemma.

Let $\mathscr{H}$ be a maximal element in $\mathcal{F}$, then $\mathscr{H}$ is an orthonormal basis. Otherwise, there exists $x\in H\backslash\{0\}$ such that $\langle x,e_\lambda\rangle=0$ for all $e_\lambda\in\mathscr{H}$, which implies $\mathscr{H}\cup\left\{x/\Vert x\Vert\right\}\in\mathcal{F}$, contradicting the maximality of $\mathscr{H}$!
\end{proof}

\subsubsection{The Projection Theorem}
\paragraph{Review.} Let $(X,d)$ be a metric space, and let $A$ be a subset of $X$. The distance from a point $x\in X$ to $A$ is defined as
\begin{align*}
	d(x,A) = \inf_{a\in A} d(x,a).
\end{align*}
The function $d(\cdot, A):X\to\mathbb{R}_+$ is continuous. To see this, fix $\epsilon > 0$ and $x_0\in X$. Then there exists $a\in A$ such that $d(x_0,a) < d(x_0,A) + \epsilon/2$. Once $d(x,x_0)<\epsilon/2$, we have
\begin{align*}
	d(x,A) \leq d(x,a) \leq d(x_0,x) + d(x_0,a) < d(x_0,A) + \epsilon.
\end{align*}
Similarly, $d(x_0,A) < d(x,A) + \epsilon$. Hence $x\mapsto d(x,A)$ is continuous. 

A \textit{projection} of $x$ on $A$ is defined as a point $a_0\in A$ such that $d(x,a_0)=d(x,A)$. In other words,
\begin{align*}
	d(x,a_0) = \min_{a\in A}d(x,a).
\end{align*}
The existence of projection is not ensured. For example, consider the point $x=-1$ and the open interval $(0,1)$ in Euclidean space $\mathbb{R}$. Also, a point has possibly more than one projections on a set. For example, consider the point $z=0$ and the unit circle $\mathbb{T}=\{\mathrm{e}^{\i\theta},\theta\in[0,2\pi)\}$ in the complex plane $\mathbb{C}$.

In this section, we discuss the projection in context of Hilbert spaces.

\paragraph{Definition 1.34\label{def:1.34}} (Convex sets). A subset $C$ of a vector space $X$ is said to be \textit{convex}, if for all $x,y\in C$ and all $t\in[0,1]$, $tx+(1-t)y\in C$.

\paragraph{Theorem 1.35.\label{thm:1.35}} Let $H$ be a Hilbert space, and let $M$ be a closed convex subset of $H$. Then for all $x\in H$, there exists a unique $x_0\in M$ such that $\Vert x-x_0\Vert=d(x,M):=\inf_{y\in M}\Vert x-y\Vert$.
\begin{proof}
Choose a sequence $(x_n)$ of points of $M$ such that $\Vert x-x_n\Vert\to d(x,M)$. By the parallelogram law,
\begin{align*}
	2\Vert x-x_n\Vert^2 + 2\Vert x - x_m\Vert^2 = 4\left\Vert x-\frac{x_n+x_m}{2}\right\Vert^2 + \Vert x_n - x_m\Vert^2,\ \forall n,m\in\mathbb{N}.
\end{align*}
Then $0\leq\Vert x_n - x_m\Vert^2 \leq 2\Vert x-x_n\Vert^2 + 2\Vert x-x_m\Vert^2 - 4d(x,M)^2 \to 0$, and $(x_n)$ is a Cauchy sequence. By completeness of $M$, which is a closed subset of a complete space $H$, the sequence $(x_n)$ converges to some $x_0\in M$, and $\Vert x-x_0\Vert = \lim_{n\to\infty}\Vert x-x_n\Vert = d(x,M)$.

To prove the uniqueness, suppose $x^\prime_0\in M$ also satisfies the condition. Then
\begin{align*}
	0\leq \Vert x^\prime_0 - x_0\Vert^2 = 2\left(\Vert x-x_0\Vert^2 + \Vert x-x_0^\prime\Vert^2\right) - 4\left\Vert x-\frac{x_0+x_0^\prime}{2}\right\Vert^2 \leq 0.
\end{align*}
Hence $\Vert x^\prime_0 - x_0\Vert=0$, $x_0=x_0^\prime$.
\end{proof}

\paragraph{Theorem 1.36\label{thm:1.36}} (Projection theorem). Let $M$ be a closed subspace of a Hilbert space $H$. Then for all $x\in H$, there exists unique $x_0\in M$ such that $\Vert x-x_0\Vert = d(x,M)$, and $x-x_0\perp M$.
\begin{proof}
Following \hyperref[thm:1.35]{Theorem 1.35}, it remains to show that $x-x_0\perp M$. Given $y\in M$, the vector $x_0+ty$ lies in $M$ for all $t\in\mathbb{R}$ (or $\mathbb{C}$). Then
\begin{align*}
	d(x,M)^2 \leq \Vert x-x_0 - ty\Vert^2 = \Vert x-x_0\Vert^2 + \vert t\vert^2\Vert y\Vert^2 - 2\Re\left(t\langle y,x-x_0\rangle\right).
\end{align*}
Let $t=\lambda\langle x-x_0,y\rangle$, then we have $2\lambda\left\vert\langle x-x_0,y\rangle\right\vert^2\leq\lambda^2\Vert y\Vert^2\left\vert\langle x-x_0,y\rangle\right\vert^2$ for all $\lambda\in\mathbb{R}$, which holds only if $\langle x-x_0,y\rangle=0$. Therefore $x-x_0\perp M$.
\end{proof}

We also have another version of projection theorem.

\paragraph{Theorem 1.37\label{thm:1.37}} (Projection theorem). Let $M$ be a closed subspace of a Hilbert space $H$. Then for all $x\in H$, there exists unique $x_0\in M$ and $x_1\perp M$ such that $x=x_0+x_1$. Furthermore, $\Vert x-x_0\Vert = d(x,M)$.
\begin{proof}
We first prove the existence of $x_0$ and $x_1$. Note that $M$ is closed in $H$, $M$ is also a Hilbert space. By \hyperref[thm:1.33]{Theorem 1.33}, there exists an orthonormal basis $\{e_\lambda,\lambda\in\Lambda_1\}$ of $M$, which can be expanded to an orthonormal basis $\{e_\lambda,\lambda\in\Lambda_2\}$ of $H$ such that $\Lambda_2\supset\Lambda_1$. By \hyperref[thm:1.31]{Theorem 1.31},
\begin{align*}
	x = \sum_{\lambda\in\Lambda_2}\left\langle x,e_\lambda\right\rangle e_\lambda = \underbrace{\sum_{\lambda\in\Lambda_1}\left\langle x,e_\lambda\right\rangle e_\lambda}_{=:x_0\in M} + \underbrace{\sum_{\lambda\in\Lambda_2\backslash\Lambda_1}\left\langle x,e_\lambda\right\rangle e_\lambda}_{=:x_1\perp M}.
\end{align*}
For the uniqueness, suppose $x=y_0+y_1$, where $y_0\in M$ and $y_1\perp M$. Then $x_0 - y_0 = y_1 - x_1$, and
\begin{align*}
	\Vert x_0 - y_0\Vert^2 = \langle \underbrace{x_0 - y_0}_{\in M},\underbrace{y_1 - x_1}_{\perp M}\rangle = 0.
\end{align*}
Hence $x_0=y_0$, and $x_1=y_1$.
\end{proof}

\paragraph{Remark.} Let $M$ be a subspace of a Hilbert space $H$. We define the \textit{orthogonal complement} of $M$ of $H$ as the set $M^\perp$ of all vectors in $H$ that are orthogonal to every vector in $M$:
\begin{align*}
	M^\perp = \left\{x\in H:x\perp M\right\}.
\end{align*}
By continuity of inner product, $M^\perp$ is closed: Given a limit point $x$ of $M^\perp$, we can find a sequence $x_n$ in $M^\perp$ that converges to $x$. Then for each $y\in M$, $\langle x,y\rangle = \lim_{n\to\infty}\langle x_n,y\rangle = 0$. As a result, $M^\perp$ is complete.
\vspace{0.1cm}

If $M$ is a closed subspace of $H$. Following the above proof, we can show that $M^\perp = \overline{\mathrm{span}}\left\{e_\lambda,\lambda\in\Lambda_2\backslash\Lambda_1\right\}$. By \hyperref[thm:1.31]{Theorem 1.31}, it suffices to show that for $y\in M^\perp$, $y=\sum_{\lambda\in\Lambda_2\backslash\Lambda_1}\langle y,e_\lambda\rangle e_\lambda$. This is clear, because $\langle y,e_\lambda\rangle=0$ for all $\lambda\in\Lambda_1$, and $y=\sum_{\lambda\in\Lambda_2}\langle y,e_\lambda\rangle e_\lambda$. Following \hyperref[thm:1.37]{Theorem 1.37}, every vector $x\in H$ can be uniquely decomposed as $x=x_0+x_1$, where $x_0\in M$ and $x_1\in M^\perp$. That is, the Hilbert space $H$ admits the direct sum $H=M\oplus M^\perp$.

\paragraph{Corollary 1.38.\label{cor:1.38}} Let $M$ be a closed subspace of a Hilbert space $H$. If $M\neq H$, then $M^\perp\neq\{0\}$.
\begin{proof}
Let $x\in H$ be a vector that does not lie in $M$. For the decomposition $x=x_0+x_1$, where $x_0\in M$ and $x_1\in M^\perp$, we have $x\neq x_0$. Hence $x_1\neq 0$.
\end{proof}

\paragraph{Corollary 1.39.\label{cor:1.39}} Let $M$ be a subspace of a Hilbert space $H$. Then $\overline{M} = \left(M^\perp\right)^\perp$, and $M^\perp=\left(\overline{M}\right)^\perp$. Furthermore, $M^\perp=\{0\}$ if and only if $M$ is dense in $H$.
\begin{proof}
Clearly, $M\subset\left(M^\perp\right)^\perp$: Let $x\in M$. Then
\begin{align*}
	\langle x,y\rangle = 0,\ \forall y\in M^\perp\ \Rightarrow\ x\in \left(M^\perp\right)^\perp.
\end{align*}

Since $\left(M^\perp\right)^\perp$ is closed, we have $\overline{M}\subset\left(M^\perp\right)^\perp$. If $\overline{M}$ is a proper subspace of $\left(M^\perp\right)^\perp$, there exists nonzero $x\in \left(M^\perp\right)^\perp\cap\overline{M}^\perp\subset\left(M^\perp\right)^\perp\cap M^\perp$. Then $x\perp x$, contradicting $x\neq 0$! Hence $\overline{M} = \left(M^\perp\right)^\perp$. 

Apply this to $M^\perp$, we have $M^\perp = \left((M^\perp)^\perp\right)^\perp = \left(\overline{M}\right)^\perp$.

If $M$ is dense in $H$, then $M^\perp = H^\perp = \{0\}$. Conversely, if $M^\perp = \{0\}$, then $\overline{M}=\left(M^\perp\right)^\perp = H$.
\end{proof}

\paragraph{Remark.} For general subspace $M$ of a Hilbert space $H$, we have $H=\overline{M}\oplus M^\perp$.

\newpage
\subsection{Density and Separability}
\subsubsection{Dense sets}
\paragraph{Definition 1.40\label{def:1.40}} (Density). Let $X$ be a topological space. Let $A$ and $B$ be subsets of $X$. Then $A$ is said to be \textit{dense} in $B$ if $B\subset\overline{A}$.

\paragraph{Remark.} The condition of density can be described as follows: $A$ is dense in $B$, if for all $x\in B$ and all $\epsilon >0$, there exists $a\in A$ such that $d(x,a) < \epsilon$.

By definition, density is transitive: If $A$ is dense in $B$ and $B$ is dense in $C$, then $A$ is dense in $C$.

\paragraph{Example 1.41.\label{example:1.41}} Following are some instances for dense sets:
\vspace{0.1cm}
\begin{itemize}
	\item[(i)] The set of rational numbers $\mathbb{Q}$ is dense in the real line $\mathbb{R}$.
	\item[(ii)] (Stone-Weierstrass). The set of all polynomial functions $P([a,b])$ on closed interval $[a,b]$ is dense in the space $(C([a,b]),\Vert\cdot\Vert_\infty)$ of continuous functions on $[a,b]$.
\end{itemize}

\paragraph{Example 1.42.\label{example:1.42}} Let $(X,\mathscr{A},\mu)$ be a measure space. The set of all simple functions
\begin{align*}
	\mathcal{S} = \left\{\sum_{k=1}^n c_k\chi_{A_k}:n\in\mathbb{N},\ c_1,\cdots,c_n\in\mathbb{R},\ A_1,\cdots,A_n\in\mathscr{A}\right\}
\end{align*}
is dense in $L^p(X,\mathscr{A},\mu)$, where $1\leq p < \infty$.
\begin{proof}
(i) We first consider bounded measurable functions that vanish outside a set $A$ with finite measure. Choose $f\in L^p(X,\mathscr{A},\mu)$ such that $\vert f\vert \leq M$ for some $M>0$, and $\{f\neq 0\}\subset A$ for some $\mu(A)<\infty$. For $n\in\mathbb{N}$, we divide $[-M,M]$ into intervals of length not greater than $n^{-1}$:
$$-M = y_0 < y_1 < \cdots < y_m = M+\frac{1}{2n}.$$
Define $E_k=\{x\in A:f(x)\in[y_{k-1},y_k)\}$. The function $f_n = \sum_{k=1}^m y_k\chi_{E_k}$ is simple, and $\vert f-f_n\vert < n^{-1}$. Note that $f$ is defined on a set $A$ with finite measure,
\begin{align*}
	0\leq \Vert f-f_n\Vert_p^p = \int_X\vert f - f_n\vert^p d\mu \leq \frac{1}{n^p}\mu(A)\to 0.
\end{align*}

(ii) We then consider unbounded measurable functions that vanish outside a set $A$ with finite measure. Choose $f\in L^p(X,\mathscr{A},\mu)$ such that $\{f\neq 0\}\subset A$ for some $\mu(A)<\infty$. Define the $M$-truncated function as
\begin{align*}
	[f]_M(x) = \begin{cases}
		M,\ f(x) > M,\\
		f(x),\ -M\leq f(x)\leq M,\\
		-M,\ f(x)<-M.
	\end{cases}
\end{align*}
By monotone convergence theorem,  
\begin{align*}
	\int_X \vert f\vert^p\,d\mu = \lim_{M\to\infty}\int_X\left\vert[f]_M\right\vert^p\,d\mu.
\end{align*}
Given $\epsilon > 0$, we choose $M_\epsilon$ such that 
\begin{align*}
	\int_X\left\vert f - [f]_{M_\epsilon}\right\vert^p\,d\mu \leq \int_X\vert f\vert^p\,d\mu - \int_X\left\vert[f]_{M_\epsilon}\right\vert^p\,d\mu < \frac{\epsilon^p}{2^p}.
\end{align*}
By (i), there exists simple function $g\in \mathcal{S}$ such that $\int_X\left\vert [f]_{M_\epsilon} - g\right\vert^p\,d\mu < 2^{-p}\epsilon^p$. Hence
\begin{align*}
	\int_X\left\vert f-g\right\vert^p\,d\mu \leq 2^{p-1}\left(\int_X\left\vert f-[f]_{M_\epsilon}\right\vert^p\,d\mu + \int_X\left\vert [f]_{M_\epsilon}-g\right\vert^p\,d\mu\right) < \epsilon^p.
\end{align*}

(iii) Now we prove the general case. Let $f\in L^p(X,\mathscr{A},\mu)$ and $\epsilon > 0$ be given. For $n\in\mathbb{N}$, we define the level set $F_n = \{x\in X:\vert f\vert^p > n^{-1}\}$. Then $\mu(F_n)\leq n\Vert f\Vert_p^p<\infty$, and $\{f\neq 0\}=\bigcup_{n=1}^\infty F_n$.

Consider the sequence $f\chi_{F_n}$, which converges to $f$ pointwise. By monotone convergence theorem,
\begin{align*}
	\int\vert f\vert^p\,d\mu = \lim_{n\to\infty}\int \left\vert f\chi_{F_n}\right\vert^p\,d\mu.
\end{align*}
Hence there exists $N_\epsilon$ such that for all $n\geq N_\epsilon$,
\begin{align*}
	\int_X\left\vert f - f\chi_{F_n}\right\vert^p\,d\mu \leq \int_X\left\vert f \right\vert^p\,d\mu - \int_X\left\vert f\chi_{F_n}\right\vert^p\,d\mu < \frac{\epsilon^p}{2^{p}}.
\end{align*}
By (ii), there exists simple function $h\in\mathcal{S}$ such that $\int_X\vert f\chi_{F_n} - h\vert^p\,d\mu < 2^{-p}\epsilon^p$, which implies
\begin{align*}
	\int_X\vert f - h\vert^p\,d\mu \leq 2^{p-1}\left(\int_X\left\vert f - f\chi_{F_n}\right\vert^p\,d\mu + \int_X\left\vert f\chi_{F_n} - h\right\vert^p\,d\mu\right) < \epsilon^p.
\end{align*}
Then we conclude the proof.
\end{proof}

\paragraph{Example 1.43.\label{example:1.43}} Following \hyperref[example:1.42]{Example 1.42}, the set $\mathcal{S}$ of all simple functions is dense in $L^\infty(X,\mathscr{A},\mu)$.
\begin{proof}
Let $f\in L^\infty(X,\mathscr{A},\mu)$. Then the bad set $E=\{x\in X:f(x)>\Vert f\Vert_\infty\}$ has zero measure. For $n\in\mathbb{N}$, we divide $[-\Vert f\Vert_\infty,\Vert f\Vert_\infty]$ into intervals of length not greater than $n^{-1}$:
$$-\Vert f\Vert_\infty = y_0 < y_1 < \cdots < y_m = \Vert f\Vert_\infty + \frac{1}{2n}.$$
Define $A_k=\{x\in X:f(x)\in[y_{k-1},y_k)\}$. Then the function $f_n=\sum_{k=1}^m y_k\chi_{A_k}\in\mathcal{S}$ satisfies
\begin{align*}
	\sup_{x\in X\backslash E}\vert f(x) - f_n(x)\vert \leq \frac{1}{n}\ \Rightarrow\ 0\leq \Vert f-f_n\Vert_\infty\leq\frac{1}{n}\to 0.
\end{align*}
Hence $\mathcal{S}$ is dense in $L^\infty(X,\mathscr{A},\mu)$, as desired.
\end{proof}

\paragraph{Review: Compact supported functions.} Let $X$ be a topological space. The support of function $f:X\to\mathbb{R}$ is defined as the closure of the set of all points in $X$ not mapped to zero by $f$:
\begin{align*}
	\supp f = \overline{\{x\in X: f(x)\neq 0\}} = \overline{\{f\neq 0\}}.
\end{align*}
If the support of $f$ is compact in $X$, $f$ is said to be \textit{compactly supported}. Following this definition, any function defined on a closed interval $[a,b]$ can be extended to a compactly supported function on $\mathbb{R}$.

The set of all continuous compactly supported functions on $X$ is denoted by $C_c(X)$. If $f\in C_c(X)$, then $f$ is uniformly continuous on $\supp f$. Note that $f=0$ outside $\supp f$, we have that $f$ is uniformly continuous on $X$, which implies $C_c(X)\subset C_0(X)$. Furthermore, by extreme value theorem, $f$ has maximum and minimum on $\supp f$, which implies that $f$ is uniformly bounded on $X$, i.e. $\max_{x\in X}\vert f(x)\vert < \infty$.

\newpage
\paragraph{Review: Radon measure.} A \textit{Radon measure} on a topological space $X$ is a Borel measure $\mu$ such that
\begin{itemize}
\item[(i)] $\mu$ is finite on all compact sets, i.e.  $\mu(K)<\infty$ for all compact $K\subset X$;
\item[(ii)] $\mu$ is outer regular on all Borel sets, i.e., for all Borel set $B\subset X$,
\begin{align*}
	\mu(B)=\inf\{\mu(U):U\supset B,\ U\ is\ open\};
\end{align*}
\item[(iii)] $\mu$ is inner regular on all open sets, i.e., for all open set $U\subset E$,
\begin{align*}
	\mu(U)=\sup\{\mu(K):K\subset E,\ K\ is\ compact\}.
\end{align*}
\end{itemize}

Let $(X,\mathscr{B})$ be a Borel measurable space, and let $\mu$ be a Radon measure on $\mathscr{B}$. Since every compact set in $X$ has finite measure, the compactly supported functions are always integrable:
\begin{align*}
	\Vert f\Vert_p = \left(\int_X\vert f\vert^p d\mu\right)^{1/p} = \left(\int_{\supp f} \vert f\vert^p dm\right)^{1/p} \leq \mu(\supp f)^{1/p}\Vert f\Vert <\infty.
\end{align*}
Hence $C_c(X)\subset L^p(X)$ for all $1\leq p\leq \infty$.

\paragraph{Example 1.44.\label{example:1.44}} Let $X$ be a locally compact Hausdorff space. Let $\mathscr{B}$ be the Borel $\sigma$-algebra, and let $\mu$ be a Radon measure. Then $C_c(X)$ is dense in $L^p(\mathbb{R},\mathscr{B},\mu)$, where $1\leq p<\infty$. 
\begin{proof}
Since the set of all simple functions $\cal{S}$ is dense in $L^p(X)$, it suffices to approximate each simple function $\chi_E\in\cal{S}$ in $L^p$ norm, where $E$ is a Borel set. For any $\epsilon>0$, we pick an open set $U$ and a compact set $K$ such that $K\subset E\subset U$ and $\mu(U\backslash K)<\epsilon$. By Urysohn's lemma, there exists $f\in C_c(X)$ such that $\chi_K\leq f\leq\chi_U$. Then $\Vert\chi_E-f\Vert_p^p\leq\mu(U\backslash K)\leq\epsilon$.
\end{proof}

\paragraph{Remark.} Particularly, since the Lebesgue measure, restricted to the Borel sets, is a Radon measure, we have $C_c(\mathbb{R}^n)\subset L^p(\mathbb{R}^n)$ for $1\leq p<\infty$.

\paragraph{Review: Convolution.} Let $f,g:\mathbb{R}\to\mathbb{R}$ be Lebesgue measurable functions. Define the bad set as
\begin{align*}
	E(f,g) := \left\{x\in\mathbb{R}:\int_\mathbb{R}\left\vert f(x-y)g(y)\right\vert dy = \infty\right\}.
\end{align*}
The \textit{convolution} of $f$ and $g$ is the function $f * g:\mathbb{R}\to\mathbb{R}$ defined by
\begin{align*}
	(f*g)(x) = \begin{cases}
		\int_\mathbb{R} f(x-y)g(y)\,dy,\ &x\notin E(f,g),\\
		0,\ &x\in E(f,g).
	\end{cases}
\end{align*}
Clearly, the convolution operation is commutative and associative, i.e. $f*g=g*f$, and $(f*g)*h = f*(g*h)$. Furthermore, the distributivity of convolution with respect to functional addition immediately follows.

\paragraph{Proposition 1.45\label{prop:1.45}} (Properties of convolution). Let $f,g:\mathbb{R}\to\mathbb{R}$ be Lebesgue measurable functions.
\begin{itemize}
	\item[(i)] If $f,g\in L^1(\mathbb{R})$, then $\mu(E(f,g))=0$, $f*g\in L^1(\mathbb{R})$, and
	\begin{align*}
		\int_\mathbb{R} (f*g)\,dm = \int_\mathbb{R}f\,dm\int_\mathbb{R}g\,dm. \tag{1.15}\label{eq:1.15}
	\end{align*}
    \item[(ii)] If $f\in C_0(\mathbb{R})$ and $g\in L^1(\mathbb{R})$, then $f*g\in C_0(\mathbb{R})$.
\end{itemize}
\begin{proof}
(i) Define $F:\mathbb{R}^2\to\mathbb{R},(x,y)\mapsto f(x)$ and $G:\mathbb{R}^2\to\mathbb{R},(x,y)\mapsto g(y)$. Then for all $\alpha\in\mathbb{R}$, both $F^{-1}((\alpha,\infty))=f^{-1}((\alpha,\infty))\times\mathbb{R}$ and $G^{-1}((\alpha,\infty))=\mathbb{R}\times g^{-1}((\alpha,\infty))$ are Lebesgue measurable sets in $\mathbb{R}$, which implies that both $F$ and $G$ are measurable, as well as their product $F\cdot G:(x,y)\mapsto f(x)g(y)$. Let $T(x,y)=(x-y,y)$ be a linear transformation. Then the composition $H=(F\cdot G)\circ T: (x,y)\mapsto f(x-y)g(y)$ is measurable. By Tonelli's theorem, 
\begin{align*}
	\int_{\mathbb{R}^2}\vert H\vert\,dm_2 = \int_\mathbb{R}\left(\int_\mathbb{R} \left\vert f(x-y)\right\vert\left\vert g(y)\right\vert dx\right)dy = \Vert f\Vert_1\Vert g\Vert_1.
\end{align*}
Hence $H:\mathbb{R}^2\to\mathbb{R}$ is integrable. By Fubini's theorem, for a.e. $x\in\mathbb{R}$, $y\mapsto H(x,y)$ is integrable, hence $\mu(E(f,g))=0$. Furthermore, the function $f*g:x\mapsto \int_\mathbb{R}H(x,y)\,dy$ is also integrable, that is, $f*g\in L^1(\mathbb{R})$. The equation \hyperref[eq:1.15]{(1.15)} follows from Fubini's theorem.
\vspace{0.1cm}

(ii) Given $\epsilon>0$. By uniform continuity of $f$, there exists $\eta > 0$ such that $\vert f(x) - f(x^\prime)\vert < \epsilon/\Vert g\Vert_1$ for all $\vert x-x^\prime\vert < \eta$, . As a result, we have
\begin{align*}
	\vert(f*g)(x) - (f*g)(x^\prime)\vert &= \left\vert\int_\mathbb{R} \left[f(x-y) - f(x^\prime-y)\right]g(y)\,dy\right\vert\\
	&\leq \int_\mathbb{R} \left\vert f(x-y) - f(x^\prime-y)\right\vert \left\vert g(y)\right\vert dy < \epsilon
\end{align*}
for all $x,x^\prime\in\mathbb{R}$ such that $\vert x-x^\prime\vert < \eta$.
\end{proof}

\paragraph{Proposition 1.46\label{prop:1.46}} (Convolution of compactly supported functions). Let $f,g:\mathbb{R}\to\mathbb{R}$.
\begin{itemize}
	\item[(i)] If $f,g\in L^1(\mathbb{R})$, then $\supp(f*g)\subset\overline{\supp f + \supp g} := \overline{\left\{x+y:x\in\supp f,y\in\supp g\right\}}$. Furthermore, if both $f$ and $g$ are compactly supported on $\mathbb{R}$, then $f*g$ is also compactly supported. In this case, $\supp(f*g)\subset\supp f + \supp g$.
	\vspace{0.1cm}
    \item[(ii)] Let $1\leq p\leq \infty$, and let $k\in\mathbb{N}_0$. If $f\in C_c^k(\mathbb{R})$ and $g\in L^p(\mathbb{R}$), then $f * g\in C_0^k(\mathbb{R})$. Furthermore, differentiation commutes with convolution, i.e.,
    \begin{align*}
    	D^j(f*g)=D^j f * g,\ j=0,1,\cdots,k,
    \end{align*}
    where $D^j f= f^{(j)}$ stands for the $j$-th derivative.
    \vspace{0.1cm}
    \item[(iii)] Let $1\leq p\leq \infty$. If $f\in C_c^\infty(\mathbb{R})$ and $g\in L^p(\mathbb{R}$), then $f * g\in C_0^\infty(\mathbb{R})$. Similarly, differentiation commutes with convolution, i.e., $D^k(f * g)=D^k f * g$ for all $k\in\mathbb{N}_0$.
\end{itemize}
\paragraph{Remark.} Combining (ii) and (iii), we obtain a useful conclusion stated as follows: Let $1\leq p\leq \infty$ and $k\in\mathbb{N}_0\cup\{\infty\}$. If $f\in C_c^k(\mathbb{R})$ and $g\in L^p(\mathbb{R})$ is compactly supported, then $f*g\in C_c^k(\mathbb{R})$.
\renewcommand{\proofname}{Proof of Proposition 1.46}
\begin{proof}
(i) Let $f,g\in L^1(\mathbb{R})$. Take any $x\in\mathbb{R}$. Note that
\begin{align*}
	(f*g)(x) = \int_\mathbb{R} f(x-y)g(y)\,dy = \int_{(x-\supp f)\cap \supp g}f(x-y)g(y)\,dy.
\end{align*}
For $x\notin \supp f + \supp g$, we have $(x-\supp f)\cap \supp g=\emptyset$, which implies $(f*g)(x) = 0$. Hence
\begin{align*}
	(f*g)(x)\neq 0\ \Rightarrow x\in \supp f + \supp g\ \Rightarrow\ \supp(f*g)\subset\overline{\supp f + \supp g}.
\end{align*}
If $f,g\in C_c(\mathbb{R})$, then $\supp f$ and $\supp g$ are compact in $\mathbb{R}$. Define $\phi(x,y)=x+y$, which is a continuous map on $\mathbb{R}^2$. Then $\supp f + \supp g = \phi(\supp f\times\supp g)$ is also compact. Hence $\supp f + \supp g$ is closed, and $\supp (f*g)$ as a closed subset is also compact, which implies $f*g\in C_c(\mathbb{R})$.
\vspace{0.1cm}

(ii) \textit{Step I:} We first show the case $k=0$. Let $q=p/(p-1)$. Note that $f$ is continuous and compact supported, then $m(\supp f) < \infty$, $f$ is uniformly continuous, and $\Vert f\Vert_\infty = \max_{x\in\supp f}\vert f(x)\vert < \infty$. By Hölder's inequality, for all $x\in\mathbb{R}$, we have
\begin{align*}
	\int_\mathbb{R}\left\vert f(x-y)\right\vert\left\vert g(y)\right\vert dy \leq \Vert f\Vert_q\Vert g\Vert_p \leq m\bigl(\supp f\bigr)^{1/q}\Vert f\Vert_\infty\Vert g\Vert_p < \infty.
\end{align*}
Then $f*g$ is well-defined on $\mathbb{R}$. To show the uniform continuity of $f*g$, we fix $\epsilon>0$ and let $\eta$ be such that $\vert x-x^\prime\vert<\eta$ implies $\vert f(x)-f(x^\prime)\vert < \epsilon$. Then
\begin{align*}
	\vert(f*g)(x) - (f*g)(x^\prime)\vert &= \left\vert\int_\mathbb{R} \left[f(x-y) - f(x^\prime-y)\right]g(y)\,dy\right\vert\\
	&\leq m\bigl(\supp f\bigr)^{1/q}\left\Vert g\right\Vert_p\epsilon.
\end{align*}

\textit{Step II:} We prove the case $k=1$. It suffices to show the interchangeability of derivative and integral. Given any quantity $\delta\to 0$, we have
\begin{align*}
	\frac{(f*g)(x+\delta) - (f*g)x}{\delta} = \int_\mathbb{R} \frac{f(x+\delta - y) - f(x-y)}{\delta}g(y)\,dy.\tag{1.16}\label{eq:1.16}
\end{align*}
Since $f\in C^1_c(\mathbb{R})$, by Lagrange's mean value theorem, there exists $\xi\in[0,1]$ such that
\begin{align*}
	\left\vert\frac{f(x+\delta - y) - f(x-y)}{\delta}\right\vert = \left\vert f^\prime(x+\xi\delta - y)\right\vert,\tag{1.17}\label{eq:1.17}
\end{align*}
Note that $f^\prime$ is also continuous and compactly supported on $\mathbb{R}$, the RHS of \hyperref[eq:1.17]{(1.17)} is bounded by $\Vert f^\prime\Vert_\infty <\infty$, and the integrand in \hyperref[eq:1.16]{(1.16)} is dominated by an integrable function $\Vert f^\prime\Vert_\infty g$. Using Lebesgue's dominate convergence theorem, we have
\begin{align*}
	\lim_{\delta\to 0}\int_\mathbb{R}\frac{f(x+\delta - y) - f(x-y)}{\delta}g(y)\,dy = \int_\mathbb{R} f^\prime(x-y)g(y)\,dy.
\end{align*}
Therefore $(f*g)^\prime = f^\prime * g$. Since $f^\prime\in C_c(\mathbb{R})$, we have $(f*g)^\prime\in C_0(\mathbb{R})$, and $f*g\in C_0^1(\mathbb{R})$.
\vspace{0.1cm}

\textit{Step III:} Use induction. Suppose our conclusion holds for $C_c^{k-1}(\mathbb{R})$. For each $f\in C^k_c(\mathbb{R})\subset C^{k-1}_c(\mathbb{R})$, $D^{k-1} f\in C^1_c(\mathbb{R})$. By Step II, we have 
\begin{align*}
	D^k(f*g) = D(D^{k-1}(f*g)) = D(D^{k-1}f*g) = (D^k f)* g,
\end{align*} 
which is uniformly continuous on $\mathbb{R}$. Hence $f*g\in C_c^k(\mathbb{R})$.
\vspace{0.1cm}

(iii) Note that $C_c^\infty(\mathbb{R}) = \bigcap_{k=0}^\infty C_c^k(\mathbb{R})$, we have $D^k(f*g) = D^k f * g$ for all $k\in\mathbb{N}_0$. Following Step II, $D^k f\in C_c(\mathbb{R})$ implies $D^k(f*g)\in C_0(\mathbb{R})$ for all $k\in\mathbb{N}_0$. Hence $f*g\in\bigcap_{k=0}^\infty C_0^k(\mathbb{R}) = C_0^\infty(\mathbb{R})$.
\end{proof}
\renewcommand{\proofname}{Proof}

\paragraph{Review: Translation operators.} Let $X$ be a vector space, let $Y^X$ be the set of functions $f:X\to Y$, and let $s$ be a vector $X$. The \textit{translation operator} $\tau_s:Y^X\to Y^X$ is defined as
\begin{align*}
	(\tau_s f)(x) = f(x-s),\ \forall f\in Y^X.
\end{align*}

\paragraph{Proposition 1.47.\label{prop:1.47}} Let $1\leq p < \infty$. For any $f\in C_c(\mathbb{R})$,
\begin{align*}
	\lim_{s\to 0} \Vert\tau_s f-f\Vert_p \to 0.\tag{1.18}\label{eq:1.18}
\end{align*}
\begin{proof}
Let $f\in C_c(\mathbb{R})$. The collection of functions $\{\tau_s f: \vert s\vert\leq 1\}$ has a common support
\begin{align*}
	K = \bigcup_{s\in[-1,1]}\supp(\tau_s f) = \supp f + [-1,1] = \{x+y:x\in\supp f, y\in[-1,1]\} = \phi(\supp f\times [-1,1]),
\end{align*}
which is compact as the image of a compact set under a continuous map $\phi:\mathbb{R}^2\to\mathbb{R},(x,y)\mapsto x+y$.
\vspace{0.1cm}

By uniform continuity of $f$, given $\epsilon>0$, there exists $\delta > 0$ such that $\vert f(x) - f(y)\vert < \epsilon$ for all $\vert x-y\vert < \delta$. Then for any $s<\vert\min(\delta,1)\vert$, we have
\begin{align*}
	\Vert\tau_s f-f\Vert_p^p = \int_K \vert f(x-s) - f(x)\vert^p dx \leq \mu(K)\,\epsilon^p.
\end{align*}
Since $\mu(K)<\infty$, and $\epsilon$ is arbitrary, we conclude that $\Vert\tau_s f-f\Vert_p\to 0$ as $s\to 0$.
\end{proof}

\paragraph{Example 1.48.\label{example:1.48}} For $1\leq p <\infty$, $C_c^\infty(\mathbb{R})$ is dense in $L^p(\mathbb{R})$.
\begin{proof}
Let $f\in C_c(\mathbb{R})$. Then We choose a function $\phi\in C_c^\infty(\mathbb{R})$ such that $\int_\mathbb{R}\phi\,dm = 1$, for example,
\begin{align*}
	\psi(t) = \exp\left(\frac{1}{t^2-1}\right)\chi_{[-1,1]}(t),\ \phi(x) = \frac{\psi(x)}{\int_{-1}^1\psi(t)\,dt},
\end{align*}
and define $\phi_\epsilon(x) = \frac{1}{\epsilon}\phi\left(\frac{x}{\epsilon}\right)$ for $\epsilon > 0$. By \hyperref[prop:1.46]{Proposition 1.46}, $f*\phi_\epsilon\in C^\infty_c(\mathbb{R})$, and
\begin{align*}
	\int_\mathbb{R} \vert(f *\phi_\epsilon)(x) - f(x)\vert^p\,dx &= \int_\mathbb{R}\left\vert\int_{[-\epsilon,\epsilon]} (f(x-y)-f(x))\phi_\epsilon(y)\,dy\right\vert^p dx\\
	&\leq \int_\mathbb{R}\int_{[-\epsilon,\epsilon]} \tag{By Jensen's inequality} \left\vert(f(x-y)-f(x))\right\vert^p\phi_\epsilon(y)\,dydx\\
	& = \int_{[-\epsilon,\epsilon]}\phi_\epsilon(y)\Vert\tau_y f -f\Vert_p^p\,dy\\
	&\leq\sup_{y\in[-\epsilon,\epsilon]}\Vert\tau_y f - f\Vert_p^p.
\end{align*}
which converges to $0$ as $\epsilon\to 0$ by \hyperref[prop:1.47]{Proposition 1.47}. Since $C_c(\mathbb{R})$ is dense in $L^p(\mathbb{R})$, the result follows.
\end{proof}

\paragraph{Remark.} In fact, the limit \hyperref[eq:1.18]{(1.18)} in \hyperref[prop:1.47]{Proposition 1.47} remains zero for all $f\in L^p(\mathbb{R})$. Fix $\epsilon > 0$, there exists $g\in C^\infty_c(\mathbb{R})$ such that $\Vert f-g\Vert_\infty < \epsilon/3$ by \hyperref[example:1.48]{Example 1.48}. Choose $\delta$ such that $\Vert\tau_s g -g\Vert_p<\epsilon/3$ for all $\vert s\vert<\delta$. Then for all $\in(-\delta,\delta)$,
\begin{align*}
	\Vert \tau_s f - f\Vert_p &\leq \Vert \tau_s f - \tau_s g\Vert_p + \Vert \tau_s g - g\Vert_p + \Vert g - f\Vert_p = 2\Vert f - g\Vert + \Vert\tau_s g -g\Vert_p < \epsilon.
\end{align*}

Similarly, we have the following conclusion similar to \hyperref[example:1.48]{Example 1.48}.

\paragraph{Example 1.49.\label{example:1.49}} Denote by $C_c^\infty(a,b)$ the set of functions $f:[a,b]\to\mathbb{R}$ such that $f$ is smooth and compactly supported in $(a,b)$, i.e. $\supp f\subset (a,b)$. Then $C_c^\infty(a,b)$ is dense in $L^p([a,b])$, where $1\leq p < \infty$.

\newpage
\subsubsection{Separable sets}
\paragraph{Definition 1.50\label{def:1.50}} (Separability). Let $X$ be a topological space. Then $X$ is said to be \textit{separable} if it has a countable dense subset.

\paragraph{Example 1.51.\label{example:1.51}} Following are some instances for separable spaces.
\vspace{0.1cm}
\begin{itemize}
	\item[(i)] The space $\mathbb{R}^n$ is separable, since $\mathbb{Q}^n$ is a countable dense subset.
	\vspace{0.1cm}
	\item[(ii)] The spaces $C([a,b])$ and $L^p([a,b]), 1\leq p <\infty$ are separable: The set $P([a,b])$ of all polynomials on $[a,b]$ is dense in $C([a,b])$, and the set of all polynomials with rational coefficients is dense in $P([a,b])$.
	\vspace{0.1cm}
	\item[(iii)] If $(X,d)$ is separable, so is $(A,d)$, where $A\subset X$.
\end{itemize}
\renewcommand{\proofname}{Proof of (iii).}
\begin{proof}
Let $\mathcal{D}=\{x_n,n\in\mathbb{N}\}$ be a countable dense subset of $X$. Then we have $X\subset O(x_n,\epsilon)$ for all $\epsilon>0$. For every $n,k\in\mathbb{N}$, choose arbitrary $y_{n,k}\in A\cap O(x_n,1/k)$ provided it is not empty. Given $y\in A$ and $\epsilon > 0$, we choose an integer $k > 2/\epsilon$. By density of $\mathcal{D}$, there exists $x_n\in\mathcal{D}$ such that $d(y,x_n)<\epsilon / 2$. Moreover, $A\cap O(x_n,1/k)$ is not empty since it contains $y$. Then
\begin{align*}
	d(y,y_{n,k}) \leq d(y,x_n) + d(x_n,y_{n,k}) < \frac{\epsilon}{2} + \frac{1}{k} < \epsilon.
\end{align*}
Hence $\{y_{n,k}:n,k\in\mathbb{N}\}$ is dense in $A$.
\end{proof}
\renewcommand{\proofname}{Proof}

\paragraph{Example 1.52.} Let $U\subset\mathbb{R}$ be Lebesgue measurable with $\mu(U)>0$. If $1\leq p <\infty$, then $L^p(U)$ is separable.
\begin{proof}
Consider the set of countably many functions in $L^p(U)$:
\begin{align*}
	\mathcal{D} := \left\{\sum_{j=1}^n c_j\chi_{(a_j,b_j)\cap U}:n\in\mathbb{N},a_1,b_1,c_1,\cdots,a_n,b_n,c_n\in\mathbb{Q}\right\}
\end{align*}
For any $f\in L^p(\mathbb{R})$, approximate it with functions in $\mathcal{D}$ as follows: (i) By \hyperref[example:1.42]{Example 1.42}, approximate $f$ by a simple function $\varphi = \sum_{i=1}^m r_i\chi_{A_i}$, with $m(A_i)<\infty$ for each $i$. (ii) By Littlewood's first principle, we can approximate each Lebesgue measurable set $A_i$ with a finite collection of disjoint open intervals $\{(s_{ij},t_{ij})\}_{j=1}^{n_i}$. Then we obtain a simple function $\phi=\sum_{i=1}^m\sum_{j=1}^{n_i} r_i\chi_{(s_{ij},t_{ij})}$ near to $\psi$; (iii) Approximate $\phi$ by rational coefficients and endpoints.

According to the above procedure, $\mathcal{D}$ is dense in $L^p(U)$.
\end{proof}

\paragraph{Remark.} The space $L^\infty(\mathbb{R})$ is not separable. To see this, consider the set $A=\{\chi_{(-\infty,t]},t\in\mathbb{R}\}$. For any two distinct functions $f$ and $g$ in $A$, we have $\Vert f-g\Vert_\infty = 1$. Then any proper subset of $A$ is not dense in $A$, and $A$ is not separable. As a result, $L^\infty(\mathbb{R})$ is not separable.

\newpage
\subsection{Completeness}
\subsubsection{Complete metric spaces}
\paragraph{Lemma 1.53.\label{lemma:1.53}} The following statements are true.
\begin{itemize}
	\item[(i)] (\hyperref[lemma:1.6]{Lemma 1.6}) A closed subspace of a complete metric space is complete.
	\vspace{0.1cm}
	\item[(ii)] (\hyperref[lemma:1.7]{Lemma 1.7}, subsequence criterion) A metric space $(X,d)$ is complete if every Cauchy sequence in $X$ has a convergent subsequence.
	\vspace{0.1cm}
	\item[(iii)] If $A$ is a dense subset of a metric space $(X,d)$, and every Cauchy sequence in $A$ converges to some point of $X$, then $(X,d)$ is complete.
\end{itemize} 
\renewcommand{\proofname}{Proof of (iii)}
\begin{proof}
	Let $(x_n)$ be a Cauchy sequence in $X$. Since $\overline{A}=X$, there exists find $a_n\in A$ such that $d(a_n,x_n)<1/n$ for each $n\in\mathbb{N}$. Fix $\epsilon > 0$. Then there exists $N$ such that $d(x_n,x_m)<\epsilon/3$ for all $n,m\geq N$. By setting $n,m\geq\max\{N,3\epsilon^{-1}\}$, we have
	\begin{align*}
		d(a_n,a_m) \leq d(a_n,x_n) + d(x_n,x_m) + d(x_m,a_m) < \epsilon.
	\end{align*}
	Hence $(a_n)$ is a Cauchy sequence in $A$, and it converges to some $x\in X$. Since $d(x_n,a_n)\to 0$, and $d(a_n,x)\to 0$, we have $d(x_n,x)\to 0$, which concludes the proof.
\end{proof}
\renewcommand{\proofname}{Proof}

\paragraph{Example 1.54\label{example:1.54}} (Quotient spaces). Let $M$ be a subspace of a vector $X$. For $x,y\in X$, define $x\sim y$ if and only if $x-y\in M$. Then $\sim$ is an equivalence relation on $X$. We define the \textit{quotient space} $X/M$ as
\begin{align*}
	X/M := X/\sim\  = \{[x]:x\in X\},\ \text{where}\ [x] := \{x+y:y\in M\}\ \text{is an equivalence class.}
\end{align*}
The \textit{quotient map} is defined as $\pi:X\to X/M,x\mapsto x$. Clearly, $X/M$ forms a vector space, if we set $[x]+[y]=[x+y]$ and $\alpha[x]=[\alpha x]$, where $x,y\in X$ and $\alpha\in\mathbb{R}$ (or $\mathbb{C}$), and let $[0]$ be the zero element.
\vspace{0.1cm}

If $X$ is a normed space and $M$ is a closed subspace of $X$, then we define a norm $\Vert\cdot\Vert$ on $X/M$ by
\begin{align*}
	\Vert [x]\Vert = d(x,M) = \inf_{y\in M}\Vert x-y\Vert.
\end{align*}
It is easy to verify that $\Vert\cdot\Vert$ satisfy the conditions in \hyperref[def:1.13]{Definition 1.13}. Moreover, $\Vert\cdot\Vert$ is well-defined, because $x\sim y$ implies $\Vert[x]\Vert=\Vert[y]\Vert$.
\vspace{0.1cm}

Note that we require $M$ to be closed. Otherwise, there exists $x\in X\backslash M$ such that $x$ is a limit point of $M$, and there exists a sequence $(x_n)$ of points of $M$ such that $x_n\to x$. As a result, $\Vert [x]\Vert = \inf_{y\in M}\Vert x-y\Vert = 0$. However $[x]\neq[0]$, a contradiction! In this case, $\Vert\cdot\Vert$ is merely a seminorm on $X/M$.

\paragraph{Claim.} If $(X,\Vert\cdot\Vert)$ is a Banach space, so is $(X/M,\Vert\cdot\Vert)$.
\begin{proof}
Let $([x_n])$ be a Cauchy sequence of points of $X/M$. Then for all $\epsilon>0$, there exists $N\in\mathbb{N}$ such that $\left\Vert [x_n] - [x_m]\right\Vert = \inf_{y\in M}\Vert x_n-x_m-y\Vert < \epsilon$ for all $n,m\geq N$. We choose a subsequence $n_k$ such that
\begin{align*}
	\inf_{y\in M}\Vert x_{n_{k+1}} - x_{n_k} - y\Vert < 2^{-k},\ k\in\mathbb{N}.
\end{align*}
Then there exists $y_k\in M$ such that $\Vert x_{n_{k+1}} - x_{n_k} - y_k\Vert < 2^{-k}$. We define another sequence $\bigl(x_{n_k}^\prime\bigr)$ by
\begin{align*}
	x_{n_1}^\prime=x_{n_1},\ x_{n_2}^\prime=x_{n_2} - y_1,\ \cdots,\  x_{n_k}^\prime=x_{n_k} + \sum_{j=1}^{k-1} (-1)^{k-j}y_j,\ \cdots.
\end{align*}
By definition, $\bigl\Vert x_{n_{k+1}}^\prime - x_{n_k}^\prime\bigr\Vert < 2^{-k}$, and $x_{n_k}^\prime - x_{n_k}\in M$, which implies $[x_{n_k}^\prime] = [x_{n_k}]$. Then $\bigl(x_{n_k}^\prime\bigr)$ is a Cauchy sequence in Banach space $(X,\Vert\cdot\Vert)$, which converges to some $x^\prime\in X$. 

As a result, the subsequence $[x_{n_k}]$ converges to $[x^\prime]\in X/M$:
\begin{align*}
	0\leq\left\Vert[x_{n_k}] - [x^\prime]\right\Vert = \left\Vert[x_{n_k}^\prime] - [x^\prime]\right\Vert = \inf_{y\in M}\left\Vert x_{n_k}^\prime - x^\prime - y\right\Vert \leq \left\Vert x_{n_k}^\prime - x^\prime\right\Vert \to 0.
\end{align*}
By subsequence criterion (\hyperref[lemma:1.53]{Lemma 1.53}), $X/M$ is a Banach space.
\end{proof}

\paragraph{Example 1.55} (Functions of bounded variation). Let $V([a,b])$ be the set of all functions $f:[a,b]\to\mathbb{R}$ of bounded variation, i.e., the total variation of $f$ on $[a,b]$ is bounded:
\begin{align*}
	V_a^b(f) := \sup\left\{\sum_{i=1}^n\left\vert f(x_i)  - f(x_{i-1})\right\vert:n\in\mathbb{N},a=x_0<x_1<\cdots<x_n=b\right\} < \infty.
\end{align*}
For all $f\in V([a,b])$, we define the norm
\begin{align*}
	\Vert f\Vert = \vert f(a)\vert + V_a^b(f).
\end{align*}
Then $(V([a,b]),\Vert\cdot\Vert)$ is a normed space.
\vspace{0.1cm}

Let $V_0([a,b])$ be the subspace of $V([a,b])$, which consists of all functions $f:[a,b]\to\mathbb{R}$ such that $f$ is of bounded variation, $f(a)=0$ and that $f$ is right-continuous on $(a,b)$. We continue to use the norm $\Vert\cdot\Vert$ on $V([a,b])$, which becomes $\Vert f\Vert = V_a^b(f)$ for $f\in V_0([a,b])$. Then $(V_0([a,b]),\Vert\cdot\Vert)$ is also a normed space.

\paragraph{Claim.} $V([a,b])$ and $V_0([a,b])$ are Banach spaces.
\begin{proof}
(i) We first show that $V([a,b])$ is Banach. Let $(f_n)$ be a Cauchy sequence in $V([a,b])$, i.e. for all $\epsilon>0$, there exists $N$ such that $\vert f_n(a) - f_m(a)\vert + V_a^b(f_n - f_m) < \epsilon$ for all $n,m\geq N$. Given $x\in[a,b]$,
\begin{align*}
	\vert f_n(x) - f_m(x)\vert &\leq \vert f_n(a) - f_m(a)\vert + \vert(f_n(x)-f_m(x)) - (f_n(a) - f_m(a))\vert\\
	&\leq \vert f_n(a) - f_m(a)\vert + V_a^b(f_n - f_m).
\end{align*}
Then $f_n(x)$ is a Cauchy sequence, which converges to some $f(x)\in\mathbb{R}$. Hence we obtain a function $f$ on $[a,b]$ to which $f_n$ converges pointwise.
\vspace{0.1cm}

Let $a=x_0<x_1<\cdots<x_k=b$ be any partition of $[a,b]$. Then we have
\begin{align*}
	\sum_{j=1}^k\vert f(x_j) - f(x_{j-1})\vert &\leq \sum_{j=1}^k\vert f(x_j) - f_n(x_j)\vert + \sum_{j=1}^k\vert f_n(x_j) - f_n(x_{j-1})\vert + \sum_{j=1}^k\vert f_n(x_{j-1}) - f(x_{j-1})\vert\\
	&\leq \underbrace{\sum_{j=1}^k\vert f(x_j) - f_n(x_j)\vert + \sum_{j=1}^k\vert f_n(x_{j-1}) - f(x_{j-1})\vert}_{\text{(a)}} + \underbrace{V_a^b(f_n)}_{\text{(b)}}.
\end{align*}
The term (a) converges to zero, since $f_n$ converges to $f$ pointwise. Hence it suffices to bound term (b). Note that $(f_n)$ is a Cauchy sequence, there exists $N$ such that $\Vert  f_n - f_m\Vert < 1$ for all $n,m\geq N$. Then the sequence is uniformly bounded by $M=\{\Vert f_1\Vert,\cdots,\Vert f_{N-1}\Vert,1+\Vert f_N\Vert\}$, and $V_a^b(f_n)\leq \Vert f_n\Vert\leq M$ for all $n\in\mathbb{N}$. Since the partition $a=x_0<x_1<\cdots<x_n= b$ is arbitrary, the total variation of $f$ is also bounded by $M$.
\vspace{0.1cm}

Now it remains to show $\Vert f-f_n\Vert\to 0$. Note that $f_n(a)\to f(a)$, we need to show $V_a^n(f-f_n)\to 0$. Given $\epsilon>0$, we choose $N$ such that $\Vert f_n-f_m\Vert < \epsilon$ for all $n\geq N$. Then
\begin{align*}
	\sum_{j=1}^k\vert (f_m-f_n)(x_j) - (f_m-f_n)(x_{j-1})\vert < \epsilon
\end{align*}
holds for all partition $a=x_0<x_1<\cdots<x_n=b$ and all $n,m\geq N$. Let $m\to\infty$. Since $f_n$ converges to $f$ pointwise, we have $\Vert f-f_n\Vert <\epsilon$, as desired.
\vspace{0.10cm}

(ii) To show $V_0([a,b])$ is Banach, it suffices to show that $V_0([a,b])$ is a closed subspace of $V([a,b])$. Let $f_n$ be a sequence of functions in $V_0([a,b])$ that converges to $f\in V([a,b])$ in sense that $\Vert f_n-f\Vert\to 0$. It suffices to show that $f$ is right-continuous. 

Let $x\in(a,b)$ and $\epsilon>0$ be given. Then there exists $N$ such that $\Vert f - f_N\Vert <\epsilon/3$, which implies
\begin{align*}
\vert f(x+h) - f(x)\vert &\leq \vert f(x+h) - f_N(x+h)\vert + \vert f_N(x+h) - f_N(x)\vert + \vert f_N(x) - f(x)\vert\\
&\leq \vert f_N(x+h) - f_N(x)\vert + 2\Vert f_N - f\Vert\\
&< \vert f_N(x+h) - f_N(x)\vert + 2\epsilon/3.
\end{align*}
Moreover, by right continuity of $f_N$, there exists $\delta > 0$ such that $\vert f_N(x+h) - f_N(x)\vert < \epsilon/3$ for all $h\in(0.\delta)$. Hence $\vert f(x+h) - f(x)\vert < \epsilon$ for all $h\in(0,\delta)$. As a result, $\lim_{h\to 0^+}\vert f(x+h)-f(x)\vert = 0$, which implies the right continuity of $f$.
\end{proof}


\paragraph{Theorem 1.56.\label{thm:1.56}} Let $(X,\Vert\cdot\Vert)$ be a finite-dimensional normed space. Then $X$ is complete.
\begin{proof}
Suppose $\dim X=n$. Choose a basis of $X:e_1,\cdots,e_n$. We claim that there exists $c_1,c_2>0$ such that for all $x=\sum_{i=1}^n x_ie_i\in X$,
\begin{align*}
	c_1\left(\sum_{i=1}^n x_i^2\right) \leq \Vert x\Vert \leq c_2\left(\sum_{i=1}^n x_i^2\right).
\end{align*}
We consider the unit sphere 
\begin{align*}
	S^{n-1}=\left\{\sum_{i=1}^n x_ie_i:x_1^2 + \cdots + x_n^2=1\right\}
\end{align*}
in $\mathbb{R}^n$, and the map $f:S^{n-1}\to\mathbb{R},\ (x_1,\cdots,x_n)\mapsto \Vert \sum_{i=1}^n x_ie_i\Vert$, which is continuous. By compactness of $S^{n-1}$, there exists $c_1,c_2>0$ such that $f(S^{n-1})\subset[c_1,c_2]$. By homogeneity of norm, the claim is satisfied.
\vspace{0.1cm}

As a result, any sequence in $X$ converges relative to $\Vert\cdot\Vert_2$ also converges relative to $\Vert\cdot\Vert$. Since the space $(\mathbb{R}^n,\Vert\cdot\Vert_2)$ is complete, $(X,\Vert\cdot\Vert)$ is also complete. 
\end{proof}


\paragraph{Corollary 1.57.\label{cor:1.57}} Let $L$ be a finite-dimensional subspace of a normed space $X$. Then $L$ is closed in $X$.

\paragraph{Example 1.58.\label{example:1.58}} The space $(C([0,1]),\Vert\cdot\Vert_1)$, which is a subspace of $L^1([0,1])$, is not complete. Define
\begin{align*}
	f_n(x)=\begin{cases}
		1,\ 0\leq x\leq \frac{1}{2},\\
		1-n(x-1/2),\ \frac{1}{2}\leq x\leq \frac{1}{2} + \frac{1}{n},\\
		0,\ \frac{1}{2} + \frac{1}{n}\leq x\leq 1,
	\end{cases}
\end{align*}
which converges to $\chi_{[0,1/2]}$ pointwise. As a result, $\Vert f_n-\chi_{[0,1/2]}\Vert = 1/2n \to 0$. Thus we obtain a Cauchy sequence in $C([0,1])$ that does not converges in $(C([0,1]),\Vert\cdot\Vert_1)$.

\paragraph{} Now we introduce the nested sequence theorem.
\paragraph{Theorem 1.59\label{thm:1.59}} (Nested sphere theorem). Let $(X,d)$ be a complete metric space. Let
\begin{align*}
	B_n=\left\{x\in X:d(x,x_n)\leq\epsilon_n\right\}
\end{align*}
be a sequence of monotone decreasing closed spheres: $B_1\supset B_2\supset \cdots\supset B_n\supset B_{n+1}\supset\cdots$. If $\lim_{n\to\infty} \epsilon_n = 0$, then there exists a unique $\xi\in\bigcap_{n=1}^\infty B_n$.
\begin{proof}
For any $n\geq m$, $x_n\in B_n\subset B_m$, then $d(x_n,x_m) \leq \epsilon_n$. Since $\lim_{n\to\infty}\epsilon_n=0$, $(x_n)$ is a Cauchy sequence in $X$, which converges to some $x$ by completeness of $X$. Let $m\to\infty$, we have $d(x,x_n)\leq\epsilon_n$, which implies $x\in B_n$ for all $n\in \mathbb{N}$. Hence $x\in\bigcup_{n=1}^\infty B_n$.

To show uniqueness, let $y\in\bigcup_{n=1}^\infty B_n$. Then $x,y\in B_n$ for all $n\in\mathbb{N}$, and $d(x,y)\leq 2\epsilon_n\to 0$.
\end{proof}

The depiction of nested sequence also implies completeness of the corresponding metric space.

\paragraph{Theorem 1.60.\label{thm:1.60}} Let $(X,d)$ be a metric space in which the nested sphere theorem (\hyperref[thm:1.59]{Theorem 1.59}) holds. Then $(X,d)$ is complete. 
\begin{proof}
Let $(x_n)$ be a Cauchy sequence in $X$, we choose a subsequence $(x_{n_k})$ such that $d(x_{n_k},x_{n_{k+1}})\leq 2^{-k}$. Then for all $m\geq k$, $d(x_{n_k},x_{n_m})\leq 2^{-k+1}$. We choose sequence of closed sphere $B_k=B(x_{n_k},2^{-k+1})$, then we have $B_1\supset B_2\supset \cdots$ and $\lim_{k\to\infty}2^{-k+1}=0$. As a result, there exists a unique $x\in\bigcup_{n=1}^\infty B_n$ to which $(x_{n_k})$ converges.
\end{proof}

\subsubsection{Completion}
We consider the procedure from incomplete to complete space.
\paragraph{Definition 1.61\label{def:1.61}} (Completion). Let $(X,d)$ be a metric space. A complete metric space $(Y,\tilde{d})$ is said to be a \textit{completion} of $(X,d)$, if there exists an injective mapping $\iota:X\to Y$ such that (i) $\iota$ is isometric, i.e. $\tilde{d}(\iota(x),\iota(x^\prime))=d(x,x^\prime)$ for any pair $x,x^\prime\in X$, and (ii) $\overline{\iota(X)}=Y$. In this case, $\iota$ is called an \textit{imbedding}.

\paragraph{} The following theorem states that every incomplete metric space has at least one completion.

\paragraph{Theorem 1.61\label{thm:1.61}} (Existence of a completion). Let $(X,d)$ be a metric space. Then there exists a completion of $(X,d)$. Namely, there exists an isometric imbedding from $X$ to a complete metric space.
\begin{proof}
	We construct a complete metric space which consists of equivalence classes of Cauchy sequences in $X$.
	\vspace{0.1cm}
	
	\textit{Step I:} Let $Y^\prime$ be the set of all Cauchy sequences $\mathbf{x}=(x_1,x_2,\cdots)$ in $X$. Let $d^\prime(\mathbf{x},\mathbf{y}):=\lim_{n\to\infty}d(x_n,y_n)$. Then $d^\prime$ is a pseudometric on $Y^\prime$, that is, $d^\prime:Y^\prime\times Y^\prime\to\mathbb{R}_+$ satisfies symmetry and triangle inequality.
	
	\vspace{0.1cm}
	\textit{Step II:} Define a relation $\sim$ on $Y^\prime$: for $\mathbf{x}=(x_n)$ and $\mathbf{y}=(y_n)$ in $Y^\prime$, 
	\begin{align*}
		\mathbf{x}\sim\mathbf{y}\ \overset{\mathrm{def.}}{\Leftrightarrow}\ \lim_{n\to\infty}d(x_n,y_n)=0.
	\end{align*}
	It is clear that $\sim$ is an equivalence relation on $Y^\prime$, i.e., $\sim$ has reflexivity, symmetry and transitivity. Let $\widetilde{Y}=Y^\prime/\sim$ be the set of equivalence classes on $Y^\prime$, and define $\tilde{d}:\widetilde{Y}\times\widetilde{Y}\to\mathbb{R}_+$ as
	\begin{align*}
		\tilde{d}([\mathbf{x}],[\mathbf{y}])=\lim_{n\to\infty} d(x_n,y_n).
	\end{align*}
	Note that $\tilde{d}([\mathbf{x}],[\mathbf{y}])=d^\prime(\mathbf{x},\mathbf{y})$. Following Step I, $\tilde{d}$ is a metric on $\widetilde{Y}$.
	\vspace{0.1cm}
	
	\textit{Step III:} Define $\iota:X\to\widetilde{Y},x\mapsto[(x,x,\cdots)]$, which maps a point of $X$ to an equivalence class of a constant sequence. Clearly, $\tilde{d}(\iota(x),\iota(y))=d(x,y)$, which implies that $\iota$ is an isometric imbedding.
	
	Now we show that $\overline{\iota(X)}=\widetilde{Y}$. Given any Cauchy sequence $\mathbf{x}=(x_n)\in Y^\prime$, we have
	\begin{align*}
		\lim_{n\to\infty}\tilde{d}(\iota(x_n),[\mathbf{x}])=\lim_{n,m\to\infty} d(x_n,x_m) = 0,
	\end{align*}
	which implies $[\mathbf{x}]\in\overline{\iota(X)}$. Since $\mathbf{x}$ is arbitrary, we have $\overline{\iota(X)}=\widetilde{Y}$.
	
	\vspace{0.1cm}
	\textit{Step IV:} It remains to show the completeness of $(\widetilde{Y},\tilde{d})$. By \hyperref[lemma:1.53]{Lemma 1.53 (iii)}, it suffices to show that every Cauchy sequence in $\iota(X)$ converges in $\widetilde{Y}$.
	
	Let $\{[\mathbf{x}^{(n)}]\}_{n\in\mathbb{N}}$ be a Cauchy sequence in $\iota(X)$, where $\mathbf{x}^{(n)}=(x_n,x_n,\cdots)$ for each $n\in\mathbb{N}$. By definition, $\tilde{d}([\mathbf{x}^{(n)}],[\mathbf{x}^{(m)}]) = d(x_n,x_m)$, which implies that $\mathbf{x}=(x_n)$ is a Cauchy sequence in $X$. Moreover,
	\begin{align*}
		\lim_{n\to\infty}\tilde{d}\left([\mathbf{x}^{(n)}],[\mathbf{x}]\right) = \lim_{n\to\infty}\left[\lim_{k\to\infty} d(x_n,x_k)\right] = 0,
	\end{align*}
	which implies $[\mathbf{x}^{(n)}]\to[\mathbf{x}]\in\widetilde{Y}$. Therefore we obtain a completion of $X$.
\end{proof}

By construction, we showed that every metric space has at least one completion. Naturally, we wonder if the completion is unique. We have the following theorem.

\paragraph{Theorem 1.62\label{thm:1.62}} (Uniqueness of the completion). The completion of a metric space $(X,d)$ is uniquely determined up to an isometry. Namely, if $\iota_1:X\to Y_1=\overline{\iota_1(X)}$ and $\iota_2:X\to Y_2=\overline{\iota_2(X)}$ are two isometric imbeddings from $X$ to a complete metric space, then there exists an isometric bijection from $Y_1$ to $Y_2$.
\begin{proof}
	\textit{Step I:} Define map $\phi_0:\iota_1(X)\to\iota_2(X)$, $\iota_1(x)\mapsto\iota_2(x)$, which is bijective and isometric from $\iota_1(X)$ to $\iota_2(X)$. We extend $\phi_0$ to $\phi:Y_1\to Y_2$ as follows: Given $y_1\in Y_1$, choose a sequence $(x_n)$ of points of $X$ such that $d_{Y_1}(\iota_1(x_n),y_1)\to 0$, which is feasible because $Y_1=\overline{\iota_1(X)}$, and define $$\phi(y_1)=\lim_{n\to\infty}\phi_0(\iota_1(x_n))=\lim_{n\to\infty}\iota_2(x_n).$$
	
	\textit{Step II:} check that $\phi$ is well-defined. Since $(\iota_1(x_n))$ converges to $y_1\in Y_1$, it is a Cauchy sequence in $Y_1$. Note that $\iota_1$ and $\iota_2$ are isometric, $(x_n)$ is a Cauchy sequence in $X$, and $(\iota_2(x_n))$ is a Cauchy sequence in $Y_2$. By completeness of $Y_2$, $(\iota_2(x_n))$ converges to some point $y_2$ of $Y_2$.
	
	Suppose $(x_n^\prime)$ is another sequence of points of $X$ such that $\iota_1(x_n^\prime)\to y_1$. Repeat the above procedure, there exists $y_2^\prime\in Y_2$ such that $\iota_2(x^\prime_n)\to y_2^\prime$. Moreover,
	\begin{align*}
		d_{Y_2}(y_2,y_2^\prime) = \lim_{n,m\to\infty}d_{Y_2}(\iota_2(x_n),\iota_2(x_m^\prime)) = \lim_{n,m\to\infty} d(x_n,x^\prime_m) = \lim_{n,m\to\infty}d_{Y_1}(\iota_1(x_n),\iota_1(x_m^\prime)) = d_{Y_1}(y_1,y_1)=0.
	\end{align*}
	Hence $y_2=y^\prime_2$. Therefore, $\phi:Y_1\to Y_2$ is well-defined and agrees with $\iota_2\circ\iota_1^{-1}$ on $\iota_1(X)$.
	\vspace{0.1cm}
	
	\textit{Step III:} It remains to show that $\phi$ is isometric. Given $y,y^\prime\in Y_1$, we choose two sequences $(x_n)$ and $(x_n^\prime)$ from $X$ such that $\iota_1(x_n)\to y$ and $\iota_1(x_n^\prime)\to y^\prime$. Then we have
	\begin{align*}
		d_{Y_2}(\phi(y),\phi(y^\prime))=\lim_{n,m\to\infty}d_{Y_2}(\iota_2(x_n),\iota_2(x_m^\prime)) = \lim_{n,m\to\infty} d(x_n,x^\prime_m) = \lim_{n,m\to\infty}d_{Y_1}(\iota_1(x_n),\iota_1(x_m^\prime)) = d_{Y_1}(y,y^\prime).
	\end{align*}
	Hence $\phi$ is an isometric bijection from $Y_1$ to $Y_2$.
\end{proof}

\paragraph{Remark.} Combining \hyperref[thm:1.61]{Theorem 1.61} and \hyperref[thm:1.62]{Theorem 1.62}, we conclude that for every metric space, there exists a unique completion up to an isometry.

\subsubsection{Contraction mappings and Banach Fixed Point Theorem}
\paragraph{Review: Newton's method.} To solve a equation $f(x)=0,x\in[a,b]$, where $f$ is differentiable, define
\begin{align*}
	T(x) = x - \frac{f(x)}{f^\prime(x)}.
\end{align*}
We choose $x_0\in[a,b]$, and update $x_{n+1}=T(x_n)$. In appropriate conditions, $x_n\to x$ such that $f(x)=0$.
\paragraph{Review: Picard's method for ordinary differential equations.} To solve the ODE
\begin{align*}
	\begin{cases}
		\frac{\mathrm{d}y}{\mathrm{d}x} = f(x,y),\\
		y(x_0) = y_0, 
	\end{cases}\tag{1.19}\label{eq:1.19}
\ \Rightarrow\ 
	y(x) = y_0 + \int_{x_0}^x f(s,y(s))\mathrm{d}s.
\end{align*}
For appropriate $f$, let $\varphi_0(x)\equiv y_0$. Update:
\begin{align*}
	\varphi_{n+1}(x)=y_0 + \int_{x_0}^x f(s,\phi_n(x))\mathrm{d}s.
\end{align*}
Then $\varphi_n\rightrightarrows\varphi$, where $\varphi$ is the solution of \hyperref[eq:1.19]{ODE (1.19)}.

\paragraph{Definition 1.63\label{def:1.63}} (Fixed points). Let $X$ be a nonempty set, and let $\phi:X\to X$. If there exists $x^*\in X$ such that $\phi(x^*)=x^*$, then $x^*$ is said to be a \textit{fixed point} of $X$.

\paragraph{Definition 1.64\label{def:1.64}} (Contraction mappings). Let $(X,d)$ be a metric space, and let $\phi:X\to X$. If there exists $\gamma\in (0,1)$ such that $d(\phi(x),\phi(y)) < \gamma d(x,y)$ for all $x,y\in X$, then $\phi$ is said to be a \textit{contraction mapping} on $X$.

\paragraph{Lemma 1.65.\label{lemma:1.65}} A contraction mapping is continuous.
\begin{proof}
	Given $x_n\to x$, $d(\phi(x_n),\phi(x))\leq\gamma d(x_n,x)\to 0$ as $n\to\infty$.
\end{proof}

\paragraph{Theorem 1.66\label{thm:1.66}} (Banach fixed point theorem). Let $(X,d)$ be a complete metric space. Let $\phi:X\to X$ be a contraction mapping on $X$. Then $\phi$ has a unique fixed point.
\begin{proof}
Choose $x_0\in X$. Let $x_n=\phi(x_{n-1})=\phi^n(x_0)$ for all $n\in\mathbb{N}$. We claim that $(x_n)$ is a Cauchy sequence in $X$. For all $n\in\mathbb{N}$,
\begin{align*}
d(x_{n+1},x_n) = d\left(\phi(x_n),\phi(x_{n-1})\right) < \gamma d(x_n,x_{n-1})<\cdots < \gamma^n d(x_1,x_0). 
\end{align*}
For any $n,p\in\mathbb{N}$, by triangle inequality,
\begin{align*}
	d(x_{n+p},x_n)&\leq d(x_{n+p},d_{n+p-1}) + d(x_{n+p-1},d_{n+p-2}) +\cdots + d(x_{n+1},d_{n})\\
	&\leq \left(\gamma^{n+p-1} + \gamma^{n+p-2} + \cdots + \gamma^n\right) d(x_1,x_0) < \frac{\gamma^n}{1-\gamma}d(x_1,x_0).\tag{1.20}\label{eq:1.20}
\end{align*}
Then $(x_n)$ is a Cauchy sequence, which converges to some $x^*\in X$. Let $p\to\infty$ in \hyperref[eq:1.20]{(1.20)}, then
\begin{align*}
	d(x^*,x_n)\leq\frac{\gamma^n}{1-\gamma}d(x_1,x_0).
\end{align*}
As a result, $x$ is a fixed point of $\phi$:
\begin{align*}
	\phi(x^*) = \phi\left(\lim_{n\to\infty}x_n\right) = \lim_{n\to\infty} x_{n+1} = x^*.
\end{align*}
To show the uniqueness, let $x^\prime$ be a fixed point of $\phi$. Then
\begin{align*}
	d(x^\prime,x^*) = d(\phi(x^\prime),\phi(x^*)) < \gamma d(x^\prime,\phi(x^*)),
\end{align*}
which implies $d(x^\prime,x^*)=0$, and $x^\prime=x^*$.
\end{proof}
\paragraph{Remark.} If $X$ is not complete, Banach fixed point theorem does not hold. Consider 
$$\phi:(0,\infty)\to(0,\infty),\ x\mapsto \gamma x,\ \text{where}\ 0< \gamma < 1.$$ 
Furthermore, if $\gamma=1$ in \hyperref[def:1.64]{Definition 1.64}, Banach fixed point theorem does not hold. Consider
$$\phi:[0,\infty)\mapsto[0,\infty),\ x\mapsto x+\frac{1}{1+x}.$$

\paragraph{Theorem 1.67\label{thm:1.67}} (Generalization). Let $(X,d)$ be a complete metric space, and let $\phi:X\to X$ is a map on $X$. If there exists $n\in\mathbb{N}$ such that $\phi^n$ is a contraction mapping, then $\phi$ has a unique fixed point.
\begin{proof}
Denote $\psi = \phi^n$. By \hyperref[thm:1.66]{Theorem 1.66}, $\psi$ has a unique fixed point $x^*\in X$. Also,
\begin{align*}
	\phi(x^*) = \phi\left(\psi(x^*)\right) = \phi^n(x^*) = \psi\left(\phi(x^*)\right)
\end{align*}
is a fixed point of $\psi$, which implies $\phi(x^*)=x^*$. Hence $x^*$ is a fixed point of $\psi$. To show the uniqueness, let $x^\prime$ be a fixed point of $\phi$. Then $x^\prime$ is a fixed point of $\psi$, which implies $x^\prime=x^*$.
\end{proof}

We present some applications of Banach fixed point theorem.
\paragraph{Example 1.68\label{example:1.68}} (Implicit function theorem). Let $f:\mathbb{R}^2\to\mathbb{R}$ be continuous on $\mathcal{D} = [a,b]\times\mathbb{R}$, and there exists $m<M$ such that $0<m\leq D_y f(x,y)\leq M$ for all $(x,y)\in\mathcal{D}$. Then there exists unique continuous $\varphi\in C([a,b])$ such that $f(x,\varphi(x))=0$.
\begin{proof}
Define $A:C([a,b])\to C([a,b])$ in $(C([a,b]).\Vert\cdot\Vert)$ by
\begin{align*}
	(A\varphi)(x):=\varphi(x) - \frac{1}{M} f(x,\varphi(x)).
\end{align*}
Then $A$ is a contraction on $(C([a,b]).\Vert\cdot\Vert)$:
\begin{align*}
	\Vert A\varphi_1 - A\varphi_2\Vert_\infty &= \sup_{x\in[a,b]}\vert A\varphi_1(x) - A\varphi_2(x)\vert\\
	&= \sup_{x\in[a,b]}\left\vert \varphi_1(x)-\varphi_2(x) - \frac{1}{M}\left(f(x,\varphi_2(x))-f(x,\varphi_1(x))\right) \right\vert\\
	&= \sup_{x\in[a,b]}\left\vert 1- \frac{1}{M}D_yf(x,\xi_x)\right\vert\vert\varphi_1(x) -\varphi_2(x)\vert \tag{By mean value theorem}\\
	&\leq \left(1-\frac{m}{M}\right)\Vert\varphi_2-\varphi_1\Vert_\infty.
\end{align*}
By \hyperref[thm:1.66]{Theorem 1.66}, there exists unique $\varphi\in C([a,b])$ such that $A\varphi=\varphi$, which implies $f(x,\varphi(x))=0$.
\end{proof}

\paragraph{Example 1.69\label{example:1.69}} (Volterra integral equation). Suppose $f\in C([a,b])$, and $K\in C(\mathcal{D})$, where $$\mathcal{D}=\left\{(x,y)\in\mathbb{R}^2:a\leq x\leq b, a\leq y\leq x\right\}.$$
Then for all $\lambda\in\mathbb{R}$, the Volterra integral equation
\begin{align*}
	\varphi(x) = f(x) +\lambda\int_a^x K(x,y)\varphi(y)\,dy
\end{align*}
has a unique continuous solution in $C([a,b])$.
\begin{proof}
Set $M=\sup_{x,y\in\mathcal{D}}\vert K(x,y)\vert$. Define $B:C([a,b])\to C([a,b])$ by
\begin{align*}
	(B\varphi)(x) = f(x) + \lambda\int_a^x K(x,y)\varphi(y)\,dy.
\end{align*}
For all $\varphi_1,\varphi_2\in C([a,b])$ and all $x\in[a,b]$,
\begin{align*}
	\left\vert(B\varphi_2)(x) - (B\varphi_1)(x)\right\vert &= \vert\lambda\vert\left\vert\int_a^x K(x,y)(\varphi_2(y)-\varphi_1(y))\,dy\right\vert\\
	&\leq M(x-a)\left\vert\lambda\right\vert\Vert\varphi_2-\varphi_1\Vert_\infty,
\end{align*}
\begin{align*}
	\left\vert(B^2\varphi_2)(x) - (B^2\varphi_1)(x)\right\vert &= \vert\lambda\vert\left\vert\int_a^x K(x,y)\left[(B\varphi_2)(y)-(B\varphi_1)(y)\right]\,dy\right\vert\\
	&\leq \left\vert\lambda\right\vert\left\vert\int_a^x M\cdot M(y-a)\left\vert\lambda\right\vert\Vert\varphi_2-\varphi_1\Vert_\infty\,dy\right\vert\\
	&\leq \frac{1}{2}M^2(x-a)^2\left\vert\lambda\right\vert^2\Vert \varphi_2-\varphi_1\Vert_\infty,
\end{align*}
\begin{align*}
	\cdots,
\end{align*}
by induction,
\begin{align*}
	\left\vert(B^n\varphi_2)(x) - (B^n\varphi_1)(x)\right\vert = \frac{1}{n!}M^n(x-a)^n\left\vert\lambda\right\vert^n\Vert \varphi_2-\varphi_1\Vert_\infty.
\end{align*}
for all $n\in\mathbb{N}$. Then for efficiently large $n$,
\begin{align*}
	\frac{1}{n!}M^n(b-a)^n\left\vert\lambda\right\vert^n < 1,
\end{align*}
and $B^n$ is a contraction mapping. By \hyperref[thm:1.67]{Theorem 1.67}, $B$ has a unique fixed point $\varphi^*$, which is the solution of Volterra integral equation.
\end{proof}

\newpage
\subsection{Compactness and Sequential Compactness}
\paragraph{Review: Compactness and sequential compactness.} Given a subset $A$ of a topological space $X$, $A$ is said to be \textit{compact} if every open cover of $A$ has a finite subcover, and $A$ is said to be \textit{sequentially compact} if every sequence of points of $A$ has a subsequence that converges to some point of $A$.

In a metric space $X$, a subset $A$ is compact if and only if it is sequentially compact.

\paragraph{Review: Relatively compactness and relative sequential compactness.} Let $(X,d)$ be a metric space, and let $A$ be a subset of $X$. 
\begin{itemize}
	\item[(i)] $A$ is said to be \textit{relatively compact} (or \textit{precompact}) if its closure is compact;
	\item[(ii)] $A$ is said to be \textit{relatively sequentially compact}, if for every sequence $(x_n)\subset A$ there exists a subsequence that converges to some $x\in X$. (Clearly, $x\in\overline{A}$.)
\end{itemize}

The following proposition reveals the equivalence of these two definitions.
\paragraph{Proposition 1.70.\label{prop:1.70}} Let $(X,d)$ be a metric space. Let $A\subset X$. Then $A$ is relatively sequentially compact if and only if $A$ is relatively compact.
\begin{proof}
	Suppose that $\overline{A}$ is compact. Then $\overline{A}$ is also sequentially compact by \hyperref[thm:4.36]{Theorem 4.36}, and the relative sequential compactness of $A$ is clear.
	
	Conversely, suppose that $A$ is relatively sequentially compact. We show that $\overline{A}$ is sequentially compact. Let $(x_n)$ be a sequence of points of $\overline{A}$. For every $n\in\mathbb{N}$, since $x_n\in\overline{A}$, we can choose $y_n\in A$ such that $d(x_n,y_n)<1/n$. By relative sequential compactness of $A$, there is a subsequence $(y_{n_k})$ with $y_{n_k}\to y\in\overline{A}$. 
	
	Fix $\epsilon > 0$. We first choose $K_1\in\mathbb{N}$ such that $d(y_{n_k},y)<\epsilon/2$ for all $k\geq K_1$. Then we choose $K_2\in\mathbb{N}$ such that $n_k > 2/\epsilon$ for all $k\geq K_2$, which implies $d(x_{n_k},y_{n_k})<\epsilon/2$. Hence $d(x_{n_k},y) < \epsilon$ for all $k\geq\max\{K_1,K_2\}$, and the subsequence $(x_{n_k})$ converges to $y\in\overline{A}$ as $k\to\infty$. Therefore $\overline{A}$ is sequentially compact.
\end{proof}

\paragraph{Review: Totally bounded sets.} Let $(X,d)$ be a metric space, and let $A$ be a subset of $X$.
\begin{itemize}
	\item $A$ is said to be \textit{bounded}, if its diameter $\mathrm{diam}(A):=\sup_{x,x^\prime\in A}d(x,x^\prime)$ is finite. 
	\item Given $\epsilon > 0$, an $\epsilon$\textit{-cover} of $A$ is a collection of open balls of radius $\epsilon$ of which the union covers $A$. An $\epsilon$-net is the centers of balls in an $\epsilon$-cover.
	\item If for all $\epsilon>0$, $A$ has a finite $\epsilon$-net, then $A$ is said to be \textit{totally bounded}.
\end{itemize}
Let $A$ be a totally bounded set. Clearly, $\overline{A}$ is also totally bounded. Fix $\epsilon>0$, we first cover $A$ by finitely many open balls $O(x_j,\epsilon/2),\ j=1,\cdots,n$. For any $y\in\overline{A}$, there exists $x\in A$ such that $d(x,y)<\epsilon/2$. As a result, we can cover $\overline{A}$ by expanding the radii of the balls to $\epsilon$.

The following theorem reveals the equivalence between totally bounded sets and relatively compact sets in metric spaces.

\paragraph{Theorem 1.71\label{thm:1.71}} (Hausdorff). Let $X$ be a metric space. Let $A\subset X$.
\begin{itemize}
	\item[(i)] If $A$ is relatively compact, then $A$ is totally bounded.
	\item[(ii)] If $X$ is complete and $A$ is totally bounded, then $A$ is relatively compact.
\end{itemize}
\begin{proof}
	(i) Consider a cover of $\overline{A}$ consists of open $\epsilon$-balls, the conclusion is clear by finding a finite subcover.
	
	(ii) We shall prove that $\overline{A}$ is sequentially compact. Let $(x_n)$ be a sequence of points, it suffices to construct a subsequence of $(x_n)$ that is a Cauchy sequence, which converges by completeness of $\overline{A}$.
	
	We first cover $\overline{A}$ by finitely many $1$-balls. At least one of these balls, denoted by $O_1$, contains infinitely many elements of $(x_n)$. We denote by $J_1=\{n\in\mathbb{N}:x_n\in O_1\}$ the index set of these elements.
	
	Next, cover $\overline{A}$ by finitely may $1/2$-balls. Since $J_1$ is infinite, at least one of these balls, denoted by $O_2$, contains infinitely many elements of $\{x_n:n\in J_1\}$. Similarly, let $J_2=\{n\in J_1:x_n\in O_2\}$. By repeating this procedure, we obtain a finite cover of $\overline{A}$ by $1/k$-balls and an infinite index set $J_k=\{n\in J_{k-1}:x_n\in O_{k}\}$ for arbitrarily large $k$, with $J_k\subset J_{k-1}\subset\cdots\subset J_1$.
	
	Choose $n_1\in J_1$. Given $n_{k-1}$, choose $n_k\in J_k$ with $n_k > n_{k-1}$, which is feasible because $J_k$ is infinite. For any $l,m\geq k$, $n_l,n_m\in J_k$, and $x_{n_l},x_{n_m}\in O_k$, implying $d(x_{n_l},x_{n_m})<2/k$. Hence the subsequence $(x_{n_k})$ is a Cauchy sequence, as desired.
\end{proof}

\paragraph{Theorem 1.72.\label{thm:1.72}} A metric space $X$ is complete if every totally bounded set in $X$ is relatively compact.
\begin{proof}
	Let $(x_n)$ be a Cauchy sequence in $X$. Given $\epsilon>0$, there exists $N$ such that $d(x_n,x_m)<\epsilon$ for all $n,m\geq N$. Hence $O(x_k,\epsilon),\ k=1,\cdots,N$ is an $\epsilon$-net of $\{x_n,n\in\mathbb{N}\}$.
	
	By \hyperref[thm:1.71]{Theorem 1.71}, every Cauchy sequence $(x_n)$ in $X$ is relatively sequentially compact, and the completeness follows from subsequence criterion (\hyperref[lemma:1.53]{Lemma 1.53}).
\end{proof}

\paragraph{Lemma 1.73.\label{lemma:1.73}} Any relatively compact set is separable.
\begin{proof}
	Let $A$ be a relatively compact subset of a metric space $X$. Since $A$ is totally bounded, we can cover it by finitely many $1$-balls. We denote the centers of these balls by $C_1$. Similarly, we can cover $A$ by finitely many $1/n$-balls for arbitrarily large $n\in\mathbb{N}$, and extract their centers $C_n$. Then $\bigcup_{n=1}^\infty C_n$, being the union of countably many finite sets, is a countable dense set in $X$.
\end{proof}

\paragraph{Example 1.74.\label{example:1.74}} We know that in a finite-dimensional space $\mathbb{R}^n$, the closed unit ball \begin{align*}
	B=\left\{(x_1,\cdots,x_n):x_1^2 + \cdots + x_n^2 \leq 1\right\}
\end{align*}
is compact. However, this does not hold when the dimension becomes infinite.
\vspace{0.1cm}

We give a counterexample here. Let $l^2:=\left\{\mathbf{x}=(x_1,x_2,\cdots):\sum_{n=1}^\infty \vert x_n\vert^2<\infty\right\}$ be the set of square-summable real sequences. Then $l^2$ is a Banach space under norm
\begin{align*}
	\Vert\mathbf{x}\Vert_2 = \sqrt{\sum_{k=1}^\infty\vert x_k\vert^2}.
\end{align*}
Consider the closed unit ball
\begin{align*}
	B=\left\{\mathbf{x}=(x_1,x_2,\cdots)\in l^2:\sum_{k=1}^\infty\vert x_k\vert^2 \leq 1\right\}.
\end{align*}
We let $\mathbf{e}_k=(0,\cdots,0,\underset{k\text{-th}}{1},0,\cdots)$ be the unit vector whose $k$-th element is 1, and choose open balls \begin{align*}
	O=\{\mathbf{x}\in l^2:\Vert\mathbf{x}\Vert_2 <1\},\quad O_k=\left\{\mathbf{x}\in l^2:\Vert\mathbf{x}-\mathbf{e}_k\Vert^2 < 1/2\right\},\ k\in\mathbb{N}.
\end{align*}
And for each $\mathbf{x}\in E:= B\backslash\left(O\cup\left(\bigcup_{k=1}^\infty O_k\right)\right)$, define $O_{\mathbf{x}}=\{\mathbf{y}\in l^2:\Vert\mathbf{y}-\mathbf{x}\Vert_2< 1/2\}$. Then $\mathbf{e}_k\notin O_\mathbf{x}$ for eack $k$. As a result, we obtain an open cover
\begin{align*}
	O\cup \left(\bigcup_{k=1}^\infty O_k\right)\cup\left(\bigcup_{\mathbf{x}\in E}O_\mathbf{x}\right)
\end{align*}
of $B$. Moreover, every open ball in this cover contains at most one $\mathbf{e}_k$.

\paragraph{Lemma 1.75\label{lemma:1.75}} (F.Riesz). Let $X$ be a normed space, and let $A$ be a closed proper subspace of $X$, i.e. $A\neq X$. Then for all $0<\epsilon<1$, there exists unit vector $x_0\in X$ such that $d(x_0,A)>\epsilon$.
\begin{proof}
Choose $\bar{x}\in X\backslash A$. Since $A$ is a closed subspace, $d(\bar{x},A) > 0$, and there exists $x^\prime\in A$ such that $\Vert\bar{x}-x^\prime\Vert < d(\bar{x},A)/\epsilon$. We define
\begin{align*}
	x_0 = \frac{\bar{x}-x^\prime}{\Vert\bar{x}-x^\prime\Vert}\notin A.
\end{align*}
For any $x\in A$, we have
\begin{align*}
	& x-x_0 = x - \frac{\bar{x}-x^\prime}{\Vert\bar{x}-x^\prime\Vert} = \underbrace{x + \frac{x^\prime}{\Vert\bar{x}-x^\prime\Vert}}_{\in A} - \underbrace{\frac{\bar{x}}{\Vert\bar{x}-x^\prime\Vert}}_{\notin A}\\
	&\Vert x-x_0\Vert \geq d\left(\frac{\bar{x}}{\Vert\bar{x}-x^\prime\Vert}, A\right) = \frac{d\left(\bar{x}, A\right)}{\Vert\bar{x}-x^\prime\Vert} > \epsilon.
\end{align*}
Since $x$ is arbitrary, the result follows.
\end{proof}

\paragraph{Theorem 1.76.\label{thm:1.76}} Let $X$ be a normed space. If $X$ is infinite-dimensional, then the closed unit ball in $X$ is not compact.
\begin{proof}
	Choose $x_1\in X$ with $\Vert x_1\Vert=1$, and let $A_1=\mathrm{span}\,\{x_1\}$. By \hyperref[cor:1.57]{Corollary 1.57} and \hyperref[lemma:1.75]{Lemma 1.75}, choose $x_2\in X$ such that $\Vert x_2\Vert=1$ and $d(x_2,A_1) > 1/2$, and let $A_2=\mathrm{span}\,\{x_1,x_2\}\neq X$. Repeat this procedure, we obtain a sequence $(x_n)$ of unit vectors in $X$. For any $m<n$, we have
	\begin{align*}
		x_m\in A_{n-1},\ x_n\notin A_{n-1},\ d(x_n,x_m) > 1/2.
	\end{align*}
	To obtain an open cover of the closed unit ball in $X$, we take open balls $O=O(0,1)$, $O_n = O(x_n,1/2)$ for every $n\in\mathbb{N}$, and $O_x = O(x,1/2)$ for every $x\notin O\cup\bigcup_{n=1}^n O_n$. Each of them contains at most one element of $\{x_n,n\in\mathbb{N}\}$. Hence there exists no finite subcover.
\end{proof}

It is seen that bounded closed sets in infinite-dimensional spaces are not always compact. We are going to discuss some instances for compact sets in infinite-dimensional spaces. 

\paragraph{Review: Equicontinuity.} Let $X$ be a topological space and let $(Y,d)$ be a metric space. Let $\mathcal{F}$ be a collection of functions $X\to Y$. Given $x_0\in X$, $\mathcal{F}$ is said to be \textit{equicontinuous at} $x_0$ if for each $\epsilon>0$, there exists a neighborhood $U$ of $x_0$ such that $d(f(x), f(x_0)) < \epsilon$ for all $x\in U$ and all $f\in\mathcal{F}$. If $\mathcal{F}$ is equicontinuous at all $x\in X$, then $f$ is said to be \textit{equicontinuous}.

Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces. Let $\mathcal{F}$ be a collection of functions $X\to Y$. $\mathcal{F}$ is said to be \textit{uniformly equicontinuous} if for each $\epsilon>0$, there exists $\delta>0$ such that $d(f(x),f(x^\prime))<\epsilon$ for all $x,x^\prime\in X$ such that $d(x,x^\prime)<\delta$ and all $f\in\mathcal{F}$.

\paragraph{Theorem 1.77\label{thm:1.77}} (Arzelà-Ascoli). Give $C([a,b])$ the uniform topology (induced by $\Vert\cdot\Vert_\infty$). A subset $\mathcal{F}$ of $C([a,b])$ is relatively compact if and only if it is bounded and uniformly equicontinuous.
\begin{proof}
\textit{``If'' case:} Suppose $\mathcal{F}$ is bounded and uniformly equicontinuous. By \hyperref[thm:1.71]{Theorem 1.71}, it suffices to show $\mathcal{F}$ is totally bounded. Given $\epsilon>0$, there exists $\delta>0$ such that $\vert f(x)-f(x^\prime)\vert < \epsilon/3$ for all $\vert x-x^\prime\vert < \delta$. We first choose a partition $a=x_0<x_1<\cdots < x_n = b$ such that $\vert x_j - x_{j-1}\vert < \delta$ for all $j=1,\cdots,n$.

Since $\mathcal{F}$ is bounded, there exists $K$ such that $\max_{x\in[a,b]}\vert f(x)\vert \leq K$ for all $f\in\mathcal{F}$, and
\begin{align*}
	A=\left\{\left(f(x_0),f(x_1),\cdots,f(x_n)\right):f\in\mathcal{F}\right\}\subset\mathbb{R}^{n+1}
\end{align*}
is a bounded set. Note that $A$ is finite-dimensional, it is totally bounded. Then there exist $f_1,\cdots,f_k\in\mathcal{F}$ that form a $\epsilon/3$-net of $A$.

We claim that $\{f_1,\cdots,f_k\}$ is an $\epsilon$-net of $\mathcal{F}$: for any $x\in[a,b]$, it lies in some $[x_{j-1},x_j]$; for any $f\in\mathcal{F}$, there exists $p\in\{1,\cdots,k\}$ such that $\{f(x_j),j=0,1,\cdots,n\}$ lies in the $\epsilon/3$-ball centered at $\{f_p(x_j),j=0,1,\cdots,n\}$.
\begin{align*}
	\vert f(x) - f_p(x)\vert \leq \vert f(x) - f(x_j)\vert + \vert f(x_j) - f_p(x_j)\vert + \vert f_p(x_j) - f_p(x)\vert  < \epsilon.
\end{align*}
As a result, $\{f_1,\cdots,f_k\}$ is a $\epsilon$-net of $\mathcal{F}$, as desired.
\vspace{0.1cm}

\textit{``Only if'' case:} Suppose $\mathcal{F}$ is relatively compact, it is totally bounded. Given $\epsilon>0$, let $\mathcal{N}=\{f_1,\cdots,f_k\}$ be an $\epsilon/3$-net of $\mathcal{F}$ in $C([a,b])$. By compactness of $[a,b]$, any $f_i$ is uniformly continuous on $[a,b]$, and we choose $\delta_i>0$ such that $\vert f(x)-f(x^\prime)\vert < \epsilon/3$ for all $\vert x-x^\prime\vert < \delta$. Let $\delta=\min_{i\in\{1,\cdots,k\}}\delta_i$. Then for any $f\in\mathcal{F}$,
\begin{align*}
	\vert f(x_1) - f(x_2)\vert \leq \vert f(x_1) - f_p(x_1)\vert + \vert f_p(x_1) - f_p(x_2)\vert + \vert f_p(x_2) - f(x_2)\vert < \epsilon,\ \exists f_p\in\mathcal{N}
\end{align*}
Hence $\mathcal{F}$ is uniformly equicontinuous, as desired.
\end{proof}

\paragraph{Theorem 1.78\label{thm:1.78}} (Kolmogorov-Riesz-Fréchet). Let $1\leq p < \infty$. Let $\mathcal{F}$ be a subset of $L^p(\mathbb{R})$. Then $\mathcal{F}$ is relatively compact if and only if the following conditions hold:
\begin{itemize}
	\item[(i)] (Bounded). there exists $M>0$ such that $\sup_{f\in\mathcal{F}}\Vert f\Vert_p \leq M$.
	\item[(ii)] (Equitight). For all $\epsilon>0$, there exists $r>0$ such that
	\begin{align*}
		\int_{\vert x\vert \geq r}\vert f(x)\vert^p dm(x) < \epsilon^p,\ \forall f\in\mathcal{F}.
	\end{align*}
	\item[(iii)] ($L^p$-Equicontinuous). For all $\epsilon>0$, there exists $\delta>0$ such that
	\begin{align*}
		\Vert\tau_h f - f\Vert_p  < \epsilon,\ \forall f\in\mathcal{F},\ h\in(0,\delta).
	\end{align*}
\end{itemize}
\begin{proof}
\textit{``If'' case:} We first suppose the functions $\mathcal{F}$ are supported on $[a,b]$. For any $\delta>0$, define
\begin{align*}
	f^\delta(x):= \frac{1}{2\delta}(f*\chi_{[-\delta,\delta]})(x) = \frac{1}{2\delta}\int_{[-\delta,\delta]} f(x-y)\,dm(y).
\end{align*}
For any $f\in\mathcal{F}$, by Jensen's inequality, we have
\begin{align*}
	\left\vert f^\delta(x) - f(x)\right\vert^p = \left\vert\frac{1}{2\delta}\int_{[-\delta,\delta]}\left(f(x-y)-f(x)\right) dm(y)\right\vert^p \leq \frac{1}{2\delta}\int_{[-\delta,\delta]} \left\vert f(x-y)-f(x)\right\vert^p\,dm(y)
\end{align*}
Given $\epsilon>0$, we choose $\delta$ that satisfies condition (iii):
\begin{align*}
	\int_\mathbb{R}\vert f^\delta(x)-f(x)\vert^p\,dm(x) \leq \frac{1}{2\delta}\int_\mathbb{R}\int_{[-\delta,\delta]}\vert f(x-y)-f(x)\vert^p\,dm(y) = \frac{1}{2\delta}\int_{[-\delta,\delta]}\Vert\tau_y f-f\Vert_p^p\,dm(y) \leq \epsilon^p.
\end{align*}
We still denote by $f^\delta$ the restriction of $f^\delta$ on $[a,b]$. Let $\mathcal{F}^\delta = \{f^\delta:f\in\mathcal{F}\}$. It is bounded and equicontinuous on $[a,b]$: For any $f^\delta\in\mathcal{F}$ and any $x\in[a,b]$,
\begin{align*}
	\vert f^\delta(x)\vert \leq \frac{1}{2\delta}\int_{[-\delta,\delta]} \vert f(x-y)\vert\,dm(y) \leq \left(\frac{1}{2\delta}\int_\mathbb{R} \vert f(x-y)\vert^p\,dm(y)\right)^{1/p}\leq (2\delta)^{-1/p}M.
\end{align*}
To show equicontinuity, fix $\epsilon^\prime>0$, and choose $\delta^\prime$ such that $\Vert\tau_h f-f\Vert < (2\delta)^{1/p}\epsilon^\prime$. Then for any $\vert x_1-x_2\vert < \delta^\prime$,
\begin{align*}
	\left\vert f^\delta(x_1) - f^\delta(x_2)\right\vert &\leq \left(\frac{1}{2\delta}\int_{[-\delta,\delta]} \left\vert f(x_1-y) - f(x_2-y)\right\vert^p\,dm(y)\right)^{1/p}\\
	&\leq \left(\frac{1}{2\delta}\int_\mathbb{R} \left\vert f(t + x_1 -x_2 ) - f(t)\right\vert^p\,dm(t)\right)^{1/p}
	\leq \epsilon^\prime.
\end{align*}
Hence $\mathcal{F}^\delta$ is a bounded and equicontinuous set in $(C([a,b]),\Vert\cdot\Vert_\infty)$. Using Arzelà-Ascoli theorem, we choose an $\epsilon$-net $\mathcal{N}^\delta=\{f_1^\delta,\cdots,f_k^\delta\}$ of $\mathcal{F}^\delta$. Then $\mathcal{N}^\delta$ is an $(b-a)^{1/p}\epsilon$-net in $L^p([a,b])$. Let $\mathcal{N}=\{f:f^\delta\in\mathcal{N}^\delta\}$, then $\mathcal{N}$ is a $\left((b-a)^{1/p}+2\right)\epsilon$-net of $\mathcal{F}$ in $L^p([a,b])$: For any $f\in\mathcal{F}$, choose the closest $f_i\in\mathcal{N}$, then
\begin{align*}
	\Vert f-f_i\Vert_p \leq \Vert f - f^\delta\Vert_p + \Vert f^\delta - f^\delta_i\Vert_p + \Vert f_i^\delta - f_i\Vert_p < (b-a)^{1/p}\epsilon + 2\epsilon.
\end{align*}
Since $\epsilon$ is arbitrary, $\mathcal{F}$ is totally bounded.
\vspace{0.1cm}

Now we consider general $f\in L^p(\mathbb{R})$. For any $\epsilon>0$, by equitightness, choose $R>0$ such that
\begin{align*}
	\int_{\vert x\vert \geq R}\vert f(x)\vert^p\,dm(x) < \left(\frac{\epsilon}{3}\right)^p.
\end{align*}
Then $\mathcal{F}_R=\{f\chi_{[-R,R]}:f\in\mathcal{F}\}$ is also a totally bounded set in $L^p([-R,R])$. Let  
\begin{align*}
\mathcal{N}_R=\left\{f_1\chi_{[-R,R]},\cdots,f_k\chi_{[-R,R]}\right\}
\end{align*}
be an $\epsilon/3$-net of $\mathcal{F}_R$ in $L^p([-R,R])$, then $\mathcal{N}=\{f:f\chi_{[-R,R]}\in\mathcal{N}_R\}$ is an $\epsilon$-net in $L^p(\mathbb{R})$:
\begin{align*}
	\Vert f - f_i\Vert_p = \Vert f - f\chi_{[-R,R]}\Vert_p + \Vert f - f_i\Vert_p + \Vert f_i - f_i\chi_{[-R,R]}\Vert_p < \epsilon. 
\end{align*}
\textit{``Only if'' case:} Let $\mathcal{F}$ be relatively compact. Then $\mathcal{F}$ is totally bounded. Given $\epsilon>0$, choose an $\epsilon/3$-net $\mathcal{N}=\{f_1,\cdots,f_k\}$ of $\mathcal{F}$ in $L^p(\mathbb{R})$. For each $f_i\in\mathcal{N}$, by \hyperref[example:1.48]{Example 1.48 Remark}, there exists $\delta_i$ such that $\Vert\tau_h f_i - f_i\Vert_p < \epsilon/3$ for all $\vert h\vert < \delta_i$. Let $\delta=\min_{i\in\{1,\cdots,k\}}\delta_i$. For any $f\in\mathcal{F}$, there exists $f_i\in\mathcal{N}$ such that
\begin{align*}
	\Vert\tau_h f - f\Vert_p \leq \Vert\tau_h f - \tau_h f_i\Vert_p + \Vert \tau_h f_i - f_i\Vert_p + \Vert f_i - f\Vert_p < \epsilon,\ \forall \vert h\vert < \delta. \tag{iii}
\end{align*}
To show equitightness (ii), choose $r_i$ such that $\int_{\vert x\vert\geq r_i}\vert f_i(x)\vert^p\,dm(x)<2^{-p}\epsilon^p$. Let $r=\max_{i\in\{1,\cdots,k\}}r_i$, then
\begin{align*}
	\left(\int_{\vert x\vert\geq r}\vert f(x)\vert^p\,dm(x)\right)^{1/p} &= \left(\int_{\vert x\vert\geq r}\vert f(x) - f_i(x)\vert^p\,dm(x)\right)^{1/p} + \left(\int_{\vert x\vert\geq r}\vert f_i(x)\vert^p\,dm(x)\right)^{1/p}\\
	&\leq \Vert f-f_i\Vert_p + \left(\int_{\vert x\vert\geq r}\vert f_i(x)\vert^p\,dm(x)\right)^{1/p} < \epsilon.
\end{align*}
Thus we complete the proof.
\end{proof}
\paragraph{Remark.} In fact, condition (i) in \hyperref[thm:1.78]{Theorem 1.78} is not required. Conditions (ii) and (iii) sufficiently imply relative compactness of $\mathcal{F}$.

\newpage
\section{Linear Functionals}
\subsection{Linear Operators and Linear Functionals}
In this section we investigate linear operators and linear functionals on general vector spaces.
\paragraph{Definition 2.1\label{def:2.1}} (Linear operators). Let $X$ and $Y$ be two real (or complex) vector spaces. A map $T:X\to Y$ is said to be a \textit{linear operator} from $X$ to $Y$ if for all $x,x^\prime\in X$ and all $\alpha\in\mathbb{R}$ (or $\mathbb{C}$), it holds
\begin{align*}
	T(x+x^\prime) = Tx + Tx^\prime\quad \text{and}\quad T(\alpha x) = \alpha (Tx).
\end{align*}
The space $X$ is said to be the \textit{domain} of $T$, which is also denoted by $\mathfrak{D}(T)$. The image $T(X)\subset Y$ is said to be the \textit{range} of $T$, denoted by $\mathfrak{R}(T)$. The subspace $T^{-1}(\{0\}) = \{x\in X:T(x)=0\}$ is said to be the \textit{kernel} (or the \textit{null space}) of $T$, denoted by $\ker T$.

\paragraph{Example 2.2.\label{example:2.2}} Following are some examples of linear operators.
\begin{itemize}
\item[(i)] (Matrices). Let $\{e_1,\cdots,e_n\}$ be a basis of $\mathbb{R}^n$, and let $\{f_1,\cdots,f_m\}$ be a basis of $\mathbb{R}^m$. Consider the operator $A:\mathbb{R}^n\to\mathbb{R}^m$ corresponding to a $m\times n$ matrix $(a_{ij})$,
\begin{align*}
	x=\sum_{j=1}^n x_je_j\ \mapsto\ y= Ax = \sum_{i=1}^n y_if_i,\quad  x_1,\cdots,x_n,y_1,\cdots,y_m\in\mathbb{R},
\end{align*}
where $y_i=\sum_{j=1}^m a_{ij}x_j$. Then $A$ is a linear operator. With the bases $\{e_1,\cdots,e_n\}$ and $\{f_1,\cdots,f_m\}$ chosen, $A$ is uniquely determined by matrix $(a_{ij})$. Hence we also write $A=(a_{ij})$.
\vspace{0.1cm}
\item[(ii)] (Differentiation). Consider the differentiation operator $D:C^1([a,b])\to C([a,b])$:
\begin{align*}
	Df(x)=\frac{d}{dx}f(x) = \lim_{h\to 0}\frac{f(x+h)-f(x)}{h},\ x\in[a,b].
\end{align*}
This is a linear operator on $C^1([a,b])$.
\vspace{0.1cm}
\item[(iii)] (Fredholm integral operator). $T:L^2([a,b])\to L^2([a,b])$,
\begin{align*}
	(Tf)(x) = \int_a^b K(x,y)f(y)\,dy,
\end{align*}
where $K$ is a continuous function on rectangle $[a,b]\times[a,b]$.
\vspace{0.1cm}
\end{itemize}

\paragraph{Theorem 2.3.\label{thm:2.3}} Let $(X,\Vert\cdot\Vert)$ and $(Y,\Vert\cdot\Vert)$ be normed spaces. Let $T:X\to Y$ be a linear operator. The following are equivalent:
\begin{itemize}
	\item[(i)] $T$ is a continuous operator;\quad (ii) $T$ is continuous at $0$;
	\item[(iii)] $T$ is bounded, i.e. there exists $M>0$ such that $\Vert Tx\Vert\leq M\Vert x\Vert$ for all $x\in X$.
\end{itemize}
\begin{proof}
(i) $\Rightarrow$ (ii): Clearly.
\vspace{0.1cm}

(ii) $\Rightarrow$ (iii): By assumption, there exists $\delta>0$ such that $\Vert Tx\Vert < 1$ for all $\Vert x\Vert <\delta$. Then for all $x\in X\backslash\{0\}$,
\begin{align*}
	\Vert Tx\Vert = \left\Vert\frac{2\Vert x\Vert}{\delta}\,T\left(\frac{\delta x}{2\Vert x\Vert}\right)\right\Vert\leq  \frac{2}{\delta}\Vert x\Vert.\tag{2.1}\label{eq:2.1}
\end{align*}
Clearly, \hyperref[eq:2.1]{(2.1)} is true for $x=0$. Setting $M=2\delta^{-1}$ complete the proof.
\vspace{0.1cm}

(iii) $\Rightarrow$ (i): For $x,x^\prime\in X$, we have $\Vert Tx-Tx^\prime\Vert\leq M\Vert x-x^\prime\Vert$. Hence $T$ is continuous at each $x\in X$.
\end{proof}
\paragraph{Remark.} By \hyperref[thm:2.3]{Theorem 2.3}, we know that a linear operator is bounded if and only if it is continuous. Here we present an example of unbounded linear operators. Consider $T:C^1([0,1])\to\mathbb{R}$,
\begin{align*}
	Tf = \left.\frac{d}{dx}f(x)\right|_{x=\frac{1}{2}}.
\end{align*}
We define sequence $f_n(x)=\frac{1}{n}\sin(2n\pi x)$, then $Tf_n = f_n^\prime(1/2) = (-1)^n\,2\pi$. While $f_n\to 0$ relative to the supremum norm $\Vert\cdot\Vert_\infty$, the image sequence $Tf_n$ diverges.

\paragraph{Definition 2.4\label{def:2.4}} (Operator norm). Let $T$ be a bounded operator from normed space $X$ into normed space $Y$. The norm of $T$ is defined as
\begin{align*}
	\Vert T\Vert = \sup_{x\neq 0}\frac{\Vert Tx\Vert}{\Vert x\Vert}.
\end{align*}
Clearly, $\Vert Tx\Vert \leq \left\Vert T\right\Vert\left\Vert x\right\Vert$ for all bounded operators $T$ and all $x\in X$. Furthermore, by linearity of $T$, we have
\begin{align*}
	\Vert T\Vert = \sup_{\Vert x\Vert=1}\Vert Tx\Vert = \sup_{\Vert x\Vert\leq 1}\Vert Tx\Vert = \sup_{\Vert x\Vert < 1}\Vert Tx\Vert.
\end{align*}
The last equality holds because $\Vert Tx\Vert = \sup_{0<\alpha<1}\Vert T(\alpha x)\Vert$ when we fix $\Vert x\Vert =1$. 

\paragraph{Example 2.5.\label{example:2.5}} Consider operator $T$ on $L^1([a,b])$:
\begin{align*}
	(Tf)(x) = \int_a^x f(t)\,dt.
\end{align*}
\begin{itemize}
	\item[(i)] If $T$ is viewed as $L^1([a,b])\to C([a,b])$, then $\Vert T\Vert = 1$;
	\item[(ii)] If $T$ is viewed as $L^1([a,b])\to L^1([a,b])$, then $\Vert T\Vert = b-a$.
\end{itemize}
\begin{proof}
(i) By definition,
\begin{align*}
	\Vert T\Vert = \sup_{f\in L^1([a,b])\backslash\{0\}}\frac{\Vert Tf\Vert_\infty}{\Vert f\Vert_1}.
\end{align*}
For any $f\in L^1([a,b])$ with $f\neq 0$,
\begin{align*}
	\frac{\Vert Tf\Vert_\infty}{\Vert f\Vert_1} = \sup_{x\in[a,b]}\frac{\int_a^x f(t)\,dt}{\int_a^b \vert f(t)\vert\,dt}\leq \sup_{x\in[a,b]}\frac{\int_a^x \vert f(t)\vert\,dt}{\int_a^b \vert f(t)\vert\,dt}= 1.
\end{align*}
If $f$ is nonnegative on $[a,b]$, the equality holds. Hence $\Vert T\Vert = 1$.
\vspace{0.1cm}

(ii) By definition,
\begin{align*}
	\Vert T\Vert = \sup_{f\in L^1([a,b])\backslash\{0\}}\frac{\Vert Tf\Vert_1}{\Vert f\Vert_1}.
\end{align*}
For any $f\in L^1([a,b])$ with $f\neq 0$,
\begin{align*}
	\frac{\Vert Tf\Vert_1}{\Vert f\Vert_1} = \frac{\int_a^b\left\vert\int_a^x f(t)\,dt\right\vert dx}{\int_a^b \vert f(t)\vert\,dt}\leq \frac{\int_a^b\int_a^x \left\vert f(t)\right\vert dt\,dx}{\int_a^b \vert f(t)\vert\,dt}\leq  \frac{\int_a^b\int_a^b \left\vert f(t)\right\vert dt\,dx}{\int_a^b \vert f(t)\vert\,dt} = b-a.
\end{align*}
Hence $\Vert T\Vert \leq b-a$.
\vspace{0.1cm}

For the other side, define $f_n = n\chi_{[a,a+n^{-1}(b-a)]}$, which is supported on closed interval $[a,a+n^{-1}(b-a)]$. Then
\begin{align*}
	\Vert T\Vert \geq \frac{\Vert Tf_n\Vert_1}{\Vert f_n\Vert_1} = \frac{\int_a^{a+n^{-1}(b-a)} (x-a)\,dx + \frac{n-1}{n}(b-a)^2}{(b-a)} = \left(1 - \frac{1}{n} + \frac{1}{2n^2}\right)(b-a),\ \forall n\in\mathbb{N}.
\end{align*}
Let $n\to\infty$, we have $\Vert T\Vert \geq b-a$. 
\end{proof}

\paragraph{Example 2.6.\label{example:2.6}} Let $g\in L^\infty([a,b])$. Define $T:L^1([a,b])\to L^1([a,b])$ as
\begin{align*}
	(Tf)(x) = f(x)g(x),\ x\in[a,b].
\end{align*}
Then we have
\begin{align*}
	\Vert T\Vert = \sup_{f\in L^1([a,b])\backslash\{0\}}\frac{\Vert Tf\Vert_1}{\Vert f\Vert_1}.
\end{align*}
For any $f\in L^1([a,b])$, we have
\begin{align*}
	\frac{\Vert Tf\Vert_1}{\Vert f\Vert_1} = \frac{\int_a^b \vert f(x)g(x)\vert\,dx}{\int_a^b\vert f(x)\vert\,dx} \leq \Vert g\Vert_\infty.
\end{align*}
Hence $\Vert T\Vert \leq \Vert g\Vert_\infty$. Furthermore, we define $E_n=\{x\in X: g(x)\geq \Vert g\Vert_\infty - 1/n\}$. By definition of essential supremum $\Vert\cdot\Vert_\infty$, $m(E_n)\neq 0$ for all $n\in\mathbb{N}$. Then
\begin{align*}
	\Vert T\Vert \geq \frac{\Vert T\chi_{E_n}\Vert_1}{\Vert\chi_{E_n}\Vert_1} \geq \frac{(\Vert g\Vert_\infty -n^{-1})m(E_n)}{m(E_n)} = \Vert g\Vert_\infty - \frac{1}{n},\ \forall n\in\mathbb{N}.
\end{align*}
Let $n\to\infty$, then $\Vert T\Vert \geq \Vert g\Vert_\infty$. Therefore $\Vert T\Vert = \Vert g\Vert_\infty$.

\paragraph{} Now we investigate the kernel of bounded linear operators.
\paragraph{Proposition 2.7.\label{prop:2.7}} Let $X$ and $Y$ be normed spaces. Let $T:X\to Y$ be a bounded linear operator. Then $\ker T$ is closed in $X$. The operator $\tilde{T}:X/\ker T\to\mathfrak{R}(T),\ [x]\mapsto Tx$, which is induced by $T$, is a bijection. Furthermore, $\Vert\tilde{T}\Vert = \Vert T\Vert$.
\begin{proof}
Note that $\{0\}$ is closed in $Y$, and $T:X\to Y$ is continuous, the kernel
\begin{align*}
	\ker T = T^{-1}(\{0\})
\end{align*}
is closed in $X$ by continuity. To verify that $\tilde{T}$ is a bijection from $X/\ker T$, note that $\ker\tilde{T} = \{[0]\}$, and that for any $y\in\mathfrak{R}(T)$, there exists $x\in X$ such that $Tx=y$, which implies $\tilde{T}([x]) = y$. Finally, we determine the norm of $\tilde{T}$. Without loss of generality, assume $\ker T\neq X$. Since the quotient map $\pi:X\mapsto X/\ker T,x\mapsto [x]$ projects unit ball $\{x\in X:\Vert x\Vert < 1\}$ onto $\{[x]:x\in X,\Vert[x]\Vert<1\}$, we have
\begin{align*}
	\Vert\tilde{T}\Vert = \sup_{\Vert [x]\Vert < 1}\Vert\tilde{T}([x])\Vert = \sup_{\Vert x\Vert < 1}\Vert Tx\Vert = \Vert T\Vert,
\end{align*}
which completes the proof.
\end{proof}

\paragraph{Definition 2.8\label{def:2.8}} (Spaces of bounded linear operators). Let $X$ and $Y$ be normed spaces. Define 
\begin{align*}
	\mathfrak{B}(X,Y)=\{T:\ T\ \text{is a bounded linear operator from}\ X\ \text{into}\ Y\}.
\end{align*}
And we define addition and scalar multiplication on $\mathfrak{B}(X,Y)$ by
\begin{align*}
	&(S+T)(x) = Sx + Tx,\ S,T\in\mathfrak{B}(X,Y)\\
	&(\alpha T)(x) = \alpha Tx,\ T\in\mathfrak{B}(X,Y),\ \alpha\ \text{is a number}.
\end{align*}
Then
\begin{align*}
	&\Vert T\Vert = 0 \Rightarrow\ \sup_{x\neq 0}\frac{\Vert Tx\Vert}{\Vert x\Vert} = 0\ \Rightarrow\ Tx=0\ \text{for all}\ x\in X\ \Rightarrow\ T\equiv 0;\\
	&\Vert (S+T)x\Vert \leq\Vert Sx\Vert + \Vert Tx\Vert \leq (\Vert S\Vert + \Vert T\Vert)\Vert x\Vert\ \Rightarrow\ S+T\in\mathfrak{B}(X,Y),\ \Vert S+T\Vert\leq\Vert S\Vert + \Vert T\Vert;\\
	&\sup_{x\neq 0}\frac{\Vert (\alpha T)x\Vert}{\Vert x\Vert} = \sup_{x\neq 0}\frac{\vert\alpha\vert\Vert Tx\Vert}{\Vert x\Vert} = \vert\alpha\vert\sup_{x\neq 0}\frac{\Vert Tx\Vert}{\Vert x\Vert} \Rightarrow\ \alpha T\in\mathfrak{B}(X,Y),\ \Vert\alpha T \Vert=\vert\alpha\vert\left\Vert T\right\Vert.
\end{align*}
Hence $(\mathfrak{B}(X,Y),\Vert\cdot\Vert)$ is a normed space, where $\Vert\cdot\Vert$ is the operator norm. \vspace{0.1cm}

We introduce another normed space $Z$, and define the multiplication operation by composition:
\begin{align*}
	(S\circ T)(x) = S(Tx),\ S\in\mathfrak{B}(Y,Z),\ T\in\mathfrak{B}(X,Y).
\end{align*}
Then we have
\begin{align*}
	\Vert(S\circ T)(x)\Vert\leq\Vert S\Vert\left\Vert Tx\right\Vert\leq\Vert S\Vert\left\Vert T\right\Vert\left\Vert x\right\Vert,\ \forall x\in X.
\end{align*}
As a result, $S\circ T\in\mathfrak{B}(X,Z)$, and $\Vert S\circ T\Vert\leq\Vert S\Vert\left\Vert T\right\Vert$.
\vspace{0.1cm}

Specifically, we write $\mathfrak{B}(X)=\mathfrak{B}(X,X)$. By the above discussion, $\mathfrak{B}(X)$ forms an algebra, given the above multiplication.

\paragraph{Lemma 2.9.\label{lemma:2.9}} Let $X$ and $Y$ be normed spaces. If $Y$ is a Banach space, so is $\mathfrak{B}(X,Y)$.
\begin{proof}
Let $(T_n)$ be a Cauchy sequence in $\mathfrak{B}(X,Y)$. For each $x\in X$, 
\begin{align*}
	\Vert T_n x - T_m x\Vert \leq \left\Vert T_n - T_m\right\Vert \left\Vert x\right\Vert.
\end{align*}
Then $(T_n x)$ is a Cauchy sequence in $Y$, which converges to some point of $Y$, denoted by $Tx$. Hence we obtain an operator $T:X\to Y$ to which $T_n$ converges pointwise.
\vspace{0.1cm}

The linearity of $T$ follows from $T_n$:
\begin{align*}
	&\Vert Tx + Ty - T(x+y)\Vert = \left\Vert \lim_{n\to\infty} \left(T_nx + T_ny - T_n(x+y)\right)\right\Vert = 0,\\
	&\Vert \alpha Tx - T(\alpha x)\Vert = \left\Vert \lim_{n\to\infty} \left(\alpha T_n x - T_n(\alpha x)\right)\right\Vert = 0.
\end{align*}
Choose $N$ such that $\Vert T_n - T_m\Vert < 1$ for all $n,m\geq N$. Then for all $x\in X$ and all $n\in\mathbb{N}$,
\begin{align*}
\Vert T_n x\Vert \leq \Vert T_n\Vert\left\Vert x\right\Vert \leq\max\left\{\Vert T_1\Vert,\cdots,\Vert T_{N-1}\Vert,\Vert T_N\Vert + 1\right\}\Vert x\Vert.
\end{align*}
Hence $\Vert Tx\Vert \leq \max\left\{\Vert T_1\Vert,\cdots,\Vert T_{N-1}\Vert,\Vert T_N\Vert + 1\right\}\Vert x\Vert$ for all $x\in X$, and $T\in\mathfrak{B}(X,Y)$.
\vspace{0.1cm}

It remains to show that $\Vert T_n - T\Vert\to 0$. Given $\epsilon>0$, choose $N_\epsilon$ such that $\Vert T_n-T_m\Vert < \epsilon$ for all $n,m\geq N_\epsilon$. Then for all $n\geq N_\epsilon$,
\begin{align*}
	\Vert (T_n - T)x\Vert = \lim_{m\to\infty}\Vert (T_m - T_n)x\Vert \leq  \lim_{m\to\infty}\Vert T_m - T_n\Vert\left\Vert x\right\Vert < \epsilon\Vert x\Vert,\ \forall x\in X\ \Rightarrow\ \Vert T_n-T\Vert \leq \epsilon\Vert x\Vert.
\end{align*}
Hence $T_n$ converges to $T$ relative to operator norm.
\end{proof}

\paragraph{Remark.} In \hyperref[lemma:2.9]{Lemma 2.9}, we do not require the completeness of domain $X$.

\paragraph{} Let $X$ be a vector space over field $\mathbb{F}$. Then a linear operator $f:X\to\mathbb{F}$ is said to be a \textit{linear functional} on $X$. The space of bounded linear functionals $\mathfrak{B}(X,\mathbb{F})$ is said to be the \textit{dual space} of $X$, denoted by $X^*$.

\paragraph{Lemma 2.10.\label{lemma:2.10}} Let $X$ and $Y$ be two finite-dimensional normed spaces over $\mathbb{R}$ (or $\mathbb{C}$). Then any linear operator $T:X\to Y$ is bounded.
\begin{proof}
Use matrix representation of linear operators and equivalence of norms in finite-dimensional spaces.
\end{proof}
\paragraph{Theorem 2.11.\label{thm:2.11}} Let $X$ be a normed space. A linear operator $f:X\to Y$ is bounded if and only if its kernel $\ker f$ is closed.
\begin{proof}
Following \hyperref[prop:2.7]{Proposition 2.7}, it remains to show sufficiency. Assume $\ker f$ is a closed subspace of $X$. According to \hyperref[example:1.54]{Example 1.54}, the quotient space
\begin{align*}
	X/\ker f:= \left\{[x]=\left\{x+y,y\in\ker f\right\}\right\}
\end{align*}
has an immediate induced norm
\begin{align*}
	\Vert [x]\Vert := d(x,\ker f) = \inf_{y\in\ker f}\Vert x-y\Vert,\ x\in X.
\end{align*}
We define $\tilde{f}:X/\ker f\to \mathbb{R}$ (or $\mathbb{C}$), $[x]\mapsto f(x)$. Since $\dim(X/\ker f)=\dim\mathfrak{R}(f)\leq 1$,  by \hyperref[lemma:2.10]{Lemma 2.10}, $f$ is bounded. Furthermore, $f$ is the composition
\begin{align*}
	x\in X\ \overset{\pi}{\to}\ [x]\in X/\ker f\ \overset{\tilde{f}}{\to}\ f(x).
\end{align*}
Then for all $x\in X$,
\begin{align*}
	\vert f(x)\vert \leq \bigl\Vert\tilde{f}\bigr\Vert\left\Vert \pi(x)\right\Vert \leq \bigl\Vert\tilde{f}\bigr\Vert\left\Vert x\right\Vert
\end{align*}
Hence $f$ is bounded.
\end{proof}
\paragraph{Remark.} Let $X$ be a normed space over $\mathbb{R}$ (or $\mathbb{C}$). By \hyperref[def:2.8]{Definition 2.8}, the dual space $X^*$ is a vector space equipped with a natural norm
\begin{align*}
	\Vert f\Vert = \sup_{x\neq 0}\frac{\vert f(x)\vert}{\Vert x\Vert},\ f\in X^*.
\end{align*}
Furthermore, $X^*$ is a Banach space by \hyperref[lemma:2.9]{Lemma 2.9}, even though $X$ is not complete.



\subsubsection{Riesz Representation Theorem}
Now we discuss linear functionals on Hilbert spaces. We first introduce the definition of isomorphism, which allows us to connect an abstract normed space to a specific one. 

\paragraph{Definition 2.12\label{def:2.12}} (Isomorphism). Let $X$ and $Y$ be normed spaces, and $U$ is an operator from $X$ into $Y$.
\begin{itemize}
	\item[(i)] If $\Vert Ux\Vert =\Vert x\Vert$ for all $x\in X$, then $U$ is said to be a \text{norm-preserving} operator.
	\item[(ii)] If $U:X\to Y$ is linear, norm-preserving and surjective, then $U$ is said to be an \textit{isomorphism}. If there exists an isomorphism between $X$ and $Y$, we say $X$ and $Y$ are \textit{isomorphic}, and we write $X\cong Y$.
\end{itemize}

\paragraph{Remark.} Isomorphism is an important tool when we investigate dual spaces. The dual space $X^*$, which consists of bounded linear functionals on a normed space $X$, can be intractable. Hopefully, we can find a specific normed space $Y$ that is isomorphic to $X^*$. Then every bounded linear functional on $X$ is uniquely determined by some element $y$ of $Y$.

\paragraph{Revisit: \hyperref[example:1.54]{Example 1.54.}} Let $H$ be a Hilbert space, and let $M$ be a closed subspace of $H$. Then the quotient space $H/M$ is isomorphic to the orthogonal complement $M^\perp$.
\begin{proof}
For each $x\in X$, by \hyperref[thm:1.37]{Theorem 1.37}, there exists unique $x_0\in M$ and $x_1\in M^\perp$ such that $x=x_0+x_1$. Then we can define $U:X\to M$ by $U(x)=x_1$. Furthermore, for all $y\in M$, we have $x+y=(x_0+y)+x_1$, where $x_0+y\in M$ and $x_1\in M^\perp$, which implies $U(x+y) = x_1$. As a result, the induced operator $$\widetilde{U}:X/M\to M^\perp,\ [x]\mapsto U(x)$$ 
is well-defined. Clearly, $\widetilde{U}$ is a linear operator, and $U$ is norm-preserving:
\begin{align*}
	\left\Vert\widetilde{U}([x])\right\Vert = \Vert Ux\Vert = \Vert x_1\Vert = \inf_{y\in M}\Vert x_1 - y\Vert = \inf_{y\in M}\Vert x_1 + x_0 - y\Vert = \Vert [x]\Vert.
\end{align*}
Furthermore, for any $x_1\in M^\perp$, $\widetilde{U}([x_1]) = U(x_1) = x_1$. Hence $\widetilde{U}$ is surjective. As a result, $\widetilde{U}$ is an isomorphism, and $H/M\cong M^\perp$.
\end{proof}

\paragraph{Review.} Consider the finite-dimensional euclidean space $\mathbb{R}^n$ equipped with the standard inner product. We choose an orthonormal basis $\{e_1,\cdots,e_n\}$ of $\mathbb{R}^n$. Then for every linear functional $f$ on $\mathbb{R}^n$, we have
\begin{align*}
	f(x) = f\left(\sum_{j=1}^n\left\langle x,e_j\right\rangle e_j\right) = \sum_{j=1}^n\left\langle x,e_j\right\rangle f\left(e_j\right),\ \forall x\in\mathbb{R}^n.
\end{align*}
It is seen that $f$ is uniquely determined by tuple $\left(f(x_1),\cdots,f(x_n)\right)\in\mathbb{R}^n$. Similarly, every tuple $(f_1,\cdots,f_n)\in\mathbb{R}^n$ induces a linear functional
$f(x) = \sum_{j=1}^n f_j\left\langle x,e_j\right\rangle$. Furthermore,
\begin{align*}
	\Vert f\Vert = \sup_{x\neq 0}\frac{\vert f(x)\vert}{\Vert x\Vert} = \sup_{x\neq 0}\frac{\left\vert\sum_{j=1}^n\langle x,e_j\rangle f(e_j)\right\vert}{\sqrt{\sum_{j=1}^n\vert\langle x,e_j\rangle\vert^2}} = \sqrt{\sum_{j=1}^n\vert f(e_j)\vert^2}.
\end{align*}
Hence we have $(\mathbb{R}^n)^*\cong\mathbb{R}^n$, which is a standard conclusion in linear algebra.

\paragraph{} For general Hilbert spaces, we have the following important theorem.

\paragraph{Theorem 2.13\label{thm:2.13}} (Riesz representation theorem). Let $H$ be a Hilbert space. Let $F\in H^*$, i.e. $F$ is a bounded linear functional on $H$. Then there exists uniquely $y\in H$ such that $F(x) = \langle x,y\rangle$ for all $x\in X$, and $\Vert F\Vert = \Vert y\Vert$.
\begin{proof}
If $F=0$, then $y=0$. We assume $F\neq 0$. Then $\ker F$ is a closed subspace of $H$, and there exists $z\notin \ker F$ such that $z\perp\ker F$. We set $z_0 = z/F(z)\in H$, then $z_0\perp \ker F$, and $F(z_0)=1$.
\vspace{0.1cm}

For each $x\in H$, we have
\begin{align*}
	F(x-F(x)z_0) = F(x) - F(x)F(z_0) = 0.
\end{align*}
Hence we have $x-F(x)z_0\in\ker F$, and $\langle x,z_0\rangle = F(x)\left\langle z_0,z_0\right\rangle$. Setting $y=\frac{z_0}{\langle z_0,z_0\rangle}$ yields the desired result. Uniqueness is clear, and $\Vert F\Vert = \Vert y\Vert$.
\end{proof}
\paragraph{Remark.} By \hyperref[thm:2.13]{Theorem 2.13}, we have $H^*\cong H$. Then every bounded linear functional $F$ on $H$ corresponds to a unique vector $y\in H$, and we can write $F$ as $F_y=\langle\cdot,y\rangle$.

\paragraph{Definition 2.14\label{def:2.14}} (Sesquilinear forms). Let $X$ be a complex vector space. Let $\varphi:X\times X\to\mathbb{C}$.
\begin{itemize}
\item[(i)] If for all $x,y,z\in H$ and all $\alpha,\beta\in\mathbb{C}$,
\begin{align*}
	\varphi(\alpha x+\beta y,z) = \alpha\varphi(x,z) + \beta\varphi(y,z),\\
	\varphi(z,\alpha x+\beta y) = \overline{\alpha}\varphi(z,x) + \overline{\beta}\varphi(z,y),
\end{align*}
then $\varphi$ is said to be a \textit{sesquilinear form} on $X$. If there exists $M>0$ such that
\begin{align*}
	\vert\varphi(x,y)\vert\leq M\left\Vert x\right\Vert\left\Vert y\right\Vert,\ \forall x,y\in X,
\end{align*}
then $\varphi$ is said to be a bounded sesquilinear form on $X$, and we define norm of $\varphi$ by
\begin{align*}
	\Vert\varphi\Vert = \sup_{\Vert x\Vert=\Vert y\Vert =1}\vert\varphi(x,y)\vert.
\end{align*}
\item[(ii)] If $\varphi$ is a sesquilinear functional on $X$ and $\varphi(x,y)=\overline{\varphi(y,x)}$ for all $x,y\in X$, then $\varphi$ is said to be a \textit{Hermitian form} on $X$.
\end{itemize}

\paragraph{Remark.} Let $T$ be a bounded linear operator on a Hilbert space $H$. Clearly, the map $\varphi(x,y):=\langle Tx,y\rangle$ induced by $T$ is a sesquilinear form on $H$. Moreover,
\begin{align*}
	\vert\varphi(x,y)\vert = \langle Tx,y\rangle\leq\left\Vert Tx\right\Vert\left\Vert y\right\Vert\leq\left\Vert T\right\Vert\left\Vert x\right\Vert\left\Vert y\right\Vert,\ \forall x,y\in H\ \Rightarrow\ \Vert\varphi\Vert \leq \Vert T\Vert,\\
	\Vert T\Vert = \sup_{\Vert x\Vert=1} \Vert Tx\Vert = \sup_{\Vert x\Vert=\Vert y\Vert = 1} \vert\langle Tx,y\rangle\vert = \sup_{\Vert x\Vert=\Vert y\Vert = 1} \vert\varphi(x,y)\vert\ \Rightarrow\ \Vert\varphi\Vert\geq\Vert T\Vert.
\end{align*}
Therefore $\Vert\varphi\Vert = \Vert T\Vert$. Furthermore, every bounded sesquilinear form on $H$ uniquely determines a bounded linear operator $T$ on $H$, as stated below.

\paragraph{Theorem 2.15\label{thm:2.15}} (Riesz). Let $H$ be a Hilbert space, and let $\varphi$ be a bounded sesquilinear form on $H$. Then there exists uniquely $T\in\mathfrak{B}(H)$ such that $\varphi(x,y)=\langle Tx,y\rangle$ for all $x,y\in H$, and $\Vert T\Vert = \Vert \varphi\Vert$.
\begin{proof}
Fix $x\in H$. By definition of bounded sesquilinear form, $\varphi_x(\cdot) = \overline{\varphi(x,\cdot)}$ is a bounded linear functional on $H$, with $\Vert\varphi_x\Vert\leq\left\Vert \varphi\right\Vert\left\Vert x\right\Vert$.
By Riesz representation theorem (\hyperref[thm:2.13]{Theorem 2.13}), there exists $z\in H$ such that
\begin{align*}
	\varphi(x,y)=\overline{\varphi_x(y)} = \overline{\langle y,z\rangle} = \langle z,y\rangle,\ \forall y\in H,
\end{align*}
and $\Vert z\Vert =\Vert\varphi_x\Vert\leq \left\Vert \varphi\right\Vert\left\Vert x\right\Vert$. We denote by $Tx=z$ the uniquely determined Riesz vector of $\varphi_x$. Then $T$ is an operator on $X$. Clearly, $T$ is linear, and $\Vert T\Vert \leq \Vert \varphi\Vert$.
\end{proof}

\paragraph{Lemma 2.16.\label{lemma:2.16}} Let $H$ be a complex Hilbert space, and let $\varphi$ be a bounded sesquilinear form on $H$.
\begin{itemize}
	\item[(i)] $\varphi$ is Hermitian if and only if $\varphi(x,x)\in\mathbb{R}$ for all $x\in H$;
	\item[(ii)] If $\varphi$ is Hermitian, and there exists $M>0$ such that $\vert\varphi(x,x)\vert\leq M\Vert x\Vert^2$ for all $x\in H$, then $\varphi$ is bounded, and $\Vert\varphi\Vert\leq M$.
\end{itemize} 
\begin{proof}
(i) The necessity is clear. To show sufficiency, use the polarization identity:
\begin{align*}
	\varphi(x,y) = \frac{1}{4}\sum_{k=0}^3\i^k\varphi\left(x+\i^k y, x+\i^k y\right),\ \forall x,y\in H.
\end{align*}
Then we can verify that $\varphi(x,y)=\overline{\varphi(y,x)}$.
\vspace{0.2cm}

(ii) Assume $\varphi(x,y)\neq 0$. Let $\lambda = \frac{\overline{\varphi(x,y)}}{\vert\varphi(x,y)\vert}$, then $\varphi(\lambda x,y)\in\mathbb{R}$, and
\begin{align*}
	\vert\varphi(x,y)\vert = \varphi(\lambda x,y) &= \frac{1}{4}\left[\varphi(x+y,x+y) - \varphi(x-y,x-y)\right]\\
	&\leq\frac{M}{4}\left[\Vert x+y\Vert^2 + \Vert x-y\Vert^2\right]\\ &=\frac{M}{2}\left(\Vert x\Vert^2 + \Vert y\Vert^2\right).
\end{align*}
Whenever $\Vert x\Vert=\Vert y\Vert=1$, we have $\vert\varphi(x,y)\vert\leq M$. Hence $\varphi$ is bounded, and $\Vert\varphi\Vert\leq M$.
\end{proof}

\paragraph{Remark.} Let $H$ be a complex Hilbert space. A linear operator $T:X\to X$ is said to be an \textit{Hermitian} operator if $\langle Tx,x\rangle\in\mathbb{R}$ for all $x\in H$. By \hyperref[thm:2.15]{Theorem 2.15}, every bounded Hermitian form on $H$ is uniquely induced by a bounded Hermitian operator $T\in\mathfrak{B}(H)$. Furthermore,
\begin{align*}
	\Vert T\Vert = \sup_{\Vert x\Vert=1}\vert\langle Tx,x\rangle\vert.
\end{align*}

\newpage
\subsection{Hahn-Banach Theorem}
\paragraph{Definition 2.17\label{def:2.17}} (Linear extension). Let $L$ be a real vector space, and let $L_0$ be a subspace of $L$. Given a linear functional $f_0$ on $L_0$, a linear functional $f:L\to\mathbb{R}$, is said to be a \textit{(linear) extension of} $f_0$, if $f|_{L_0}=f_0$, i.e. $f(x)=f_0(x)$ for all $x\in L_0$.

\paragraph{Remark.} Let $\{b_\lambda,\lambda\in\Lambda_0\}$ be a Hamel basis of $L_0$, we can expand it to a Hamel basis $\{b_\lambda,\lambda\in\Lambda\}$ on $L$, where $\Lambda_0\subset\Lambda$. Given a linear functional $f_0:L_0\to\mathbb{R}$, we maintain $f(b_\lambda)=f_0(b_\lambda)$ for all $\lambda\in\Lambda_0$, and set $f(b_\lambda)=0$ for $\lambda\notin\Lambda_0$. Then we obtain a trivial extension of $f_0$ on $L$.

\paragraph{Definition 2.18\label{def:2.18}} (Sublinear functional). Let $L$ be a real vector space. A function $p:L\to\mathbb{R}$ is said to be a \textit{sublinear functional} on $L$, if

\vspace{0.30cm}
$\hspace{3cm} p(x+y)\leq p(x)+p(y),\ \forall x,y\in L;\quad p(\lambda x) = \lambda p(x),\ \forall x\in L,\ \lambda\geq 0$.
\vspace{0.10cm}

\paragraph{Theorem 2.19\label{thm:2.19}} (Hahn-Banach, real version). Let $p$ be a sublinear functional on a real vector space $L$. Let $L_0\subset L$ be a subspace. Suppose $f_0$ is a linear functional on $L_0$ that is subject to $p$, i.e. $f_0(x)\leq p(x)$ for all $x\in L_0$. Then there exists an extension $f:L\to\mathbb{R}$ of $f_0$ that is subject to $p$.
\begin{proof}
\textit{Step I:} Suppose $L_0\neq L$, and choose $z\in L\backslash L_0$. We claim that $f_0$ can be extended to a linear functional $f_1$ on space $L_1=\mathrm{span}\{L_0,z\}$ such that $f_1$ is subject to $p$.
\vspace{0.1cm}

For any $tz+x\in L_1$, where $t\in\mathbb{R}$ and $x\in L_0$, if $f_1$ is an extension of $f_0$, then
\begin{align*}
	f_1(tz+x) = tf_1(z) + f_0(x).
\end{align*}
We need to determine $f_1(z)$, denoted by $c$. To ensure that $f$ is subject to $p$, we require
\begin{align*}
	f_1(tz+x)=tc+f_0(x)\leq p(tz+x),\ \forall x\in L_0,t\in\mathbb{R}.
\end{align*}
If $t>0$, then
\begin{align*}
	tc+f_0(x)\leq p(tz+x),\ \forall x\in L_0,t>0\ &\Leftrightarrow\ c\leq p\left(z+\frac{x}{t}\right) - f_0\left(\frac{x}{t}\right),\ \forall x\in L_0,t>0\\ &\Leftrightarrow\ c\leq p(z+y^\prime) - f_0(y^\prime),\ \forall y^\prime\in L_0.\tag{2.2}\label{eq:2.2}
\end{align*}
If $t<0$, then
\begin{align*}
	tc+f_0(x)\leq p(tz+x),\ \forall x\in L_0,t<0\ &\Leftrightarrow\ c\geq -p\left(-z-\frac{x}{t}\right) - f_0\left(\frac{x}{t}\right),\ \forall x\in L_0,t<0\\ &\Leftrightarrow\ c\geq -p(-z-y^{\prime\prime}) - f_0(y^{\prime\prime}),\ \forall y^{\prime\prime}\in L_0.\tag{2.3}\label{eq:2.3}
\end{align*}
By \hyperref[eq:2.2]{(2.2)} and \hyperref[eq:2.3]{(2.3)}, to choose an appropriate $c$, it suffices to show
\begin{align*}
	\sup_{y^{\prime\prime}\in L_0} -p(-z-y^{\prime\prime})-f_0(y^{\prime\prime}) \leq \inf_{y^\prime\in L_0} p(z+y^\prime) - f_0(y^\prime).\tag{2.4}\label{eq:2.4}
\end{align*}
For any $y^\prime,y^{\prime\prime}\in L_0$, we have $y^\prime-y^{\prime\prime}\in L_0$. Then
\begin{align*}
	p(z+y^\prime) - f_0(y^\prime) + p(-z-y^{\prime\prime}) + f_0(y^{\prime\prime}) \geq p(y^\prime-y^{\prime\prime}) - f_0(y^\prime-y^{\prime\prime})\geq 0,
\end{align*}
which implies \hyperref[eq:2.4]{(2.4)}. Then we choose an appropriate $c$ and set $f_1(z)=c$. 

\paragraph{} \textit{Step II:} Use Zorn's lemma. Let $\mathscr{H}$ be the set of all extensions of $f_0$:
\begin{align*}
	\mathscr{H}=\left\{(f,Y): L_0\subset Y\subset L\ \text{is a subspace of}\ L;\ f\ \text{is a linear functional on}\ Y\ \text{such that}\ f|_{L_0}=f_0, f\leq p\right\}
\end{align*}

We define a partial order on $\mathscr{H}$: $(f_1,Y_1)\preceq (f_2,Y_2)$ if $Y_1\subset Y_2$ and $f_2|_{Y_1}=f_1$. Let $C=\{(f_\lambda,Y_\lambda),\lambda\in\Lambda\}$ be a chain in $\mathscr{H}$, and let $Y=\bigcup_{\lambda\in\Lambda}Y_\lambda$. Then $Y$ is a subspace of $L$: for any $x_1,x_2\in Y$, there exists $\lambda_1,\lambda_2\in\Lambda$ such that $x_1\in Y_{\lambda_1}$ and $x_2\in Y_{\lambda_2}$. Furthermore, one of $Y_{\lambda_1}$, $Y_{\lambda_2}$ contains the other because $C$ is a chain, then both $x_1$ and $x_2$ belong to $Y_{\lambda_2}$, without loss of generality. Hence $\alpha x_1 + \beta x_2\in Y_{\lambda_2}\subset Y$ for $\alpha,\beta\in\mathbb{R}$.

For any $x\in Y$, there exists $\lambda\in\Lambda$ such that $x\in Y_\lambda$. Then we define $f(x)=f_\lambda(x)$. Note that $f(x)$ is well-defined: if $x$ belongs both $Y_{\lambda_1}\cap Y_{\lambda_2}$, $f_{\lambda_1}$ and $f_{\lambda_2}$ will agree on $x$, since $C$ is a chain. Similar arguments also show that $f$ is linear, subjected to $p$, and that it is an extension of $f_\lambda$ for all $\lambda\in\Lambda$. Then we obtain an upper bound $(f,Y)$ of $C$ in $\mathscr{H}$, and we can apply Zorn's lemma.

Now $\mathscr{H}$ has a maximal element $(f,Y)$. It remains to show $Y=L$; suppose not. By Step I, there exists subspace $Y_1\supsetneq Y$, and $f$ can be extended to $f_1:Y_1\to\mathbb{R}$, contradicting the maximality of $(f,Y)$!
\end{proof}

The following theorem is a corollary of \hyperref[thm:2.19]{Theorem 2.19}.

\paragraph{Theorem 2.20\label{thm:2.20}} (Hahn-Banach, real version). Let $L_0$ be a subspace of a real normed space $L$. If $f_0$ is a bounded linear functional on $L_0$, then there exists an extension $f:L\to\mathbb{R}$ of $f_0$ such that $\Vert f\Vert = \Vert f_0\Vert$.
\begin{proof}
Let $p(x)=\left\Vert f_0\right\Vert\left\Vert x\right\Vert$ for all $x\in L$, $p$ is a sublinear functional to which $f_0$ is subject. By \hyperref[thm:2.19]{Theorem 2.19}, there exists an extension $f:L\to\mathbb{R}$ of $f_0$ with $f\leq p$. Then
\begin{align*}
	\Vert f\Vert = \sup_{x\in L\backslash\{0\}}\frac{\vert f(x)\vert}{\Vert x\Vert} \geq \sup_{x\in L_0\backslash\{0\}}\frac{\vert f(x)\vert}{\Vert x\Vert} = \sup_{x\in L_0\backslash\{0\}}\frac{\vert f_0(x)\vert}{\Vert x\Vert} = \Vert f_0\Vert;\\
	-\left\Vert f_0\right\Vert\left\Vert x\right\Vert = -p(-x)\leq \vert f(x)\vert \leq p(x) = \left\Vert f_0\right\Vert\left\Vert x\right\Vert,\ \forall x\in L\ \Rightarrow\ \Vert f\Vert\leq\Vert f_0\Vert.
\end{align*}
Hence $\Vert f\Vert = \Vert f_0\Vert$.
\end{proof}

Now we consider the complex case. Let $X$ be a complex vector space, and let $f$ be a complex linear functional on $X$. For each $x\in X$, $f(x)=\Re f(x) + \i\,\Im f(x)$. We denote $f_R=\Re f,\ f_I=\Im f$.
\vspace{0.1cm}

If $f$ is $\mathbb{C}$-linear, then for all $x,y\in X$ and all $\alpha,\beta\in\mathbb{R}$,
\begin{align*}
\begin{cases}
	f_R(x+y) = f_R(x) + f_R(y),\ f_I(x+y) = f_I(x) + f_I(y),\\
	f_R\left((\alpha+\i\beta)x\right) = \alpha f_R(x) - \beta f_I(x),\\
	f_I\left((\alpha+\i\beta)x\right) = \beta f_R(x) + \alpha f_I(x).
\end{cases}
\end{align*}
Hence the following are equivalent: (i) $f=f_R+\i f_I$ is $\mathbb{C}$-linear; (ii) $f_R$ and $f_I$ are $\mathbb{R}$-linear, and $f_R(\i x)=-f_I(x)$ for all $x\in X$; (iii) $f_R$ and $f_I$ are $\mathbb{R}$-linear, and $f_R(x)=f_I(\i x)$ for all $x\in X$.
\vspace{0.1cm}

By (ii), $f$ is uniquely determined by its real part $f_R$: $f(x)=f_R(x)-\i f_R(\i x)$. By (iii), $f$ is uniquely determined by its imaginary part $f_I$: $f(x)= f_I(\i x)+\i f_I(x)$.

\paragraph{Theorem 2.21} (Hahn-Banach, complex version). Let $L_0$ be a subspace of a complex vector space $L$. Let $p$ be a seminorm on $L$. Suppose $f_0$ is a linear functional on $L_0$ such that $\vert f_0(x)\vert\leq p(x)$ for all $x\in L_0$. Then there exists a linear functional $f:L\to\mathbb{R}$ such that $f|_{L_0}=f_0$ and $\vert f(x)\vert \leq p(x)$ for all $x\in L$.
\begin{proof}
We first view $L$ and $L_0$ as $\mathbb{R}$-vector spaces, denoted by $L_\mathbb{R}$ and $L_{0\mathbb{R}}$, respectively. Then $p$ is a sublinear functional on $L_{0\mathbb{R}}$, and $f_{0R}=\Re f_0$ satisfies
\begin{align*}
	f_{0R}(x)\leq\vert f_0(x)\vert\leq p(x),\ \forall x\in L_{0\mathbb{R}}.
\end{align*}

By \hyperref[thm:2.19]{Theorem 2.19}, there exists $\mathbb{R}$-linear functional $f_R:L_\mathbb{R}\to\mathbb{R}$ such that $f_R|_{L_{0\mathbb{R}}}=f_{0R}$, and $f_R(x)\leq p(x)$ for all $x\in L_\mathbb{R}$. Let $f(x)=f_R(x)-\i f_R(\i x)$ for all $x\in L_{\mathbb{R}}$. Then $f$ is $\mathbb{C}$-linear on $L$, and $f$ extends $f_0$. 
\vspace{0.1cm}

For any $x\in L$, denote $\theta = \mathrm{Arg}\, f(x)$. Then
\begin{align*}
	\vert f(x)\vert = \mathrm{e}^{-\i\theta}f(x) = \underbrace{f\left(\mathrm{e}^{-\i\theta}x\right)}_{\in\mathbb{R}} = f_R\left(\mathrm{e}^{-\i\theta}x\right)\leq p\left(\mathrm{e}^{-\i\theta}x\right) \leq\left\vert\mathrm{e}^{-\i\theta}\right\vert p(x) = p(x).
\end{align*}
Thus we complete the proof.
\end{proof}

Now we introduce some useful corollaries of Hahn-Banach theorem.
\paragraph{Corollary 2.22.\label{cor:2.22}} Let $X$ be a normed space. \begin{itemize}
	\item[(i)] For each $x_0\in X\backslash\{0\}$, there exists $f\in X^*$ such that $\Vert f\Vert = 1$ and $f(x_0)=\Vert x_0\Vert$.
	\item[(ii)] For each $x_1,x_2\in X$ such that $x_1\neq x_2$, there exists $f\in X^*$ such that $f(x_1)\neq f(x_2)$.
	\item[(iii)] For all $x\in X$,
	\begin{align*}
		\Vert x\Vert = \max_{f\in X^*,\left\Vert f\right\Vert=1}\vert f(x)\vert.
	\end{align*}
\end{itemize}
\begin{proof}
(i) Consider the subspace $Y=\mathrm{span}\,\{x_0\}=\mathbb{C}x_0 =\{\alpha x_0:\alpha\in\mathbb{C}\}$. Define $f_0:Y\to\mathbb{C},\ \alpha x_0\mapsto \alpha\Vert x_0\Vert$. Then $\Vert f_0\Vert=1$. By Hahn-Banach theorem, there exists an extension $f\in X^*$ such that $\Vert f\Vert=\Vert f_0\Vert=1$, and $f|_{Y}=f_0$. Hence $f(x_0)=\Vert x_0\Vert$. 
\vspace{0.1cm}

(ii) Apply (i) to $x_0=x_1-x_2$.
\vspace{0.1cm}

(iii) Clearly, for all $f\in X^*$ such that $\Vert f\Vert=1$, we have $\vert f(x)\vert \leq \Vert x\Vert$.  By (i), there exists $f\in X^*$ such that $\Vert f\Vert=1$ and $\vert f(x)\vert =\Vert x\Vert$.
\end{proof}

\paragraph{Corollary 2.23.\label{cor:2.23}} Let $M$ be a closed subspace of a normed space $X$. For all $x\in X\backslash M$, there exists $f\in X^*$ such that $\Vert f\Vert=1$, $f(M)=\{0\}$, and $f(x)=d(x,M)$.
\begin{proof}
Let $X_0=\mathrm{span}\,\{M,x\}$. For any $y=m+\lambda x\in X_0$, where $m\in M$ and $\lambda\in\mathbb{R}$ (or $\mathbb{C}$), define
\begin{align*}
	f_0:X_0\to\mathbb{R}\ (\text{or}\ \mathbb{C}),\ m+\lambda x\to \lambda d(x,M).
\end{align*}
Then $f_0$ is a linear functional on $X_0$, and
\begin{align*}
	\Vert f_0\Vert = \sup_{m+\lambda x\neq 0}\frac{\vert\lambda\vert\, d(x,M)}{\Vert m+\lambda x\Vert} = \sup_{m^\prime\in M}\frac{d(x,M)}{\Vert m^\prime + x\Vert} = \frac{d(x,M)}{\inf_{m^\prime\in M}\Vert m^\prime + x\Vert}  = 1.
\end{align*}

By Hahn-Banach theorem, there exists an extension $f$ of $f_0$ on $X$ such that $\Vert f\Vert = \Vert f_0\Vert = 1,$ $f(M)=\{0\}$, and $f(x) = d(x,M)$. Note that we require $M$ to be closed. Otherwise, let $x$ be a limit point of $M$ not lying in $M$. Then $d(x,M)=0$, and $f_0\equiv 0$ on $X_0$.
\end{proof}

\paragraph{Corollary 2.24.\label{cor:2.24}} Let $M$ be a subset of a normed space $X$. Let $x\in X$. Then $x\in\overline{\mathrm{span}}(M)$ if and only if $f(x)=0$ for all $f\in X^*$ such that $f(M)=\{0\}$.
\begin{proof}
``$\Rightarrow$'': Clearly. \quad ``$\Leftarrow$'': Argue by contradiction. By \hyperref[cor:2.23]{Corollary 2.23}, if $x\notin \overline{\mathrm{span}}(M)$, there exists $f\in X^*$ such that $f(x)=d(x,\overline{\mathrm{span}}(M))>0$ and $f(M)=\{0\}$.
\end{proof}

Now we introduce the generalization of orthogonal complements in Banach spaces.
\paragraph{Definition 2.25\label{def:2.25}} (Annihilators and pre-annihilators). Let $X$ be a normed space.
\begin{itemize}
\item[(i)] For a subset $M\subset X$, the \textit{annihilator} of $M$ is defined as
\begin{align*}
	M^\perp = \{f\in X^*:f(x)=0,\ \forall x\in M\}.
\end{align*}
\item[(ii)] For a subset $N\subset X^*$, the \textit{pre-annihilator} of $N$ is defined as
\begin{align*}
	^\perp N = \{x\in X:f(x)=0,\ \forall f\in N\}.
\end{align*}
\end{itemize}
Clearly, $M^\perp$ is a closed subspace of $X^*$, and $^\perp N$ is a closed subspace of $X$.

\paragraph{Remark.} By definition, $\overline{M}^\perp\subset M^\perp$. For each $x\in \overline{M}$, there exists sequences $(x_n)$ of points of $M$ such that $x_n\to x$. If $f\in M^\perp$, by continuity of $f$, we have $f(x)=\lim_{n\to\infty} f(x_n)=0$. Hence $\overline{M}^\perp = M^\perp$.

Similarly, for every $f\in\overline{N}$, there exists sequences $(f_n)$ of points of $N$ such that $f_n\to f$, which implies $f_n(x)\to f(x)$ for all $x\in X$. If $x\in\,^\perp N$, then $f(x)=0$. Hence $^\perp\overline{N}=\,^\perp N$.

\paragraph{Theorem 2.26.\label{thm:2.26}} Let $M$ be a closed subspace of a normed space $X$.
\begin{itemize}
	\item[(i)] For all $m^*\in M^*$, there exists a norm-preserving extension $x^*$ of $M^*$ on $X$. We define 
	$$\sigma(m^*)=[x^*],$$ 
	where $[x^*]$ is the equivalence class of $x^*$ in quotient space $X^*/M^\perp$. Then map $\sigma:M^*\to X^*/M^\perp$ is a well-defined norm-preserving isomorphism.
	\item[(ii)] Let $\pi:X\to X/M,\ x\mapsto[x]$ be the quotient map. For all $f\in(X/M)^*$, define
	\begin{align*}
		\tau(f) = f\circ\pi.
	\end{align*}
    Then $\tau:(X/M)^*\to M^\perp$ is a norm-preserving isomorphism.
\end{itemize}

\begin{proof}
(i) We first check that the map $\sigma$ is well-defined. Let $x^*,y^*\in X^*$ be two extensions of $m^*$ on $X$. Then $x^*m=y^*m = m^*m$ for all $m\in M$, and $x^*-y^*\in M^\perp$. Hence $[x^*]=[y^*]$ in $X/ M^\perp$.
\vspace{0.1cm}

Clearly, $\sigma$ is linear: if $x_1^*,x_2^*\in X^*$ are extensions of $m_1^*,m_2^*\in M^*$, respectively, then $\alpha x_1^* + \beta x_2^*$ is an extension of $\alpha m_1^* + \beta m_2^*$. Also, $\sigma$ is norm-preserving: $\Vert \sigma(m^*)\Vert = \Vert[x^*]\Vert \leq \Vert x^*\Vert = \Vert m^*\Vert$, and
\begin{align*}
	y^*|_M=m^*,\ \forall y^*\in[x^*]\ \Rightarrow\ \Vert y^*\Vert \geq \Vert m^*\Vert,\ \forall y^*\in[x^*]\ \Rightarrow\ \Vert[x^*]\Vert = \inf\{\Vert y^*\Vert:\ y^*\in [x^*]\} \geq \Vert m^*\Vert.
\end{align*}
For any $[x^*]\in X^*/M^\perp$, $\sigma(x^*|_M)=[x^*]$, which implies $\sigma$ is surjective. As a result, $\sigma:M^*\to X^*/M^\perp$ is a norm-preserving isomorphism, and $M^*\cong X^*/M^\perp$.
\vspace{0.1cm}

(ii) Clearly, $\tau$ is linear. To show that $\tau$ is norm-preserving, note that for all $f\in (X/M)^*$,
\begin{align*}
	\Vert\tau(f)\Vert = \sup_{y\in X\backslash M}\frac{f([y])}{\Vert y\Vert} = \sup_{x\in X\backslash M,y\in[x]}\frac{f([y])}{\Vert y\Vert} = \sup_{x\in X\backslash M}\frac{f([x])}{\inf_{y\in[x]}\Vert y\Vert} = \sup_{x\in X\backslash M}\frac{f([x])}{\Vert [x]\Vert} = \Vert f\Vert.
\end{align*}
Finally, for each $g\in M^\perp$, we define $\tilde{g}:X/M\to\mathbb{R},\ [x]\mapsto g(x)$. Then $g=\tilde{g}\circ\pi = \tau(\tilde{g})$, and $\tau$ is surjective. Therefore, $\tau:(X/M)^*\to M^\perp$ is a norm-preserving isomorphism, and $(X/M)^*\cong M^\perp$.
\end{proof}

Finally, we present an interesting application of Hahn-Banach theorem.
\paragraph{Example 2.27.\label{example:2.27}} We wish to find a finitely additive translation-invariant probability measure $\mu$ on $\mathbb{R}$, such that $\mu$ is defined on all subsets of $\mathbb{R}$, and
\begin{align*}
	\mu(\alpha + A) = \mu(A)\quad \text{for all}\ A\subset\mathbb{R}\ \ \text{and all}\ \alpha\in\mathbb{R},\ \text{where}\ \alpha+A=\{x+\alpha:x\in A\}.
\end{align*}

Let $B(\mathbb{R})$ be the set of all bounded $\mathbb{R}$-valued functions on $\mathbb{R}$, and define $\Vert f\Vert_\infty = \sup_{x\in\mathbb{R}}\vert f(x)\vert$ for all $f\in B(\mathbb{R})$. Clearly, $\Vert\cdot\Vert_\infty$ is a norm on $B(\mathbb{R})$, and $(B(\mathbb{R}),\Vert\cdot\Vert_\infty)$ is a Banach space.

\paragraph{Claim.} We define $p:B(\mathbb{R})\to\mathbb{R}$ as follows: for all $f\in B(\mathbb{R})$,
\begin{align*}
	p(f) = \inf_{n\in\mathbb{N},\alpha_1,\cdots,\alpha_n\in\mathbb{R}}\left\{N(f;\alpha_1,\cdots,\alpha_n):=\sup_{s\in\mathbb{R}}\frac{1}{n}\sum_{k=1}^n f(s+\alpha_k)\right\}.
\end{align*}
Then $p$ is a sublinear functional on $\mathbb{R}$.
\begin{proof}
Clearly, for all $\lambda\geq 0$, $p(\lambda f)=\lambda p(f)$. For all $f,g\in B(\mathbb{R})$ and all $n\in\mathbb{N}$, $\alpha_1,\cdots,\alpha_n\in\mathbb{R}$,
\begin{align*}
	N(f+g;\alpha_1,\cdots,\alpha_n) = \sup_{s\in\mathbb{R}}\frac{1}{n}\sum_{k=1}^n \bigl[f(s+\alpha_k) + g(s+\alpha_k)\bigr] \leq N(f;\alpha_1,\cdots,\alpha_n) + N(g;\alpha_1,\cdots,\alpha_n).
\end{align*}
Hence $p(f+g)\leq p(f) + p(g)$.
\end{proof}
\paragraph{Theorem.} There exists a linear functional $\nu:B(\mathbb{R})\to\mathbb{R}$ such that (i) $\nu(\mathbf{1})=1$, and (ii) $\nu(\tau_\alpha f)=\nu(f)$ for all $\alpha\in\mathbb{R}$, where $\tau_\alpha$ is the translation operator $(\tau_\alpha f)(x) = f(x-\alpha)$.
\begin{proof}
We first consider the linear functional $\nu_0(\alpha\mathbf{1})=\alpha$ on subspace $\mathbb{R}\cdot\mathbf{1}$, which satisfies $\nu_0=p$. By Hahn-Banach theorem, there exists linear functional $\nu$ on $B(\mathbb{R})$ extending $\nu_0$, with $\nu\leq p$.
\vspace{0.1cm}

For all $\alpha\in\mathbb{R}$ and $n\in\mathbb{N}$, we have
\begin{align*}
	p(\tau_\alpha f-f)\leq N(\tau_\alpha f-f;\alpha,\cdots,n\alpha) = \sup_{s\in\mathbb{R}}\frac{1}{n}\left[f(s) - f(s+n\alpha)\right] \leq \frac{2}{n}\Vert f\Vert_\infty.
\end{align*}
Let $n\to\infty$, then $p(\tau_\alpha f-f)\leq 0$, and $\nu(\tau_\alpha f-f)\leq 0$. Analogously, $\nu(f-\tau_\alpha f) \leq p(f-\tau_\alpha f)\leq 0$. Therefore $\nu(\tau_\alpha f)=\nu(f)$ for all $\alpha\in\mathbb{R}$, completing the proof.
\end{proof}

For any $A\in\mathbb{R}$, we define $\mu(A)=\nu(\chi_A)$. Then $\mu$ is the desired probability measure on $\mathbb{R}$.

\newpage
\subsection{Hyperplane Separation Theorem}
\paragraph{Definition 2.28\label{def:2.28}} (Hyperplane). Let $f$ be a nonzero linear functional on a vector space $X$. Let $c$ be a constant. The set
\begin{align*}
	M_c=\{f(x)=c\}=\{x\in X:f(x)=c\}
\end{align*}
is said to be a \textit{hyperplane} in $X$.
\paragraph{Definition 2.29\label{def:2.29}} (Separation). Suppose $X$ is a real vector space, $M$ and $N$ are subsets of $X$, and $f$ is a linear functional on $X$.
\begin{itemize}
	\item[(i)] If there exists $c\in\mathbb{R}$ such that $f(x)\geq c$ for all $x\in M$, and $f(y)\leq c$ for all $y\in N$, then $f$ is said to \textit{separate} $M$ and $N$. In other words, $\sup_{y\in N}f(y)\leq\inf_{x\in M}f(x)$.
	\item[(ii)] If $\sup_{y\in N}f(y) < \inf_{x\in M}f(x)$, then $f$ is said to \textit{strictly separate} $M$ and $N$.
\end{itemize}

\paragraph{Remark.} By definition, the following are equivalent:
\begin{itemize}
	\item[(i)] $f$ separates $M$ and $N$; 
	\item[(ii)] $f$ separates $M-N$ and $\{0\}$, where $M-N:=\{x-y:x\in M,\ y\in N\}$; 
	\item[(iii)] $f$ separates $M-x$ and $N-x$ for all $x\in X$, where $M-x=\{y-x:y\in M\}$.
\end{itemize} 

\paragraph{Lemma 2.30.\label{lemma:2.30}} Let $M$ be a convex set in a normed space $X$. Then for all $x\in M$, all $y\in\mathring{M}$, and all $t\in(0,1)$, $$(1-t)x+ty\in\mathring{M}.$$
\begin{proof}
Let $x\in M$ and $y\in\mathring{M}$. Then there exists $\epsilon>0$ such that $O(y,\epsilon)\subset M$. Let $0<t<1$. Then
\begin{align*}
	O((1-t)x+ty,t\epsilon) = \left\{(1-t)x+tz:z\in O(y,\epsilon)\right\}\subset M.
\end{align*}
Hence $(1-t)x+ty\in\mathring{M}$.
\end{proof}

Now we introduce Minkowski functional theory, which connects convexity to seminorm.

\paragraph{Proposition 2.31.\label{prop:2.31}} Let $p$ be a seminorm on a vector space $X$. Then for all $c>0$, the set $$M=\{x\in X:p(x)\leq c\}$$ satisfies the following: (i) $0\in M$; (ii) $M$ is convex; (iii) $M$ is balanced: $\alpha M\subset M$ for all $\vert \alpha\vert = 1$; (iv) $M$ is absorbing: for all $x\in X$, there exists $\alpha>0$ such that $x\in\alpha M$; (v) The seminorm $p$ can be recovered by
	\begin{align*}
		p(x) = \inf_{\alpha > 0,\,x\in\alpha M}c\alpha.
	\end{align*}
\begin{proof}
The properties (i), (ii), (iii) and (iv) are clear. It remains to prove (iv). For all $x\in X$,
\begin{align*}
	x\in \alpha M\ \Leftrightarrow\ p(\alpha^{-1}x)\leq c\ \Leftrightarrow\ p(x)\leq c\alpha\quad\Rightarrow\quad p(x)\leq \inf_{\alpha > 0,\,x\in \alpha M}c\alpha
\end{align*}
Conversely, if $p(x)\neq 0$, then $\frac{cx}{p(x)}\in M$. Set $\alpha=\frac{p(x)}{c}$, then $p(x)=c\alpha$, and
\begin{align*}
	p(x) = \min_{\alpha>0,\,x\in \alpha M}c\alpha.
\end{align*}
If $p(x)=0$, then $x\in \alpha M$ for all $\alpha > 0$, and $\inf_{\alpha>0}c\alpha =0$.
\end{proof}

Let $M$ be an absorbing convex set in vector space $X$. By definition, for all $x\in X$, there exists $\alpha >0$ such that $x\in\alpha M$. Hence $0\in M$, and $M$ is \textit{star-shaped}: whenever $x\in M$, we have $tx\in M$ for all $t\in[0,1]$. As a result, if $x\in \alpha M$ for $x\in X$ and $\alpha >0$, then $x\in \beta M$ for all $\beta > \alpha$.

\paragraph{Lemma 2.32\label{lemma:2.32}} (Minkowski functionals). Let $M$ be an absorbing convex subset of a vector space $X$. For each $x\in X$, define
\begin{align*}
	p_M(x) = \inf_{\alpha>0,\,x\in\alpha M}\alpha.
\end{align*}
Then $p_M:X\to\mathbb{R}_+$ is called the \textit{Minkowski functional} of $M$. It satisfies the following:
\vspace{0.05cm}
\begin{itemize}
	\item[(i)] $p_M$ is a sublinear functional on $X$;
	\vspace{0.05cm}
	\item[(ii)] If $M$ is balanced, then $p_M$ is a seminorm on $X$.
\end{itemize}
\begin{proof}
(i) Clearly, $0\in M$, and $p_M(\lambda x)=\lambda p_M(x)$ for all $\lambda > 0$. It remains to verify subadditivity.

For all $x,y\in X$ and all $\epsilon>0$, by definition,
\begin{align*}
	\frac{x}{p(x)+\epsilon}\in M,\ \frac{y}{p(y)+\epsilon}\in M.
\end{align*}
Note that $M$ is convex, we have
\begin{align*}
	\frac{x+y}{p(x)+p(y)+2\epsilon} = \frac{p(x)+\epsilon}{p(x)+p(y)+2\epsilon}\cdot\frac{x}{p(x)+\epsilon} +  \frac{p(y)+\epsilon}{p(x)+p(y)+2\epsilon}\cdot\frac{y}{p(y)+\epsilon} \in M.
\end{align*}
Therefore $p(x)+p(y)+2\epsilon \geq p(x+y)$. Since $\epsilon>0$ is arbitrary, the subadditivity of $p$ follows.
\vspace{0.1cm}

(ii) It remains to show homogeneity. When $\lambda\neq 0$,
\begin{align*}
	p_M(\lambda x) = \inf\left\{\alpha:\alpha>0,\lambda x\in \alpha M\right\} &= \inf\left\{\alpha:\alpha>0,\lambda\alpha^{-1}x\in M\right\}\\ &=\inf\left\{\alpha:\alpha>0,\vert\lambda\vert\alpha^{-1}x\in M\right\}\\
	&= \vert\lambda\vert\inf\{\alpha:\alpha>0,x\in\alpha M\} = \vert\lambda\vert p_M(x).
\end{align*}
The third equality holds because $M$ is balanced, which implies $\lambda\alpha^{-1}x\in M$ if and only if $\vert\lambda\vert\alpha x\in M$. 
\end{proof}

\paragraph{Lemma 2.33.\label{lemma:2.33}} Let $X$ be a vector space, and let $M$ be an absorbing convex subset of $X$. Then
\begin{align*}
	\{x\in X:p_M(x)<1\}\subset M\subset \{x\in X:p_M(x)\leq 1\}.
\end{align*}
\begin{proof}
For the first inclusion, let $x$ be a point of $X$ such that $p_M(x)<1$. Then there exists $\alpha\in(0,1)$ such that $\alpha^{-1}x\in M$. Since $M$ is star-shaped, $x\in M$. 

For the second inclusion, we have $p_M(x)=\inf\left\{\alpha:\alpha>0,x\in\alpha M\right\}\leq 1$ for all $x\in M$.
\end{proof}

\paragraph{Remark.} Let $X$ be a vector space. We consider the sets
\begin{align*}
	\mathcal{P}=\{p:p\ \text{is a seminorm on}\ X\}\quad \text{and}\quad
	\mathscr{M}=\{M\subset X:\ M\ \text{is a balanced absorbing convex set in}\ X\}.
\end{align*}
By \hyperref[prop:2.31]{Proposition 2.31} and \hyperref[lemma:2.32]{Lemma 2.32}, we define maps 
\begin{align*}
	\Phi:\mathcal{P}\to\mathscr{M},\ p\mapsto\{x\in X:p(x)\leq 1\}\quad \text{and}\quad \Psi:\mathscr{M}\to\mathcal{P},\ M\mapsto p_M,
\end{align*}
where $p_M$ is the Minkowski functional of $M$. By \hyperref[prop:2.31]{Proposition 2.31 (v)}, we have $\Psi\circ\Phi(p)=p$ for all $p\in\mathcal{P}$.

However, the equality $\Phi\circ\Psi(M)=M$ does not hold for all $M\in\mathscr{M}$. To see a counterexample, let $X$ be the Euclidean space $\mathbb{R}^n$, and let $M$ be the unit open ball $\{x\in X:\Vert x\Vert_2 < 1\}$. Then
\begin{align*}
	p_M(x) = \inf_{\alpha>0,\,x\in\alpha M}\alpha = \Vert x\Vert_2,
\end{align*}
and $\Phi\circ\Psi(M) = \{x\in X:\Vert x\Vert_2\leq 1\}$ is the unit closed ball. By \hyperref[lemma:2.33]{Lemma 2.33}, when $p_M$ is given, we can only determine $M$ between a lower bound $\{p_M(x)<1\}$ and an upper bound $\{p_M(x)\leq 1\}$.

\paragraph{Lemma 2.34.\label{lemma:2.34}} Let $M$ be an absorbing convex set in a vector space $X$. Let $x\in X$. The following are equivalent: (i) $p_M(x) < 1$; (ii) For all $y\in X$, there exists $\epsilon_y>0$ such that $x+ty\in M$ for all $\vert t\vert < \epsilon_y$.
\begin{proof}
(i) $\Rightarrow$ (ii): By definition, for every $y\in X$, there exists $\lambda_y>0$ such that $\lambda_y^{-1} y\in M$ and $-\lambda_y^{-1}y\in M$. Since $p_M(x)<1$, there exists $0< \alpha <1$ such that $\alpha^{-1} x\in M$. Then
\begin{align*}
	x + (1-\alpha)\lambda_y^{-1}y\in M,\ x - (1-\alpha)\lambda_y^{-1}y\in M.
\end{align*}
Note that $x\in M$, we have $x+ty\in M$ for all $\vert t\vert <\epsilon_y := (1-\alpha)\lambda_y^{-1}$.
\vspace{0.1cm}

(ii) $\Rightarrow$ (i): We prove the contrapositive. Assume that $p_M(x)\geq 1$, then $\alpha^{-1} x\notin M$ for all $0<\alpha < 1$. Therefore, $x+\epsilon x\notin M$ for all $\epsilon>0$, contradicting (ii).
\end{proof}

The following criterion to determine continuity of a Minkowski functional is useful.

\paragraph{Lemma 2.35.\label{lemma:2.35}} Let $M$ be an absorbing convex set in a normed space $X$. The Minkowski functional $p_M$ is continuous if and only if $0\in\mathring{M}$.
\begin{proof}
``$\Rightarrow$'': By continuity, $\{p_M(x)<1\} = p_M^{-1}((-\infty,1))$ is an open set containing $0$ and contained in $M$.
\vspace{0.1cm}

``$\Leftarrow$'': Let $O(0,\delta)$ be an open ball contained in $M$. Then $p(x)\leq 1$ for all $\Vert x\Vert\leq\delta$. Let $x_0\in X$ and $\epsilon>0$ be given. For all $x\in O(x_0,\delta\epsilon/2)$, since $p$ is a sublinear functional, we have
\begin{align*}
	p_M(x) - p_M(x_0) \leq p_M(x-x_0) \leq \frac{\epsilon}{2} < \epsilon.
\end{align*}
A similar statement holds for $p_M(x_0)-p_M(x)$. Since $x_0$ is arbitrary, $p_M(x)$ is continuous on $X$.
\end{proof}

\paragraph{Lemma 2.36.\label{lemma:2.36}} Let $M$ be an absorbing convex set in a normed space $X$ such that $0\in\mathring{M}$, and let $y\in X$. If $p_M(y)<1$, then $y\in\mathring{M}$. (Contrapositive: If $y\notin\overline{M}$, then $p_M(y)=1$.)
\begin{proof}
If $p_M(y)<1$, then there exists $\lambda>1$ such that $\lambda y\in M$. Since $0\in\mathring{M}$, by \hyperref[lemma:2.30]{Lemma 2.30}, $y\in\mathring{M}$.
\end{proof}

\paragraph{Remark.} By \hyperref[lemma:2.33]{Lemma 2.33} and \hyperref[lemma:2.36]{Lemma 2.36}, if $y\in\partial M$, where $\partial M=\overline{M}\cap\overline{(X\backslash M)}$ is the frontier $\partial M$ of an absorbing convex set $M$, then $p_M(y)=1$.

\paragraph{} Now we discuss the separation of convex sets.
\paragraph{Lemma 2.37\label{lemma:2.37}} (Separation of a convex set and a one-point set). Let $A$ be a convex subset of a real normed space $X$ such that $\mathring{A}\neq\emptyset$. Let $y_0\notin\mathring{A}$. Then there exists nonzero $f\in X^*$ that separates $A$ and $\{y_0\}$.
\begin{proof}
If $a\in\mathring{A}$, we separate $A-a$ and $\{y_0-a\}$. Without loss of generality, we suppose $0\in\mathring{A}$. Then there exists open ball $O(0,\epsilon)\subset A$, and $A$ is absorbing. By \hyperref[lemma:2.35]{Lemma 2.35}, the Minkowski functional $p_A$ is a continuous sublinear functional on $X$. By \hyperref[lemma:2.33]{Lemma 2.33}, $p_A(x)\leq 1$ for all $x\in A$. By \hyperref[lemma:2.36]{Lemma 2.36}, $p_A(y_0)\geq 1$.

Let $X_0=\mathrm{span}\left\{y_0\right\} = \mathbb{R}\cdot y_0$. Then $f_0:ty_0\mapsto tp_A(y_0)$ is a linear functional on $X_0$ that is subject to $p_A$:
\begin{align*}
	tp_A(y_0) = p_A(ty_0),\ t\geq 0;\quad
	tp_A(y_0) < 0 \leq p_A(ty_0),\ t<0.
\end{align*}

By Hahn-Banach theorem, there exists an extension $f$ on $X$ such that $f|_{X_0}=f_0$ and $f\leq p_A$. To show that $f\in X^*$, note that the continuity of $f$ follows from $p_A$:
\begin{align*}
	\vert f(x) - f(x^\prime)\vert = \vert f(x - x^\prime)\vert \leq p_A(x-x^\prime)
\end{align*}
Furthermore, $f$ separates $A$ and $\{y_0\}$: $f(x)\leq p_A(x)\leq 1$ for all $x\in A$, and $f(y_0) = p_A(y_0) \geq 1$.
\end{proof}

\paragraph{Remark.} In \hyperref[lemma:2.37]{Lemma 2.37}, if $A$ is an open convex set, and $y_0\notin A$, then
\begin{align*}
	f(x) < \sup_{y\in A} f(y) \leq f(y_0),\ \forall x\in A.
\end{align*}
For the first equality, let $O(x,\epsilon)$ be an open ball contained in $A$. Since $f$ is nonzero, there exists $f(z) > 0$. Then $x+\frac{\epsilon z}{2\Vert z\Vert}\in A$, and $f(x) < f\left(x+\frac{\epsilon z}{2\Vert z\Vert}\right)$.

\paragraph{Theorem 2.38\label{thm:2.38}} (Hyperplane separation theorem). Let $M$ and $N$ be convex sets in a real normed space $X$. If $\mathring{M}\neq\emptyset$, and $\mathring{M}\cap N=\emptyset$, then there exists nonzero $f\in X^*$ that separates $M$ and $N$.
\begin{proof}
By \hyperref[lemma:2.30]{Lemma 2.30}, $\mathring{M}$ is also a convex set. Define 
$$A=\mathring{M}-N = \bigcup_{y\in N} (\mathring{M}-y)=\{x-y:x\in\mathring{M},y\in N\}.$$
Then $A$ is an open and convex set in $X$, and $0\notin A$. By \hyperref[lemma:2.37]{Lemma 2.37}, there exists nonzero $f\in X^*$ that separates $A$ and $\{0\}$. Then $f^*$ separates $\mathring{M}$ and $N$: $\sup_{x\in\mathring{M}} f(x) \leq \inf_{y\in N}f(y)$.
\vspace{0.1cm}

Given $x\in M$, we fix some $z\in\mathring{M}$. Then $(1-t)x+tz\in\mathring{M}$ for all $t\in(0,1)$. Since $f$ is continuous,
\begin{align*}
	f(x) = \lim_{t\to 0^+} f\left((1-t)x+tz\right)\leq \sup_{x\in\mathring{M}} f(x) \leq \inf_{y\in N}f(y).
\end{align*}
Since $x\in M$ is arbitrary, $f$ also separates $M$ and $N$.
\end{proof}

\paragraph{Corollary 2.39\label{cor:2.39}} (Hyperplane separation theorem). Let $M$ and $N$ be disjoint closed convex sets in a normed space $X$. Then there exists nonzero $f\in X^*$ that strictly separates $M$ and $N$.
\begin{proof}
Since $M$ and $N$ are closed disjoint sets, $d(M,N)=\inf_{x\in M,y\in N}\Vert x-y\Vert > 0$. Let
\begin{align*}
	\widetilde{N} = \bigcup_{x\in N} O\left(x,\frac{d(M,N)}{3}\right)= \left\{x\in X:d(x,N)<\frac{d(M,N)}{3}\right\}.
\end{align*}
Then $\widetilde{N}$ is an open set in $X$ that is disjoint from $M$. Furthermore, for all $x,y\in\widetilde{N}$, there exists $z_x\in M$ and $z_y\in M$ such that $\Vert x-z_x\Vert< \frac{1}{3}d(M,N)$ and $\Vert y-z_y\Vert< \frac{1}{3}d(M,N)$. For all $t\in(0,1)$,
\begin{align*}
	d\left((1-t)x+ty, N\right) &\leq \Vert (1-t)x+ty - (1-t)z_x - tz_y\Vert\leq (1-t)\Vert x-z_x\Vert + t\Vert y-z_y\Vert < \frac{1}{3}d(M,N).
\end{align*}
Hence $\widetilde{N}$ is convex. 

By \hyperref[thm:2.38]{Theorem 2.38}, there exists nonzero $f\in X^*$ that separates $M$ and $\widetilde{N}$:
\begin{align*}
	\sup_{x\in M} f(x) \leq \beta\leq \inf_{y\in\widetilde{N}} f(y),\ \beta\in\mathbb{R}.
\end{align*}
Let $y\in N$ and $z\in O\left(0,\frac{d(M,N)}{3}\right)$, then $y-z\in\widetilde{N}$. Since $f(y)=f(y-z)+f(z)\geq \beta +f(z)$ for all $z\in O\left(0,\frac{d(M,N)}{3}\right)$, we have
\begin{align*}
	f(y) \geq \beta + \sup_{z\in O\left(0,d(M,N)/3\right)}f(z) = \beta + \frac{d(M,N)\Vert f\Vert}{3},\ \forall y\in N.
\end{align*}
As a result, $f$ strictly separates $M$ and $N$.
\end{proof}

\subsection{Dual Spaces}
\subsubsection{Dual Spaces of $L^p(X,\mathscr{A},\mu)$ and $C([a,b])$}
\paragraph{Example 2.40.\label{example:2.40}} Let $(X,\mathscr{A},\mu)$ be a measure space, and let $1\leq p < \infty$. Given $g\in L^q(X,\mathscr{A},\mu)$, where $q$ is the conjugate of $p$. (That is, $p^{-1}+q^{-1}=1$ if $p>1$, and $q=\infty$ if $p=1$.) We define a linear functional $T:L^p(X,\mathscr{A},\mu)\to\mathbb{R}$ by
\begin{align*}
	T(f) = \int_X fg\, d\mu,\ \forall f\in L^p(X,\mathscr{A},\mu).
\end{align*} 
By Hölder's inequality, $T(f)\leq\Vert f\Vert_p\Vert g\Vert_q$, which implies the continuity of $T$. Furthermore, $\Vert T\Vert=\Vert g\Vert_q$.
\vspace{0.1cm}

Naturally, we wonder if every continuous linear functional on $L^p(X,\mathscr{A},\mu)$ admits this form. If so, we can determine a unique function $g\in L^q(X,\mathscr{A},\mu)$ for each $T\in (L^p(X,\mathscr{A},\mu))^*$, and $\Vert g\Vert_q=\Vert T\Vert$. As a result, we have $(L^p(X,\mathscr{A},\mu))^*\cong L^q(X,\mathscr{A},\mu)$.

\paragraph{Riesz Representation Theorem.} Let $(X,\mathscr{A},\mu)$ be a $\sigma$-finite measure space. Let $1\leq p<\infty$, and let $q$ be the conjugate of $p$. Then for any bounded linear functional $T\in(L^p(X,\mathscr{A},\mu))^*$, there exists a unique $g\in L^q(X,\mathscr{A},\mu)$ such that
\begin{align*}
	T(f) = \int_X fg\, d\mu,\ \forall f\in L^p(X,\mathscr{A},\mu).
\end{align*}
Immediately, we have $(L^p(X,\mathscr{A},\mu))^*\cong L^q(X,\mathscr{A},\mu)$.
\begin{proof}
\textit{Step I:} We first suppose $\mu(X)<\infty$. Then $\chi_A\in L^p(X,\mathscr{A},\mu),\ \forall A\in\mathscr{A}$, and
$\nu:\mathscr{A}\to\mathbb{R},A\mapsto T(\chi_A)$ is well-defined. By continuity of $T$, $\nu$ is a signed measure that is absolutely continuous with respect to $\mu$:
\begin{align*}
	\mu(A)=0\ \Rightarrow\ 0\leq\vert \nu(A)\vert=\vert T(\chi_A)\vert\leq\left\Vert T\right\Vert\left\Vert\chi_A\right\Vert_p = 0
\end{align*}
By Radon-Nikodym theorem, there exists $g\in L^1(X,\mathscr{A},\mu)$ such that
\begin{align*}
T(\chi_A) = \nu(A) = \int_A g\,d\mu = \int_X g\chi_A\,d\mu,\ \forall A\in\mathscr{A}.
\end{align*}
As a result, for all simple functions $\varphi$ on $(X,\mathscr{A},\mu)$, we have
\begin{align*}
	T(\varphi) = \int_X g\varphi\,d\mu.\tag{2.5}\label{eq:2.5}
\end{align*}

\textit{Step II:} We prove that \hyperref[eq:2.5]{(2.5)} holds for all bounded measurable $\varphi$ on $(X,\mathscr{A},\mu)$. Suppose $\vert\varphi\vert\leq M$. Then there exists a sequence of simple functions $\varphi_n$ such that $\vert\varphi_n\vert\leq M$ and $\varphi_n$ converges pointwise to $\varphi$. By Lebesgue dominated convergence theorem,
\begin{align*}
	\lim_{n\to\infty}\Vert\varphi-\varphi_n\Vert_p^p = \lim_{n\to\infty}\int_X\vert\varphi-\varphi_n\vert^p\,d\mu  = \int_X\lim_{n\to\infty}\vert\varphi-\varphi_n\vert^p\,d\mu = 0.
\end{align*}
Since $T$ is continuous, and $\vert g\varphi_n\vert \leq M\vert g\vert$, which is integrable, we have
\begin{align*}
	T(\varphi) = \lim_{n\to\infty} T(\varphi_n) = \lim_{n\to\infty}\int_X g\varphi_n\,d\mu = \int_X g\varphi\,d\mu.
\end{align*}

\textit{Step III:} We prove that $g\in L^q(X,\mathscr{A},\mu)$. Suppose $p>1$ and $q<\infty$. Define sequence
\begin{align*}
	g_n(x) = \begin{cases}
		\vert g(x)\vert^{q-1}\mathrm{sgn}\,(g(x)),\ \text{if}\ \vert g(x)\vert^q \leq n,\\
		0,\ \text{otherwise}.
	\end{cases}
\end{align*}
By \hyperref[eq:2.5]{(2.5)}, we have
\begin{align*}
	\int_X \vert g_n\vert^q\,d\mu = T(g_n) \leq \Vert T\Vert\left\Vert g_n\right\Vert_p \leq\left\Vert T\right\Vert\left(\int_X \vert g_n\vert^q\,d\mu\right)^{1/p}\quad\Rightarrow\quad \left(\int_X \vert g_n\vert^q\,d\mu\right)^{1/q}\leq\Vert T\Vert.
\end{align*}
Let $n\to\infty$, then we have $g\in L^q(X,\mathscr{A},\mu)$, and $\Vert g\Vert_q\leq\Vert T\Vert$.
\vspace{0.1cm}

\textit{Step IV:} We show that $S(f) := T(f) - \int_X fg\,d\mu = 0$ for all $f\in L^p(X,\mathscr{A},\mu)$. By Hölder's inequality, $S$ is a continuous linear functional on $L^p(X,\mathscr{A},\mu)$ that vanishes on all bounded measurable functions. Since any $f\in L^p(X,\mathscr{A},\mu)$ can be approximated by its $n$-truncations $[f]_n=\min\{n,\max\{-n,f\}\}$ in $\Vert\cdot\Vert_p$, the result follows. The uniqueness of $g$ is clear.
\vspace{0.1cm}

\textit{Step V:} Let $(X,\mathscr{A},\mu)$ be $\sigma$-finite. Write $X=\bigcup_{n=1}^\infty X_n$, where $\mu(X_n)<\infty$ for all $n\in\mathbb{N}$. By Steps I-IV, we can find $g_n\in L^q(X,\mathscr{A},\mu)$, supported within $X_n$, such that $T(f)=\int_X fg_n\,d\mu=\int_{X_n} fg_n\,d\mu$ for all $f\in L^p(X,\mathscr{A},\mu)$, and $\Vert g_n\Vert_q\leq\Vert T\Vert$. Since $g_n$'s are unique, we assume that $g_{n+1}=g_n$ on $X_n$.

Let $g(x)=\lim_{n\to\infty}g_n(x)$ for all $x\in X$. Then $\vert g_n\vert\nearrow \vert g\vert$. By monotone convergence theorem, 
\begin{align*}
	\int_X\vert g\vert^q\,d\mu = \lim_{n\to\infty}\int_X\vert g_n\vert^q\,d\mu \leq\Vert T\Vert.
\end{align*}
Hence $g\in L^q(X,\mathscr{A},\mu)$. For any $f\in L^p(X,\mathscr{A},\mu)$, $f_n:=f\chi_{X_n}\to f$ pointwise, and $\vert f_ng\vert\leq\vert fg\vert$. By Lebesgue dominated convergence theorem,
\begin{align*}
	\int_X fg\,d\mu = \lim_{n\to\infty}\int_X f_ng\,d\mu  = \lim_{n\to\infty}\int_{X_n} f_ng_n\,d\mu = \lim_{n\to\infty} T(f_n) = T(f),
\end{align*}
as desired. Note the last equality follows from continuity of $T$.
\end{proof}

\paragraph{Remark I.} If $p=1$ and $q=\infty$, we need to modify Step III. Argue by contradiction. If $g\notin L^\infty(X,\mathscr{A},\mu)$, we have $\mu(E_\epsilon)>0$ for $E_\epsilon=\left\{\vert g\vert > \Vert T\Vert+\epsilon\right\}$ and all $\epsilon>0$. Then
\begin{align*}
	T(\chi_{E_\epsilon}) = \int_X g\chi_{E_\epsilon}\,d\mu \geq \mu(E_\epsilon)\left(\Vert T\Vert+\epsilon\right).
\end{align*}
Meanwhile, $\vert T(\chi_{E_\epsilon})\vert\leq\Vert T\Vert\left\Vert\chi_{E_\epsilon}\right\Vert_1 = \mu(E_\epsilon)\left\Vert T\right\Vert$, a contradiction! Hence $g\in L^\infty(X,\mathscr{A},\mu)$, and $\Vert g\Vert_\infty \leq \Vert T\Vert$.

\paragraph{Remark II.} If $p>1$, we can drop the requirement of $\sigma$-finiteness. Let $(X,\mathscr{A},\mu)$ be any measure space, and let $E\subset X$ be $\sigma$-finite. Then there exists a unique $g_E\in L^q(X,\mathscr{A},\mu)$, vanishing outside $E$, such that 
\begin{align*}
	T(f) = \int_X fg_E\,d\mu,\ \forall f\in L^p(X,\mathscr{A},\mu)\ \text{vanishing outside}\ E,\ \text{and}\ \Vert g_E\Vert_q\leq\Vert T\Vert.
\end{align*}
By uniqueness of $g_E$, for any $A\subset E$, $g_A=g_E$ almost everywhere on $A$. Define $\nu(E)=\int_X\vert g_E\vert^q\,d\mu$ for every $\sigma$-finite set $E$ in $X$. Then $\nu$ is a measure such that $\nu\ll\mu$, and $\nu(A)\leq\mu(E)<\Vert T\Vert^q$ for all $A\subset E$.

Let $M=\sup\{\nu(E):E\ \text{is}\ \sigma\text{-finite}\}$, and $\{E_n,n\in\mathbb{N}\}$ a sequence of sets such that $\lim_{n\to\infty}\nu(E_n) = M$. Then $H:=\bigcup_{n=1}^\infty E_n$ is $\sigma$-finite, and $\nu(H)=M$. For any $\sigma$-finite set $F\supset H$, $g_F=g_H$ a.e. on $H$, and
\begin{align*}
	\int_X\vert g_F\vert^q\,d\mu = \nu(F) \leq \nu(H) = \int_X\vert g_H\vert^q\,d\mu.
\end{align*}
Hence $g_F=0$ a.e. on $F\backslash H$. Let $g=g_H$, we have $g\in L^q(X,\mathscr{A},\mu)$, and $g_F=g$ a.e. for all $\sigma$-finite set $F\supset H$.

Given $f\in L^p(X,\mathscr{A},\mu)$, let $E=\{x\in X:f(x)\neq 0\}$. Then $E=\bigcup_{n=1}^\infty\{\vert f\vert > 1/n\}$ is $\sigma$-finite. As a result,
\begin{align*}
	T(f) = \int_E fg_E\,d\mu = \int_X fg\,d\mu.
\end{align*}

\paragraph{Review: Lebesgue-Stieltjes Measure.} Let $\Omega=[a,b]$ be a closed interval on $\mathbb{R}$. Then the collection of sets $\mathcal{E} = \{(u,v]:a\leq u\leq v \leq b\}$
is a ring: (i) $\emptyset\in\mathcal{E}$; (ii) $\forall A,B\in\mathcal{E}$, $A\cap B\in\mathcal{E}$; (iii) $\forall A,B\in\mathcal{E}$, $A\backslash B \in \mathcal{E}$.

Let $g$ be a non-decreasing function in $V_0([a,b])$, that is, $g$ is of bounded variation and right-continuous on $[a,b]$, and $g(a)=0$. We define a finite additive measure $\mu_{0g}$ on $\mathcal{E}$ by $\mu_{0g}((u,v]) = g(v)-g(u)$, and extend it to a pre-measure on the algebra $\mathcal{A}$ generated by $\mathcal{E}$ by setting $\mu_{0g}(\{a\})=0$. This pre-measure gives rise to an outer measure:
\begin{align*}
	\mu^*_g(E) = \inf\left\{\sum_{n=1}^\infty \mu_{0g}(A_n):\{A_n,n\in\mathbb{N}\}\subset\mathcal{A},\bigcup_{n=1}^\infty A_n\supset E\right\},\ \forall E\in 2^{\Omega}.
\end{align*}
By Carathéodory extension theorem, $\mu^*_g$ is a measure on $\{A\subset\Omega:\mu^*_g(A)=\mu^*_g(A\cap E) + \mu_g^*(A\backslash E),\forall E\subset\Omega\}$, which is a $\sigma$-algebra that contains all Borel sets $\mathscr{B}([a,b])$. Furthermore, the restriction $\mu_g=\mu_g^*|_{\mathscr{B}(\mathbb{R})}$ is the unique extension of $\mu_{0g}$ on $\mathscr{B}(\mathbb{R})$: $\mu_g((u,v])=g(v)-g(u)$ for all $a\leq u\leq v\leq b$.
\vspace{0.05cm}

Generally, let $g\in V_0([a,b])$ be given. Then 
\begin{align*}
	v_g(x) := V_a^x(g) = \sup\left\{\sum_{j=1}^n \vert g(x_j) - g(t_{j-1})\vert: n\in\mathbb{N},\ a=t_0<t_1<\cdots<t_n=x\right\}
\end{align*}
is a monotone non-decreasing function in $V_0([a,b])$. Clearly, $v_g - g\in V_0([a,b])$, and for all $a\leq x < y\leq b$,
\begin{align*}
	g(y) - g(x)\leq V_x^y(g) \leq V_a^y(g) - V_a^x(g) = v_g(y) - v_g(x).
\end{align*}
Hence $v_g-g$ is also non-decreasing. As a result, we can find a signed Borel measure $\mu_g:=\mu_{v_g} - \mu_{v_g-g}$ such that $\mu_g((u,v])=g(v)-g(u)$ for all $a\leq u\leq v\leq b$. Moreover, if $\nu_g$ is another such extension on $\mathscr{B}([a,b])$, then $\mathcal{F}=\{E\subset[a,b]:\mu_g(E)=\nu_g(E)\}$ is a $\lambda$-system that contains $\mathcal{E}$, which is a $\pi$-system. By Dynkin's $\pi$-$\lambda$ theorem, we have $\mathscr{B}([a,b])\subset\sigma(\mathcal{E})\subset\mathcal{F}$. Therefore $\nu_g=\mu_g$, and the extension $\mu_g$ is unique. We call this unique signed Borel measure $\mu_g$ the \textit{Lebesgue-Stieltjes measure} of $g$.

\paragraph{Theorem 2.41.\label{thm:2.41}} Define the space of all finite signed Borel measures on $[a,b]$ by
$$M([a,b]) = \left\{\mu:\mu\ \text{is a finite signed Borel measure on}\ [a,b]\right\},$$ 
and define a norm on $M([a,b])$ by
\begin{align*}
	\Vert\mu\Vert = \sup\left\{\sum_{j=1}^n\left\vert\mu(E_i)\right\vert:E_j\in\mathscr{B}([a,b]),\coprod_{i=1}^n E_i=[a,b]\right\},\ \forall \mu\in M([a,b]).
\end{align*}
Then $V_0([a,b])\cong M([a,b])$.
\begin{proof}
Define $U:V_0([a,b])\to M([a,b]),\ g\mapsto \mu_g$, where $\mu_g$ is the Lebesgue-Stieltjes measure of $g\in V_0([a,b])$. Clearly, $U$ is a linear map. For all $a=t_0<t_1<\cdots < t_n = b$, we have
\begin{align*}
	\sum_{j=1}^n\vert g(t_{j})-g(t_{j-1})\vert = \sum_{j=1}^n\left\vert \mu_g\left((t_{j},t_{j-1}]\right)\right\vert\leq\Vert \mu_g\Vert,
\end{align*}
which implies $\Vert g\Vert \leq \Vert\mu_g\Vert$. Furthermore, $g_1=\frac{1}{2}(v_g-g)$ and $g_2=\frac{1}{2}(v_g+g)$ are non-decreasing, then
\begin{align*}
	\Vert \mu_g\Vert = \Vert \mu_{g_2}-\mu_{g_1}\Vert \leq \Vert \mu_{g_1} + \mu_{g_2}\Vert = \Vert \mu_{v_g}\Vert = v_g(b) = V_a^b(g) = \Vert g\Vert.
\end{align*}
The inequality holds because $\vert \mu_{g_1}(E)-\mu_{g_2}(E)\vert \leq \mu_{g_1}(E)+\mu_{g_2}(E)$ for all $E\in\mathscr{B}([a,b])$.
\vspace{0.1cm}

Finally, for each $\mu\in M([a,b])$, let $g(x):=\mu((a,x]),\, x\in[a,b]$. Clearly, $V_a^b g\leq\Vert\mu_g\Vert$. Moreover, for every sequence $\epsilon_n\searrow 0$,
\begin{align*}
	\lim_{n\to \infty}\mu((a,x+\epsilon_n]) = \mu\left(\bigcap_{n=1}^\infty(a,x+\epsilon_n]\right) = \mu((a,x]).
\end{align*}
Hence $g$ is right-continuous, and $\mu$ is the Lebesgue-Stieltjes measure of $g\in V_0([a,b])$, which implies surjectivity of the map $U$. Therefore, $U:V_0([a,b])\to M([a,b])$ is a norm-preserving isomorphism, as desired.
\end{proof}

\paragraph{Example 2.42\label{example:2.42}} (Dual spaces of $C([a,b])$)
Given a function $g\in V_0([a,b])$, we define the \textit{Lebesgue-Stieltjes integral} of $\varphi\in C([a,b])$ relative to $g$ as
\begin{align*}
	F_g(\varphi) = \int_a^b\varphi(t)\,dg(t) := \int_{[a,b]}\varphi\,d\mu_g
\end{align*}
Clearly, $F_g$ is a linear functional on $C([a,b])$. Moreover,
\begin{align*}
	\vert F_g(\varphi)\vert\leq \int_a^b\vert\varphi(t)\vert\,\vert dg\vert(t) \leq \left\Vert \varphi\right\Vert_\infty\left\Vert g\right\Vert,
\end{align*}
and the equality holds if $\varphi=\chi_P - \chi_N$, where $P\amalg N=[a,b]$ is a Hahn decomposition for $\mu_g$. As a result, we have $F_g\in\left(C([a,b])\right)^*$, and $\Vert F_g\Vert = \Vert g\Vert = V_a^b(g)$. Naturally, we wonder if every continuous linear functional on $C([a,b])$ is determined by Lebesgue-Stieltjes integration, which implies $(C([a,b]))^*\cong V_0([a,b])$.

\paragraph{Riesz Representation Theorem.} For all $F\in(C([a,b]))^*$, there exists a unique $g\in V_0([a,b])$ such that
\begin{align*}
	F(\varphi) = F_g(\varphi) = \int_a^b \varphi(t)\,dg(t),\ \forall \varphi\in C([a,b]),\ \text{and}\ \Vert F\Vert = \Vert g\Vert = V_a^b(g).
\end{align*}
\begin{proof}
\textit{Step I:} We first view $C([a,b])$ as a subspace of $(B([a,b]),\Vert\cdot\Vert_\infty)$, which is the space of all bounded functions on $[a,b]$, and $\Vert f\Vert_\infty = \sup_{x\in[a,b]}\vert f(x)\vert$ for all $f\in B([a,b])$. By Hahn-Banach theorem, there exists an extension $F_B:B([a,b])\to\mathbb{R}$ of $F$ such that $F_B|_{C([a,b])}=F$ and $\Vert F_B\Vert = \Vert F\Vert$.
\vspace{0.15cm}

\textit{Step II:} Let $h(t):=F_B(\chi_{[a,t]})$ for all $t\in[a,b]$. We first show that $h\in V([a,b])$. For each partition $a=t_0<t_1<\cdots<t_n=b$, let $\epsilon_j=\mathrm{sgn}\left[h(t_j)-h(t_{j-1})\right],\ t=1,\cdots,n$. Then
\begin{align*}
	\sum_{j=1}^n\vert h(t_j)-h(t_{j-1})\vert &= \sum_{j=1}^n\epsilon_j\left[h(t_j)-h(t_{j-1})\right]\\ 
	&= F_B\left(\sum_{j=1}^n\epsilon_j\chi_{(t_{j-1},t_j]}\right)\leq \Vert F_B\Vert\left\Vert\sum_{j=1}^n\epsilon_j\chi_{(t_{j-1},t_j]}\right\Vert_\infty \leq \Vert F\Vert.
\end{align*}
Hence $h\in V([a,b])$, and $V_a^b(h)\leq \Vert F\Vert$. Clearly, $h(a)=0$. Now we define
\begin{align*}
	g(x) =\begin{cases}
		\lim_{\epsilon\to 0^+}h(x+\epsilon),\ &x\in(a,b),\\
		h(x),\ &x\in\{a,b\}.
	\end{cases} 
\end{align*}
Then $g$ is right-continuous, and $V_a^b(g)\leq V_a^b(h)$.
\vspace{0.15cm}

\textit{Step III:} We prove that
\begin{align*}
	F_B(\varphi) = \int_a^b \varphi(t)\,dg(t),\ \forall\varphi\in C([a,b]).
\end{align*}
Fix $\varphi\in C([a,b])$, and choose partitions $a=x_0^{(k)} < x_1^{(k)} < \cdots < x_{n_k}^{(k)} = b$ such that
\begin{itemize}
	\vspace{0.05cm}
	\item $\bigl\{x_j^{(k)},\ j=1,\cdots,n_k-1\bigr\}$ are continuous points of $h$; and
	\vspace{0.05cm}
	\item $\lim_{k\to\infty}\max_{1\leq j\leq n_k} \bigl[x_j^{(k)} - x_{j-1}^{(k)}\bigr] = 0$.\vspace{0.1cm}
\end{itemize}
We can always choose such partitions on $[a,b]$, because a function $h$ of bounded variation on $[a,b]$ has at most countably many discontinuous points. Define
\begin{align*}
	\varphi_k(t) = \sum_{j=1}^{n_k}\varphi(x_j^{(k)})\left(\chi_{[a,x_j^{(k)}]}(t) - \chi_{[a,x_{j-1}^{(k)}]}(t)\right)
\end{align*}
Then $\varphi_k\in B([a,b])$, and $\lim_{k\to\infty}\Vert \varphi_k - \varphi\Vert_\infty = 0$. Furthermore,
\begin{align*}
	F_B(\varphi_k) &= \sum_{j=1}^{n_k}\varphi(x_j^{(k)})\left[h(x_j^{(k)}) - h(x_{j-1}^{(k)})\right]\\
	&= \sum_{j=1}^{n_k}\varphi(x_j^{(k)})\left[g(x_j^{(k)}) - g(x_{j-1}^{(k)})\right]\\
	&= \int_a^b \sum_{j=1}^{n_k}\varphi(x_j^{(k)})\left(\chi_{[a,x_j^{(k)}]}(t) - \chi_{[a,x_{j-1}^{(k)}]}(t)\right)\,dg(t) = \int_a^b\varphi_k(t)\,dg(t).
\end{align*}
Note that $\vert\varphi_k\vert\leq \Vert\varphi\Vert_\infty$. By Lebesgue dominated convergence theorem, 
\begin{align*}
	F_B(\varphi) = \lim_{k\to\infty}F_B(\varphi_k) = \int_a^b\lim_{n\to\infty}\varphi_k(t)\,dg(t) = \int_a^b\varphi(t)\,dg(t).
\end{align*}
Then $F(\varphi)=F_B(\varphi) = F_g(\varphi)$ for all $\varphi\in C([a,b])$. Clearly, $\Vert F\Vert = \Vert F_g\Vert = V_a^b(g)$, and $g$ is unique.
\end{proof}

\paragraph{Remark.} By \hyperref[thm:2.41]{Theorem 2.41}, $V_0([a,b])\cong M([a,b])$. Then $(C([a,b]))^*\cong M([a,b])$: for all bounded linear functional $F$ on $C([a,b])$, there exists a unique finite signed measure $\mu$ on $([a,b],\mathscr{B}([a,b]))$ such that
\begin{align*}
	F(\varphi) = \int_{[a,b]}\varphi\,d\mu,\ \forall\varphi\in C([a,b]).
\end{align*}

\subsubsection{Reflexive Spaces}
Let $X$ be a normed space. The dual space $X^*$ is the set of all bounded linear functionals on $X$. The \textit{bidual space} $X^{**}$, is the set of all bounded linear functionals on $X^*$.
\paragraph{Definition 2.43\label{def:2.43}} (Canonical maps). Let $x$ be a normed space. Given $x\in X$, define $x^{**}: X^*\to\mathbb{R}$ as
\begin{align*}
	x^{**}(f) = f(x),\ \forall f\in X^*.
\end{align*}
Then $x^{**}$ is a linear functional on $X^*$, and $\vert x^{**}(f)\vert\leq\left\Vert f\right\Vert\left\Vert x\right\Vert$. Hence we have $x^{**}\in X^{**}$, and $\Vert x^{**}\Vert\leq\Vert x\Vert$. We define the \textit{canonical map} $J:X\to X^{**}$ as $J(x)=x^{**}$.

\paragraph{Lemma 2.44.\label{lemma:2.44}} Let $X$ be a normed space, and let $J:X\to X^{**}$ be the canonical map. Then $J$ is a norm-preserving linear operator.
\begin{proof}
The linearity is clear: $(\alpha x+\beta y)^{**}=\alpha x^{**} + \beta y^{**}$ for all $x,y\in X$, $\alpha,\beta\in\mathbb{R}$ (or $\mathbb{C}$). To show that $J$ is norm preserving, it suffices to show $\Vert x^{**}\Vert\geq\Vert x\Vert$ for all $x\in X$. By \hyperref[cor:2.22]{Corollary 2.22}, there exists $f_0\in X^*$ such that $\Vert f_0\Vert=1$ and $f_0(x)=\Vert x\Vert$. Then $\left\Vert x^{**}\right\Vert \geq x^{**}(f_0) = f_0(x) = \left\Vert x\right\Vert$.
\end{proof}

\paragraph{Definition 2.45\label{def:2.45}} (Reflexive spaces). Let $X$ be a normed space. $X$ is said to be a \textit{reflexive space}, if the canonical map $J:X\to X^{**}$ is an isomorphism. In this case, $X^{**}\cong X$.
\paragraph{Remark.} (i) If $X$ is reflexive, so is $X^*$: $(X^*)^{**} = (X^{**})^* = X^*$.

(ii) By definition, $X^{**}$ is complete. If $X$ is not complete, then the closure of $JX$ in $X^{**}$ automatically gives a completion of $X$.

\paragraph{Example 2.46.\label{example:2.46}} Let $(X,\mathscr{A},\mu)$ be a measure space. By \hyperref[example:2.42]{Example 2.42}, for $1<p<\infty$, $L^p(X,\mathscr{A},\mu)$ is reflexive.

\paragraph{Theorem 2.47.\label{thm:2.47}} Let $M$ be a closed subspace of a reflexive space $X$. Then $M$ and $X/M$ are reflexive.
\begin{proof}
(i) To prove that $M$ is reflexive, it suffices to show the canonical map $J_M:M\to M^{**}$ is surjective.

Let $m^{**}\in M^{**}$. Define $x^{**}(f) = m^{**}(f|_M)$ for all $f\in X^*$. Then $x^{**}\in X^{**}$, and there exists $x\in X$ such that $J(x)=x^{**}$. If $x\notin M$, by \hyperref[cor:2.23]{Corollary 2.23}, there exists $f\in X^*$ such that $f(x)\neq 0$, $f(M)=\{0\}$. However, $f(x) = x^{**}(f) = m^{**}(f|_M) = 0$, a contradiction! Hence $x\in M$.

We want $J_M(x)=m^{**}$, which completes the proof. For each $g\in M^*$, by Hahn-Banach theorem, there exists an extension $f\in X^*$ of $g$. Hence $g(x) = f(x) = x^{**}(f) =  m^{**}(f|_M) = m^{**}(g)$, and $m^{**}=J(x)$. \vspace{0.1cm}

(ii) We show the canonical map $J_{X/M}:X/M\to(X/M)^{**}$ is surjective. Given $[x]^{**}\in (X/M)^{**}$, we define $y^{**}(f\circ\pi) = [x]^{**}(f)$ for all $f\in(X/M)^*$, where $\pi:X\to X/M$ is the quotient map. Then $y^{**}$ is a bounded linear functional on $(X/M)^*\circ\pi:=\{f\circ\pi:f\in(X/M)^*\}$, a subspace of $X^*$. By Hahn-Banach theorem, there exists an extension $x^{**}\in X^{**}$ of $y^{**}$. Since $X$ is reflexive, there exists $x\in X$ such that $J(x)=x^{**}$.

It remains to show $J_{X/M}([x])=[x]^{**}$, which completes the proof: For all $f\in (X/M)^{*}$, \vspace{0.3cm}

$\hspace{4cm} f([x]) = (f\circ\pi)(x) = x^{**}(f\circ\pi) = y^{**}(f\circ\pi) = [x]^{**}(f).$
\end{proof} 

\paragraph{Lemma 2.48.\label{lemma:2.48}} Let $X$ be a reflexive space. Then for all $f\in X^*$, there exists $x\in X$ such that $\Vert x\Vert = 1$ and $f(x)=\Vert f\Vert$.
\begin{proof}
By \hyperref[cor:2.22]{Corollary 2.22 (i)}, for all $f\in X^*$, let $x^{**}\in X^{**}$ be such that $\Vert x^{**}\Vert = 1$ and $x^{**}(f) = \Vert f\Vert$. By reflexivity, choosing $x$ such that $J(x)=x^{**}$ completes the proof.
\end{proof}

We also have the following conclusion similar to \hyperref[cor:1.39]{Corollary 1.39}.
\paragraph{Theorem 2.49.\label{thm:2.49}} Let $X$ be a normed space.
\begin{itemize}
	\item[(i)] Let $M$ be a subspace of $X$. Then $^\perp(M^\perp)=\overline{M}$;
	\item[(ii)] Let $G$ be a subspace of $X^*$. If $X$ is reflexive, then $(^\perp G)^\perp = \overline{G}$.
\end{itemize}
\begin{proof}
(i) Let $x\in M$. Then $f(x)=0$ for all $f\in M^\perp$, which implies $x\in$$^\perp(M^\perp)$. Since $^\perp(M^\perp)$ is a closed subspace of $X$, $\overline{M}\subset$$^\perp(M^\perp)$. If $\overline{M}\neq$ $^\perp(M^\perp)$, choose $x\in$$^\perp(M^\perp)\backslash\overline{M}$. By \hyperref[cor:2.23]{Corollary 2.23}, there exists $f\in X^*$ such that $f(\overline{M}) = \{0\}$ and $f(x)\neq 0$. Then $f\in M^\perp$. However, $x\in$$^\perp(M^\perp)$ implies $f(x)=0$, a contradiction!
\vspace{0.1cm}

(ii) Clearly, $\overline{G}\subset(^\perp G)^\perp$. If $\overline{G}\neq(^\perp G)^\perp$, choose $g\in(^\perp G)^\perp\backslash\overline{G}$. There exists $x^{**}\in X^{**}$ such that $x^{**}\left(\overline{G}\right)=\{0\}$ and $x^{**}(g)\neq 0$. By reflexivity, choose $x=J^{-1}(x^{**})\in X$. Then $x\in\overline{G}^\perp\subset G^\perp$, and $g(x)\neq 0$. However $g\in(^\perp G)^\perp$, which implies $g(x)=0$, a contradiction!
\end{proof}

Finally we see some examples of normed spaces that are not reflexive. 
\paragraph{Lemma 2.50.\label{lemma:2.50}} Let $X$ be a normed space. If $X^*$ is separable, so is $X$.
\begin{proof}
If $X^*$ is separable, choose a dense sequence $\{f_n\}$ in $X^*$ in the unit sphere $S_{X^*}=\{f\in X^*:\Vert f\Vert=1\}$. For each $n\in\mathbb{N}$, there exists $x_n\in S_X=\{x\in X:\Vert x\Vert=1\}$ such that $\vert f_n(x_n)\vert > 1/2$. Denote by $X_0:=\overline{\mathrm{span}}\left\{x_n,n\in\mathbb{N}\right\}$ the closed subspace spanned by $\{x_n\}$. We prove $X_0=X$.

Argue by contradiction. If $x\in X\backslash X_0$, then there exists $f\in X^*$ such that $\Vert f\Vert=1$, $f(X_0)=\{0\}$ and $f(x) \neq 0$. Then for all $n\in\mathbb{N}$,
\begin{align*}
	\Vert f_n - f\Vert = \vert f_n(x_n)-f(x_n)\vert = \vert f_n(x_n)\vert > \frac{1}{2},
\end{align*}
contradicting the density of $\{f_n\}$ in $S_{X^*}$. Hence $X_0=X$. Furthermore, $\{qx_n,q\in\mathbb{Q},n\in\mathbb{N}\}$ is a countable dense subset of $X_0$, as desired.
\end{proof}

\paragraph{Example 2.51.\label{example:2.51}} The space $L^1([a,b])$ is not reflexive.
\begin{proof}
If $L^1([a,b])$ is reflexive, then $(L^1([a,b]))^{**}= L^1([a,b])$. Since $L^1([a,b])$ is separable, by \hyperref[lemma:2.50]{Lemma 2.50}, $L^\infty([a,b])=(L^1([a,b]))^*$ is separable. Recall that every countable subset of $\{\chi_{[a,t]},t\in[a,b]\}$ is not dense in itself, giving rise to a contradiction!
\end{proof}

\newpage
\subsection{Weak and Weak-$^*$ Topologies}
Pointwise convergence of sequences can be topologized in function spaces.
\paragraph{Definition 2.52\label{def:2.52}} (Weak topology and weak-$^*$ topology). Let $X$ be a normed space.
\begin{itemize}
\vspace{0.1cm}
\item[(i)] Given a point $x_0$ of $X$, finitely many $f_1,\cdots,f_n\in X^*$ and $\epsilon_1,\cdots,\epsilon_n > 0$, define
\begin{align*}
	U_{f_1,\cdots,f_n}^{\epsilon_1,\cdots,\epsilon_n}(x_0) := \left\{x\in X: \vert f_1(x-x_0)\vert < \epsilon_1,\cdots,\vert f_n(x-x_0)\vert < \epsilon_n\right\}
\end{align*}
The collection of sets $\bigl\{U_{f_1,\cdots,f_n}^{\epsilon_1,\cdots,\epsilon_n}(x):x\in X,\ n\in\mathbb{N},\ f_1,\cdots,f_n\in X^*,\ \epsilon_1,\cdots,\epsilon_n > 0\bigr\}$ forms a basis for a topology on $X$, which is called the \textit{weak topology}.
\vspace{0.1cm}
\item[(ii)] Given a point $f_0$ of $X^*$, finitely many $x_1,\cdots,x_n\in X$ and $\epsilon_1,\cdots,\epsilon_n > 0$, define
\begin{align*}
	U_{x_1,\cdots,x_n}^{\epsilon_1,\cdots,\epsilon_n}(f_0) := \left\{f\in X^*: \vert (f - f_0)(x_1)\vert < \epsilon_1,\cdots,\vert (f - f_0)(x_n)\vert < \epsilon_n\right\}
\end{align*}
The collection of sets $\bigl\{U_{x_1,\cdots,x_n}^{\epsilon_1,\cdots,\epsilon_n}(f):f\in X^*,\ n\in\mathbb{N},\ x_1,\cdots,x_n\in X,\ \epsilon_1,\cdots,\epsilon_n > 0\bigr\}$ forms a basis for a topology on $X^*$, which is called the \textit{weak-$^*$ topology}.
\end{itemize}
\paragraph{Remark.} We obtain three topologies on the dual space $X^*$: the norm topology, the weak topology, and the weak-$^*$ topology. By definition, the weak-$^*$ topology is in fact the product topology (or the point-open topology) on $\mathbb{C}^X$ (the space of all complex-valued functionals on $X$) restricted to $X^*$. Furthermore, if $X$ is reflexive, its weak and weak-$^*$ topologies coincide.

\paragraph{Definition 2.53\label{def:2.53}} (Weak and weak-$^*$ convergence). Let $X$ be a normed space. Let $x\in X$ and $f\in X^*$.
\begin{itemize}
\item[(i)] A sequence $(x_n)$ of points of $X$ is said to \textit{converges to $x$ in the weak topology on} $X$, if
$f(x_n)\to f(x)$ for all $f\in X^*$. We write $x_n\overset{w}{\to} x$.
\item[(ii)] A sequence $(f_n)$ of points of $X^*$ is said to \textit{converges to $f$ in the weak-$^*$ topology on} $X^*$, if
$f_n(x)\to f(x)$ for all $x\in X$. We write $f_n\overset{w^*}{\to} f$.
\end{itemize}

\paragraph{Theorem 2.54\label{thm:2.54}} (Banach-Alaoglu). Let $X$ be a normed space. The unit closed ball $B^*=\{f\in X^*:\Vert f\Vert\leq 1\}$ is compact in the weak-$^*$ topology on $X^*$.
\begin{proof}
The weak-$^*$ topology on $X^*$ is the same as the product topology on $\mathbb{C}^X$ restricted to $X^*$. Then they also coincide on $B^*\subset X^*$.  Hence we can prove that $B^*$ is compact in the product topology.

For each $x\in X$, we define the closed disc $D_x = \{z\in\mathbb{C}:\vert z\vert\leq \Vert x\Vert\}$. Then $D_x$ is compact in $\mathbb{C}$. By Tychonoff theorem,
\begin{align*}
	D = \prod_{x\in X} D_x
\end{align*}
is a compact topological space under the product topology. Furthermore, every element $f\in D$ is a $\mathbb{C}$-valued functional on $X$ such that $\vert f(x)\vert\leq \Vert x\Vert$ for each $x\in X$. Clearly, $B^*\subset D$.

It suffices to show $B^*$ is closed in $D$ (given the product topology), which implies compactness of $B^*$. Let $\{f_\lambda,\lambda\in\Lambda\}$ be a net in $B^*$ such that $f_\lambda\to f\in D$. Since the projection maps $\pi_x$ are continuous in the product topology, we have
\begin{align*}
	f_\lambda(x) = \pi_x(f_\lambda) \to \pi_x(f) = f(x),\ \forall x\in X.
\end{align*}
Then $f(\alpha x+\beta y) = \lim_\lambda f_\lambda(\alpha x+\beta y) = \lim_\lambda (\alpha f_\lambda(x) + \beta f_\lambda(y)) = \alpha f(x) + \beta f(y)$ for all $\alpha,\beta\in\mathbb{C}$ and all $x,y\in X$, and $f$ is linear. By $f\in D$, we have $\Vert f\Vert\leq 1$. Therefore $f\in B^*$, and $B^*$ is closed in $D$, as desired.
\end{proof}

\paragraph{Remark.} Let $X$ be a normed space. If $X^*$ is infinite-dimensional, we know that the closed unit ball in $X^*$ is not compact in the norm topology. However, by Banach-Alaoglu theorem, it is compact in the weak-$^*$ topology. This is one important reason why we introduce the weak-$^*$ topology.

We also have another version of Banach-Alaoglu theorem on separable normed spaces, which is similar to the Bolzano-Weierstrass theorem for $\mathbb{R}$.
\paragraph{Theorem 2.55\label{thm:2.55}} (Banach-Alaoglu). Let $X$ be a separable normed space. If $\{f_n\}$ is a bounded sequence of points of $X^*$, then there exists a subsequence $\{f_{n_k}\}$ that converges in the weak-$^*$ topology on $X^*$.
\begin{proof}
By boundedness, $\{f_n\}$ is contained in some closed ball $B_M^*:=\{f\in X^*:\Vert f\Vert\leq M\}$. By \hyperref[thm:2.54]{Theorem 2.54}, $B_M^*$ is compact, hence limit-point compact in the weak-$^*$ topology on $X^*$. Then $\{f_n\}$, being an infinite subset of $B_M^*$, has at least one limit point $f_0\in B_M^*$.

We want to find a subsequence $f_{n_k}\overset{w^*}{\to} f_0$. Note that $X$ is separable, we choose its dense subset $\{x_n,n\in\mathbb{N}\}$. For each $k\in\mathbb{N}$, define
\begin{align*}
	U_k = \left\{f\in X^*: \vert f(x_1) - f_0(x_1)\vert<\frac{1}{k},\cdots,\vert f(x_k) - f_0(x_k)\vert<\frac{1}{k}\right\}.
\end{align*}
Since $f_0$ is a limit point of $\{f_n\}$, we can choose a subsequence ${f_{n_k}}$ such that $f_{n_k}\in U_k$. For all $x\in X$ and all $\epsilon>0$, there exists $x_m$ such that $\Vert x-x_m\Vert < \epsilon/(3M)$. Once $k\geq\max\{m,3/\epsilon\}$, we have
\begin{align*}
	\vert f_0(x) - f_{n_k}(x)\vert &\leq \vert f_0(x) - f_0(x_m)\vert + \vert f_{0}(x_m) - f_{n_k}(x_m)\vert + \vert f_{n_k}(x_m) - f_{n_k}(x)\vert\\
	&\leq 2M\Vert x - x_m\Vert + \frac{1}{k} < \epsilon. 
\end{align*}
Hence we have $f_{n_k}\overset{w^*}{\to} f_0$, as desired.
\end{proof}

\paragraph{Theorem 2.56\label{thm:2.56}} (Banach-Alaoglu). Let $X$ be a reflexive space. The unit closed ball $B=\{x\in X:\Vert x\Vert\leq 1\}$ is weakly sequentially compact.
\begin{proof}
We first assume that $X=X^{**}$ is separable, so $X^*$ is separable by \hyperref[lemma:2.50]{Lemma 2.50}. Take $(x_n)\subset B$. Then the bounded sequence $(Jx_n)$ in $X^{**}$ has a weak* convergent subsequence $(Jx_{n_k})$ by \hyperref[thm:2.55]{Theorem 2.55}. Since $J:X\to X^{**}$ is an isomorphism, $(x_{n_k})$ converges in the weak topology on $X$.

Now we assume that $X$ is reflexive and let $(x_n)$ be a sequence in $B$. Let $Y=\overline{\mathrm{span}}\{x_n:n\in\mathbb{N}\}$. Then $Y$ is separable by definition, and by Theorem \hyperref[thm:2.47]{2.47}, $Y$ is reflexive. Hence $(x_n)$ has a subsequence $(x_{n_k})$ that converges weakly to an element of $B$, and $B$ is sequentially weakly compact.
\end{proof}
\paragraph{Remark.} If $X$ is a reflexive space, every bounded sequence in $X$ has a weakly convergent subsequence.

\paragraph{Theorem 2.57\label{thm:2.57}} (Mazur). Let $X$ be a real normed space, and let $(x_n)$ be a sequence of points of $X$ that converges to $x\in X$ in the weak topology. Then there exists sequence $(y_n)$ such that every $y_n$ is a convex combination of finitely many $x_{n_1},\cdots,x_{n_k}$, and that $y_n\overset{\Vert\cdot\Vert}{\to} x$. Equivalently, $x\in\overline{\mathrm{co}\left(\{x_n,n\in\mathbb{N}\}\right)}$.
\begin{proof}
Argue by contradiction. Let $M:=\mathrm{co}\left(\{x_n,n\in\mathbb{N}\}\right)$ be the convex hull of $(x_n)$. Using hyperplane separation theorem, if $x\notin\overline{M}$, there exists $f\in X^*$ and $c\in\mathbb{R}$ such that $f(y)<c<f(x)$ for all $y\in\overline{M}$. As a result, $f(x_n)<c<f(x)$, contradicting $x_n\overset{w}{\to} x$! Therefore $x\in\overline{M}$, as desired.
\end{proof}

\paragraph{Corollary 2.58.\label{cor:2.58}} Let $M$ be a convex set in a normed space $X$. Then the closures of $M$ in the norm topology and in the weak topology coincide.

\newpage
\section{Bounded Linear Operators}
\subsection{Baire Category Theorem}
\paragraph{Definition 3.1\label{def:3.1}} (Nowhere dense sets/rare sets). Let $A$ be a subset of a topological space $X$. If the closure of $A$ does not contain any nonempty open subset of $X$, that is, $\overline{A}$ has no interior point, then $A$ is said to be a \textit{nowhere dense} set (or a \textit{rare} set) in $X$.
\paragraph{Remark.} By definition, $A$ is nowhere dense if and only if $\overline{A}$ is nowhere dense. 
\paragraph{Lemma 3.2.\label{lemma:3.2}} Let $A$ be a subset of a topological space $X$. Then $A$ is rare if and only if $X\backslash\overline{A}$ is dense in $X$.
\begin{proof}
$X\backslash\overline{A}\ \textit{is dense in}\ X\ \Leftrightarrow\ X\backslash\overline{A}\ \textit{intersects every open set in}\ X\ \Leftrightarrow\ \overline{A}\ \textit{is rare in}\ X.$
\end{proof}

\paragraph{Example 3.3.\label{example:3.3}} Following are some instances for nowhere dense sets.
\begin{itemize}
\vspace{0.1cm}
\item[(i)] The set of integers $\mathbb{Z}$ is rare in $\mathbb{R}$. The set $A=\left\{\frac{1}{n}:n\in\mathbb{N}\right\}$ is rare in $[0,1]$.
\vspace{0.1cm}
\item[(ii)] Let $X$ be a normed space. Let $Y$ be a proper subspace of $X$. Then $Y$ is rare in $X$. (If not, there exists an open neighborhood of $0$ contained in $Y$. Then $Y$ is absorbing, and $Y=X$, a contradiction!)
\vspace{0.1cm}
\item[(iii)] A Cantor set $C$ is obtained by repeatedly removing the open middle third from a collection of line segments, starting from the unit interval $[0,1]$:
\begin{align*}
	C_1=[0,1]\ \to\  C_2=\left[0,\frac{1}{3}\right]\cup\left[\frac{2}{3},1\right]\ \to\  C_3=\left[0,\frac{1}{9}\right]\cup\left[\frac{2}{9},\frac{1}{3}\right]\cup\left[\frac{2}{3},\frac{7}{9}\right]\cup\left[\frac{8}{9},1\right]\ \to\ \cdots.
\end{align*}
The Cantor set $C=\bigcup_{n=1}^\infty C_n$ is a rare set in $\mathbb{R}$. To see this, let $x\in C$. Then any open interval of form $(x-\epsilon,x+\epsilon)$ is not contained in $C$, because the length of subintervals in $C_n$ with $n>\frac{\log\epsilon}{\log 2}$ is less than $2^{-n+1}<2\epsilon$. (Note that $C_n$ has $2^{n-1}$ subintervals of the same length.)
\vspace{0.1cm}
\item[(iv)] A Smith-Volterra-Cantor set is also obtained by removing certain intervals from $[0,1]$. For instance, we start from $[0,1]$ and remove the middle $1/4^{n}$ from the remaining $2^{n-1}$ intervals at the $n$-th step:
\begin{align*}
K_1 = [0,1]\ \to\  K_2=\left[0,\frac{3}{8}\right]\cup\left[\frac{5}{8},1\right]\ \to\  K_3=\left[0,\frac{5}{32}\right]\cup\left[\frac{7}{32},\frac{3}{8}\right]\cup\left[\frac{5}{8},\frac{25}{32}\right]\cup\left[\frac{27}{32},1\right]\ \to\ \cdots.
\end{align*}
Similar to (iii), the Smith-Volterra-Cantor set $K=\bigcup_{n=1}^\infty K_n$ is a nowhere dense set in $\mathbb{R}$. \vspace{0.1cm}

Note that at the $n$-th step, we remove subintervals of length $4^{-n}\times 2^{n-1} = 2^{-n-1}$ in total. Then the Lebesgue measure of $K_n$ is
\begin{align*}
	m(K_n) = 1 - \sum_{k=1}^{n-1}\frac{1}{2^{k+1}} = \frac{1}{2} + \frac{1}{2^n}.
\end{align*}
Hence $m(K)=1/2>0$. It is seen that $K$ is a rare set with positive Lebesgue measure.
\end{itemize}

\paragraph{Definition 3.4\label{def:3.4}} (Baire spaces). A topological space $X$ is said to be a \textit{Baire space} if the following condition holds: given any countable collection $\{C_n,n\in\mathbb{N}\}$ of closed nowhere dense subsets of $X$, their union $\bigcup_{n=1}^\infty C_n$ is also nowhere dense in $X$.

\paragraph{Remark.} Let $\{A_n,n\in\mathbb{N}\}$ be a collection of nowhere dense subsets of a Baire space $X$. Then the union $\bigcup_{n=1}^\infty A_n$, being a subset of $\bigcup_{n=1}^\infty\overline{A_n}$, is also nowhere dense in $X$. Therefore we can drop the requirement of ``closed sets'' in \hyperref[def:3.4]{Definition 3.4}. Applying \hyperref[lemma:3,2]{Lemma 3.2}, we obtain an equivalent definition of Baire spaces:\vspace{0.1cm}

A topological space $X$ is a Baire space if and only if the following condition holds: given any countable collection $\{U_n,n\in\mathbb{N}\}$ of open dense subsets of $X$, their intersection $\bigcap_{n=1}^\infty U_n$ is also dense in $X$.

\paragraph{Definition 3.5\label{def:3.5}} (René-Louis Baire categories). Let $A$ be a subset of a topological space $X$. Then $A$ is said to be of the \textit{first category} if it is contained in the union of a countable collection of nowhere dense sets in $X$; otherwise, it is said to be of the \textit{second category}.
\paragraph{Lemma 3.6.\label{lemma:3.6}} A space $X$ is a Baire space if and only if every open subset of $X$ is of the second category.
\begin{proof}
If $X$ is a Baire space, then the union of every countable collection of nowhere dense subsets of $X$ is nowhere dense, which is impossible to contain $X$. Hence $X$ is of the second category.

If $X$ is not a Baire space, let $\{C_n,n\in\mathbb{N}\}$ be a collection of nowhere dense sets in $X$ such that the union $\bigcup_{n=1}^\infty C_n$ contains some open set $U$ in $X$. Then $U$ is of the first category.
\end{proof}
\paragraph{Remark.} A space of second category is not necessarily a Baire space. Consider $Y=X\,\cup\,\mathbb{Q}$, where $X=[0,1]$. Since $X$ is of the second category, so is $Y$. However, $\bigcap_{q\in\mathbb{Q}} Y\backslash\{q\}$ is a countable intersection of open dense sets that is not dense.

\paragraph{Theorem 3.7\label{thm:3.7}} (Baire category theorem). A complete metric space $X$ is a Baire space.
\begin{proof}
Let $\{C_n,n\in\mathbb{N}\}$ be a collection of closed nowhere dense sets in $X$. Given an open set $U$ in $X$, we prove that there exists $x\in U$ such that $x\notin\bigcup_{n=1}^\infty C_n$. This implies $\bigcup_{n=1}^\infty C_n$ is nowhere dense.

We first consider $A_1$. By hypothesis, $A_1$ does not contain $U$. Then we choose $x_1\in U\backslash A_1$. Since $A_1$ is closed, we choose $0<\epsilon_1<1$ such that $U_1=O(x_1,\epsilon_1)$ satisfies
\begin{align*}
\overline{U_1}\subset U\ \text{and}\ \overline{U_1}\cap A_1=\emptyset.
\end{align*}

Now consider $n\geq 2$. With the open set $U_{n-1}$ given, we choose $x_n\in U_{n-1}\backslash A_n$, and choose $0<\epsilon_n < 1/n$ such that $U_n=O(x_n,\epsilon_n)$ satisfies
\begin{align*}
	\overline{U_n}\subset U_{n-1}\ \text{and}\ \overline{U_n}\cap A_n=\emptyset.
\end{align*}
Since $X$ is complete, by \hyperref[thm:1.59]{Theorem 1.59}, the nested sequence $\overline{U_1}\supset\overline{U_2}\supset\cdots$ admits a unique $x\in\bigcup_{n=1}^\infty \overline{U_n}$. Then $X\notin A_n$ for all $n\in\mathbb{N}$, as desired.
\end{proof}
\paragraph{Remark.} Let $\{U_n,n\in\mathbb{N}\}$ be a collection of open dense subsets of a complete metric space $X$. According to \hyperref[thm:3.7]{Theorem 3.7}, their intersection $\bigcap_{n=1}^\infty U_n$ is dense in $X$. Furthermore, we can prove that $\bigcap_{n=1}^\infty U_n$ is of the second category. Otherwise, there exists a collection $\{E_k,k\in\mathbb{N}\}$ of closed nowhere dense sets in $X$ such that $\bigcap_{n=1}^\infty U_n\subset\bigcup_{k=1}^\infty E_k$, which implies $\bigl(\bigcap_{n=1}^\infty U_n\bigr)\cap\bigl(\bigcap_{k=1}^\infty X\backslash E_k\bigr)=\emptyset$. However, this is a dense subset of $X$ by the conclusion we proved.

\paragraph{Example 3.8.\label{example:3.8}} Following are some instances for spaces of the first category and of the second category.
\begin{itemize}
\vspace{0.1cm}
\item[(i)] The set of integers $\mathbb{Z}$ is a Baire space itself: Only $\emptyset$ is nowhere dense in $X$, because every subset of $\mathbb{N}$ is open. Nevertheless, $\mathbb{Z}$ is of the first category in $\mathbb{R}$.
\vspace{0.1cm}
\item[(ii)] The set of rationals $\mathbb{Q}$ is not a Baire space. It is of the first category in $\mathbb{R}$.
\vspace{0.1cm}
\item[(iii)] The set of irrationals $\mathbb{R}\backslash\mathbb{Q}$ is of the second category. Otherwise, there exist countably many nowhere dense sets $\{A_n\}$ such that $\mathbb{R}\backslash\mathbb{Q}=\bigcup_{n=1}^\infty A_n$. Then $\mathbb{R}=\bigl(\bigcup_{n=1}^\infty A_n\bigr)\cup\bigl(\bigcup_{q\in\mathbb{Q}}\{q\}\bigr)$ is of the first category, a contradiction to Baire category theorem!
\vspace{0.1cm}
\item[(iv)] The unit closed interval $[0,1]$ is of the second category by Baire category theorem. Then it is uncountable. Otherwise, it is of the first category.
\vspace{0.1cm}
\item[(v)] Choose a collection of open subsets
\begin{align*}
	E_k = \bigcup_{r_n\in\mathbb{Q}}\left(r_n-\frac{1}{k2^n},r_n+\frac{1}{k2^n}\right),\ k\in\mathbb{N}.
\end{align*}
By Baire category theorem, $\bigcap_{k=1}^\infty E_k$ is a dense set in $X$ of the second category. Since $\mathbb{Q}$ is of the first category, we have $Q\subsetneq \bigcap_{k=1}^\infty E_k$. Then
\begin{align*}
	0\leq m(\mathbb{Q}) \leq m\left(\bigcup_{n=1}^\infty E_k\right) = \lim_{k\to\infty} m(E_k) = 0.
\end{align*}
It is seen that $\bigcap_{n=1}^\infty E_k$ is a set of the second category with Lebesgue measure zero.
\vspace{0.1cm}
\item[(vi)] According to \hyperref[example:3.3]{Example 3.3}, the Smith-Volterra-Cantor $K$ is a set of the first category with $m(K)>0$.
\end{itemize}

\paragraph{Review: Weierstrass function.} Karl Weierstrass has given a construction of continuous but nowhere differentiable functions. Let $a\in (0,1)$, and let $b$ be an odd integer such that $ab>1+\frac{3\pi}{2}$. We define function
\begin{align*}
	f(x) = \sum_{n=0}^\infty a^n\cos\left(b^n\pi x\right),\ x\in\mathbb{R}.
\end{align*}
By Weierstrass M-test, the partial sum given by $f$ converges uniformly, hence $f$ is continuous. Interestingly, $f$ is nowhere differentiable on $\mathbb{R}$. Fix $x_0\in\mathbb{R}$. By definition, we need to argue that the limit
\begin{align*}
	\lim_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}
\end{align*}
does not exist. In particular, we show that the difference quotient oscillates drastically as $x$ approaches $x_0$.

We first construct two sequences $(y_m)$ and $(z_m)$ that approach $x_0$ from below and above, respectively. For each $m\in\mathbb{N}$, we choose an integer $\alpha_m$ close to $b^m x_0$. To be specific, let $\alpha_m$ be such that
\begin{align*}
	x_m:= b^m x_0 - \alpha_m \in \left(-\frac{1}{2},\frac{1}{2}\right],\ \alpha_m\in\mathbb{Z}.
\end{align*}
And choose $y_m$ and $z_m$ as follows:
\begin{align*}
	y_m = x_0 -\frac{1+x_m}{b^m} = \frac{\alpha_m-1}{b^m},\quad z_m = x_0 + \frac{1-x_m}{b^m} = \frac{\alpha_m+1}{b^m}.
\end{align*}
The difference quotient at $y_m$ is
\begin{align*}
	\frac{f(y_m) - f(x_0)}{y_m-x_0} &= \frac{\sum_{n=0}^\infty a^n\left[\cos(b^n\pi y_m) - \cos\left(b^n\pi x_0\right)\right]}{y_m-x_0}\\
	&= \sum_{n=0}^{m-1}a^n\frac{\cos(b^n\pi y_m) - \cos\left(b^n\pi x_0\right)}{y_m-x_0} + \sum_{n=0}^{\infty}a^{n+m}\frac{\cos(b^{n+m}\pi y_{m}) - \cos\left(b^{n+m}\pi x_0\right)}{y_{m}-x_0}\\
	&= \underbrace{-\sum_{n=0}^{m-1}\pi(ab)^n\frac{\sin\left(\frac{b^n\pi (y_m+x_0)}{2}\right)\sin\left(\frac{b^n\pi (y_m-x_0)}{2}\right)}{\frac{b^n\pi (y_m-x_0)}{2}}}_{=:S_1} - \underbrace{\sum_{n=0}^{\infty}a^{n+m}\frac{(-1)^{\alpha_m}\left(1 + \cos\left(b^{n}\pi x_m\right)\right)}{\frac{1+x_m}{b^m}}}_{=:S_2},
\end{align*}
We can easily bound $S_1$:
\begin{align*}
	\vert S_1\vert = \sum_{n=0}^{m-1}\pi(ab)^n\left\vert \sin\left(\frac{b^n\pi (y_m+x_0)}{2}\right)\right\vert\left\vert\frac{\sin\left(\frac{b^n\pi (y_m-x_0)}{2}\right)}{\frac{b^n\pi (y_m-x_0)}{2}}\right\vert \leq\sum_{n=0}^{m-1}\pi(ab)^n= \pi\frac{(ab)^m-1}{ab-1}.
\end{align*}
Hence there exists $\vert\xi\vert<1$ such that $S_1=\xi\pi\frac{(ab)^m}{ab-1}$. For $S_2$, drop all terms $n\geq 1$:
\begin{align*}
	\sum_{n=0}^{\infty}a^n\frac{\left(1 + \cos\left(b^{n}\pi x_m\right)\right)}{1+x_m}\geq\frac{\left(1 + \cos\left(\pi x_m\right)\right)}{1+x_m}\geq \frac{2}{3},
\end{align*}
where the inequality follows from $-1/2\leq x_m < 1/2$. Then there exists $\eta\geq\frac{2}{3}$ such that $S_2=(-1)^{\alpha_m}(ab)^m\eta$. As a result,
\begin{align*}
	\left\vert\frac{f(y_m) - f(x_0)}{y_m-x_0}\right\vert = \vert S_1 - S_2\vert
	= \left\vert(-1)^{\alpha_m}(ab)^m\eta\left(1-(-1)^{\alpha_m}\frac{\xi\pi}{\eta(ab-1)}\right)\right\vert \geq \frac{2}{3}(ab)^m\left(1-\frac{3\pi}{2(ab-1)}\right)\to\infty.
\end{align*}
A similar statement also holds for $(z_m)$. Therefore, $f$ is not differentiable at $x_0$. Since $x_0$ is arbitrary, $f$ is nowhere differentiable on $\mathbb{R}$.

\paragraph{Example 3.9\label{example:3.9}} (The set of continuous and nowhere differentiable functions). The construction of continuous but nowhere differentiable functions given by Weierstrass is non-trivial. Interestingly, we can argue that these ``strange'' functions are very rich in the space of continuous functions.

Consider the space $C([0,1])$ of continuous functions on $[0,1]$. The set of all continuous and nowhere differentiable functions on $[0,1]$ is of the second category in $C([0,1])$. In a nutshell, there exists a large amount of continuous and nowhere differentiable functions. To see this, we define a collection of subsets
\begin{align*}
	F_N=\left\{f\in C([0,1]):\ \forall x\in [0,1],\ \exists y\in[0,1]\ \text{such that}\ \left\vert\frac{f(x)-f(y)}{x-y}\right\vert>N\right\},\ N\in\mathbb{N}.
\end{align*}

\paragraph{Claim 1.} We first claim that $F_N$ is open. Let $(f_n)$ be a sequence of functions in
\begin{align*}
	F_N^c = \left\{f\in C([0,1]):\exists x\in[0,1]\ \text{such that}\ \forall y\in[0,1],\ \left\vert\frac{f(x)-f(y)}{x-y}\right\vert\leq N\right\}
\end{align*}
such that $f_n$ converges uniformly to $f\in C([0,1])$. We choose $x_n\in[0,1]$ to be such that $$\left\vert\frac{f_n(y)-f_n(x_n)}{y-x_n}\right\vert\leq N$$
for all $y\in [0,1]$. There exists convergent subsequence $x_{n_k}\to x\in[0,1]$. Then for all $y\in[0,1]$,
\begin{align*}
	\vert f(x)-f(y)\vert &\leq \vert f(x)-f_{n_k}(x)\vert + \vert f_{n_k}(x)-f_{n_k}(x_{n_k})\vert + \vert f_{n_k}(x_{n_k})-f_{n_k}(y)\vert + \vert f_{n_k}(y)-f(y)\vert\\
	&\leq \Vert f-f_{n_k}\Vert_\infty + N\vert x-x_{n_k}\vert + N\vert x_{n_k}-y\vert + \Vert f-f_{n_k}\Vert_\infty\\
	&\leq 2\Vert f-f_{n_k}\Vert_\infty + 2N\vert x-x_{n_k}\vert + N\vert x-y\vert.
\end{align*}
Let $k\to\infty$, then we have $f\in F_N^c$. Hence $F_N^c$ is closed, and $F_N$ is open.

\paragraph{Claim 2.} We then claim that $F_N$ is dense in $C([0,1])$. 

\begin{proof}
Given $f\in C([0,1])$ and $\epsilon>0$, we wish to find $g\in F_N$ such that $\Vert f-g\Vert_\infty < \epsilon$. By uniform continuity of $f$, we choose $\delta>0$ such that $\vert f(x)-f(y)\vert < \epsilon/5$ for all $\vert x-y\vert <\delta$. 

Let $n>1/\delta$, and divide $[0,1]$ into $n$ subintervals $\left[\frac{k-1}{n},\frac{k}{n}\right]$, within each the amplitude of $f$ is less than $\epsilon/5$. Then let $M>\frac{5N}{n\epsilon}$, and partition $\left[\frac{k-1}{n},\frac{k}{n}\right]$ into $M$ subintervals again:
\begin{align*}
	\frac{k-1}{n} = x_{(k-1)M} < \frac{(k-1)M+1}{nM} =  x_{(k-1)M+1} < \cdots < \frac{kM - 1}{nM} =  x_{kM-1} < \frac{k}{n} = x_{kM}.
\end{align*}
For $p=0,1,\cdots,nM$, we define $g(x_p) = f(x_p) + (-1)^p\,\epsilon/5$ at $x_p\in[0,1]$, and connect points $(x_{p-1},g(x_{p-1}))$ and $(x_p,g(x_p))$ by line segment. Then we obtain a piecewise-linear function $g\in C([0,1])$.

We show that $g\in F_N$. For each $x\in [0,1]$, choose $x\in[x_{kM+j - 1},x_{kM+j}]$. Then
\begin{align*}
	\left\vert\frac{g(x_{kM+j}) - g(x)}{x_{kM+j} - x}\right\vert &= \frac{\left\vert f(x_{kM+j}) + (-1)^{kM+j}\epsilon/5 - f(x_{kM+j-1}) - (-1)^{kM+j-1}\epsilon/5\right\vert}{(nM)^{-1}}\\
	&\geq \frac{2\epsilon/5 - \left\vert f(x_{kM+j}) - f(x_{kM+j-1})\right\vert}{(nM)^{-1}} > N.
\end{align*}
Then $g\in F_N$. Furthermore, 
\begin{align*}
	\vert f(x)-g(x)\vert &\leq \vert f(x)-f(x_{kM+j})\vert + \vert f(x_{kM+j})-g(x_{kM+j})\vert + \underbrace{\vert g(x_{kM+j})-g(x)\vert}_{\leq \vert g(x_{kM+j})-g(x_{kM+j-1})\vert}\\
	&\leq \vert f(x)-f(x_{kM+j})\vert + \vert f(x_{kM+j})-g(x_{kM+j})\vert + \vert f(x_{kM+j})-f(x_{kM+j-1})\vert + \frac{2\epsilon}{5} < \epsilon.
\end{align*}
Hence $\Vert f-g\Vert_\infty <\epsilon$. As a result, $F_N$ is dense in $C([0,1])$.
\end{proof}

\paragraph{Claim 3.} Finally, we claim that the set of all continuous and nowhere differentiable functions in $C([0,1])$ is of the second category.\vspace{0.1cm}

If $f\in C([0,1])$ is differentiable at some $x\in[0,1]$, then we choose $\delta>0$ such that $$\left\vert\frac{f(x)-f(y)}{x-y}\right\vert\leq 1+\left\vert f^\prime(x)\right\vert$$ 
for all $\vert x-y\vert <\delta$. For $\vert x - y\vert \geq\delta$, we have $$\left\vert\frac{f(x)-f(y)}{x-y}\right\vert\leq \frac{2\Vert f\Vert_\infty}{\delta}.$$ 
Therefore, if we choose $$N>\max\left\{1+\left\vert f^\prime(x)\right\vert,\frac{2\Vert f\Vert_\infty}{\delta}\right\},$$ then we have $f\notin F_N.$ Hence every function in $\bigcap_{n=1}^\infty F_N$ is continuous and nowhere differentiable. Moreover, $\bigcap_{n=1}^\infty F_N$ is of the second category by Baire category theorem.

\newpage
\subsection{Banach Bounded Inverse, Open Mapping \& Closed Graph Theorems}
\paragraph{Definition 3.10\label{def:3.10}} (Invertible bounded linear operators). Let $X$ and $Y$ be normed spaces. Let $T\in\mathfrak{B}(X,Y)$. Then $T$ is said to be \textit{invertible} if $T:X\to Y$ is bijective and $T^{-1}\in\mathfrak{B}(Y,X)$.
\paragraph{Remark.} By definition,the operator $T\in\mathfrak{B}(X,Y)$ is invertible if and only if there exists $S\in\mathfrak{B}(Y.X)$ such that $S\circ T=I_X$ and $T\circ S=I_Y$, where $I_X$ and $T_Y$ are identity operators in $X$ and $Y$. In this case, $T^{-1}:= S$ is said to be the \textit{inverse} of $T$.
\paragraph{Example 3.11.\label{example:3.11}} Let $X$ be a finite-dimensional normed space, and let $T\in\mathfrak{B}(X)$. Then $T$ is injective if and only if it is surjective. In this case, $T^{-1}\in\mathfrak{B}(X)$.\vspace{0.1cm}

However, for infinite-dimensional spaces, the case becomes complicated. Let $X=l^2(\mathbb{N})$ be the space of square-summable sequences. Define the left-shift and right-shift operators on $X$ as follows:
\begin{align*}
	S:(x_1,x_2,\cdots)\to (x_2,x_3,\cdots),\quad 
	T:(x_1,x_2,\cdots)\to (0,x_1,x_2,\cdots).
\end{align*}
Then $S\cdot T=I_X$, but $T\circ S\neq I_X$. Hence $T$ is injective but not surjective, and $S$ is surjective but not injective.\vspace{0.1cm}

In \hyperref[def:3.10]{Definition 3.10}, the boundedness of $T^{-1}$ is required. Here is an example of bounded linear operators that are bijective but not invertible. Let $X=C([a,b])$, and let $Y=\left\{f\in C([a,b]):f(a)=0\ \text{and}\ f^\prime\in C([a,b])\right\}$ be a subspace of $X$. Define $T:X\to Y$ as
\begin{align*}
	(Tf)(x) = \int_a^x f(t)\,dt,\ x\in [a,b].
\end{align*}
By definition, $\Vert T\Vert\leq b-a$. Then $T\in\mathfrak{B}(X,Y)$, and $T:X\to Y$ is bijective. However, the inverse of $T$ is the differential operator: $(T^{-1}\varphi)(x)=\frac{d}{dx}\varphi(x)$, which is not bounded.
\vspace{0.1cm}

The reason that $T:X\to Y$ is not invertible is that $Y$ is not complete. In general, we have the following important theorem about invertible operators.

\paragraph{Theorem 3.12\label{thm:3.12}} (Banach bounded inverse theorem). Let $X$ and $Y$ be Banach spaces. If $T\in\mathfrak{B}(X,Y)$ is a bijection from $X$ onto $Y$, then $T$ is invertible, that is, $T^{-1}\in\mathfrak{B}(Y,X)$.

\paragraph{} The proof of \hyperref[thm:3.12]{Theorem 3.12} uses the open mapping theorem.

\paragraph{Theorem 3.13\label{thm:3.13}} (Open mapping theorem). Let $X$ and $Y$ be Banach spaces, and let $T\in\mathfrak{B}(X,Y)$. If $T:X\to Y$ is surjective, then $T$ is an \textit{open mapping}, i.e. for all open $U\subset X$, its image $TU$ is open in $Y$.

\renewcommand{\proofname}{Proof of \hyperref[thm:3.12]{Theorem 3.12}}
\begin{proof}
By definition, if $T:X\to Y$ is an open mapping, then $T^{-1}:Y\to X$ is continuous.
\end{proof}
Before proving \hyperref[thm:3.13]{Theorem 3.13}, we introduce some notations. Let $A$ be a subset of a vector space $X$. Let $x\in X$, and let $\alpha$ be a number. Then
$x+A=\left\{x+y:y\in A\right\},\ \alpha A=\left\{\alpha x:x\in A\right\}.$

\renewcommand{\proofname}{Proof of \hyperref[thm:3.13]{Theorem 3.13}}
\begin{proof}
Given an open set $G\subset X$, we prove that $TG$ is open in $Y$. That is, for any point $x$ of $G$, $Tx$ is an interior point of $TG$. We use $O_X$ and $B_X$ to denote open and closed balls in $X$.\vspace{0.1cm}

\textit{Step I:} We prove that there exists $\delta>0$ such that $TB_X(0,1)$ is dense in $O_Y(0,\delta)$.

Since $X=\bigcup_{n=1}^\infty B_X(0,n)$, we have $Y=TX=\bigcup_{n=1}^\infty TB_X(0,n)$. By completeness of $Y$, it is of the second category. Hence there exists $TB_X(0,N)$ that is not nowhere dense. As a result, there exists $y_0\in Y$ and $\eta>0$ such that $TB_X(0,N)$ is dense in $O_Y(y_0,\eta)$.

Let $Tx_0=y_0$. If $M=N+\Vert x_0\Vert$, then $TB_X(0,M)\supset TB_X(0,N) - Tx_0$ is dense in $O_Y(0,\eta)$.

\textit{Step II:} We prove that $TB_X(0,1)\supset O_Y\left(0,\frac{\delta}{2}\right)$. 

Choose $y_0\in O_Y(0,\delta)$. By Step II, choose $x_1\in B_X(0,1)$ such that $\Vert y_0-Tx_1\Vert < \delta/2$, which implies $y_1=y_0-Tx_1\in O_Y(0,\delta/2)$. By induction, with $y_{n-1}\in O_Y\left(0,2^{1-n}\delta\right)$ given, choose $x_n\in B_X(0,2^{1-n})$ such that $y_n=y_{n-1}-Tx_n\in O_Y(0,2^{-n}\delta)$. Therefore
\begin{align*}
	\left\Vert y_0 - T(x_1+\cdots+x_n)\right\Vert<\frac{\delta}{2^n}.
\end{align*}
Since $x_n\in B_X(0,2^{1-n})$, by completeness of $X$, let $x_0=\sum_{n=1}^\infty x_n \in X$. Then $\Vert x_0\Vert\leq\sum_{n=1}^\infty\Vert x_n\Vert\leq 2$. By continuity of $T$, we have $Tx_0 = y_0$. Then	$TB_X(0,2)\supset O_Y(0,\delta)$. The result follows from linearity of $T$.\vspace{0.1cm}

\textit{Step III:} Since $G$ is open, for all $x\in G$, there exists $O_X(0,b_x)\subset G$. If $\alpha<b_x$, $B_X(x,\alpha)\subset G$. Then 
\begin{align*}
	TB_X(x,\alpha)=Tx + \alpha TB_X(0,1)\subset TG.
\end{align*}
By Step II, we have $O_Y(Tx,\frac{\alpha\delta}{2})\subset TG$.
\end{proof}
\renewcommand{\proofname}{Proof}

\paragraph{Remark.} Analogously, an operator $T:X\to Y$ is said to be a \textit{closed mapping}, if for all closed subset $G\subset X$, its image $TG$ is closed in $Y$.

A surjection $T\in\mathfrak{B}(X,Y)$ is an open mapping, but it need not to be a closed mapping. For instance, consider the projection map $\pi_1:\mathbb{R}^2\to\mathbb{R},\ (x,y)\mapsto x$. The set $G=\left\{(x,y):xy=1\right\}$ is a closed set in $\mathbb{R}^2$, but its image $TG=\mathbb{R}\backslash\{0\}$ is not closed in $\mathbb{R}$.

\paragraph{} Following are applications of bounded inverse theorem and open mapping theorem.
\paragraph{Theorem 3.14\label{thm:3.14}} (Equivalence of norms). Let $\Vert\cdot\Vert_a$ and $\Vert\cdot\Vert_b$ be two norms on a vector space $X$. If both $(X,\Vert\cdot\Vert_a)$ and $(X,\Vert\cdot\Vert_b)$ are complete, and there exists $c>0$ such that $\Vert x\Vert_b\leq c\Vert x\Vert_a$ for all $x\in X$, then $\Vert\cdot\Vert_a$ and $\Vert\cdot\Vert_b$ are equivalent.
\begin{proof}
We show that there exists $c^\prime>0$ such that $\Vert x\Vert_a\leq c^\prime\Vert x\Vert_b$. Consider the identity map
\begin{align*}
	Id_X:(X,\Vert\cdot\Vert_a)\to(X,\Vert\cdot\Vert_b).
\end{align*}
Then $\Vert Id_X\Vert \leq c$. By \hyperref[thm:3.12]{Theorem 3.12}, $Id_X^{-1}$ is also bounded, and the result follows.
\end{proof}

\paragraph{Theorem 3.15.\label{thm:3.15}} Let $X$ and $Y$ be Banach spaces, and $T\in\mathfrak{B}(X,Y)$ is injective. Then $\mathfrak{R}(T)$ is closed if and only if $T$ is bounded from below, that is, there exists $c>0$ such that $\Vert Tx\Vert\geq c\Vert x\Vert$ for all $x\in X$.
\begin{proof}
If $\mathfrak{R}(T)\subset Y$ is closed, then $\mathfrak{R}(T)$ is complete. By \hyperref[thm:3.12]{Theorem 3.12}, $T:X\to\mathfrak{R}(T)$ has bounded inverse. 

Conversely, let $y_n$ be a sequence in $\mathfrak{R}(T)$ that converges to $y$. It suffices to show $y\in\mathfrak{R}(T)$. By injectivity of $T$, choose $x_n=T^{-1}y_n$. Then $\Vert x_n - x_m\Vert\leq\frac{1}{c}\Vert y_n - y_m\Vert$, and $(x_n)$ is a Cauchy sequence, which converges to some $x\in X$. By continuity of $T$, we have $Tx=\lim_{n\to\infty} Tx_n = y$.
\end{proof}

\paragraph{Example 3.16.} Given $\varphi\in L^\infty([0,1])$, define linear operator $M_\varphi$ on $L^1([0,1])$ by
\begin{align*}
	(M_\varphi f)(t) = \varphi(t) f(t),\ f\in L^1([0,1]),\ t\in[0,1]. 
\end{align*}
Then $\Vert M_\varphi\Vert = \Vert\varphi\Vert_\infty$, and $M_\varphi$ is invertible if and only if there exists $c>0$ such that $\vert\varphi\vert \geq c$ a.e. on $[0,1]$.
\begin{proof}
If $M_\varphi$ is invertible, then $\Vert f\Vert_1\leq\Vert M_\varphi^{-1}\Vert\left\Vert M_\varphi f\right\Vert_1$ for all $f\in L^1([0,1])$. If $m(\vert\varphi\vert < \Vert M_\varphi^{-1}\Vert^{-1}) > 0$, we derive a contradiction by setting $f=\chi_{\{\vert\varphi\vert < \Vert M_\varphi^{-1}\Vert^{-1}\}}$. Hence $\vert\varphi\vert\geq c:=\Vert M_\varphi^{-1}\Vert^{-1}$ a.e. on $[0,1]$.

Conversely, if there exists $c>0$ such that $\vert\varphi\vert \geq c$ a.e. on $[0,1]$, we can recover $M_\varphi^{-1}$ by
\begin{align*}
	(M_\varphi^{-1}f) = \begin{cases}
		\frac{f(t)}{\varphi(t)},\ &\varphi(t)\neq 0,\\
		0,\ &\varphi(t)=0.
	\end{cases}
\end{align*}
Clearly, $\Vert M^{-1}_\varphi f\Vert_1\leq \frac{1}{c}\Vert f\Vert_1$ for all $f\in L^1([0,1])$, which implies $M_\varphi^{-1}\in\mathfrak{B}(L^1([0,1]))$, and $\Vert M_\varphi^{-1}\Vert\leq\frac{1}{c}$.\vspace{0.1cm}

An alternative proof is based on \hyperref[thm:3.12]{Theorem 3.12}, where we prove that $T$ is a bijection on $L^1([0,1])$.
\end{proof}

Now we introduce the definition of graphs.
\paragraph{Definition 3.17\label{def:3.17}} (Graphs). Let $T:\mathfrak{D}(T)\to Y$ be a map. The set
\begin{align*}
	\Gr(T)=\left\{(x,Tx):x\in \mathfrak{D}(T)\right\},
\end{align*}
which is a subset of $\mathfrak{D}(T)\times Y$, is called the \textit{graph} of $T$.
\paragraph{Remark.} Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces. We can define a product metric $d$ on $X\times Y$ as
\begin{align*}
	d((x,y),(x^\prime,y^\prime)) = \sqrt{d_X(x,x^\prime)^2 + d_Y(y,y^\prime)^2}.
\end{align*}
In fact, the topology that $d$ induces is the product topology on $X\times Y$. That is, every basis element of this topology is of the form $U\times V$, where $U$ and $V$ are open subsets of $X$ and $Y$, respectively.

Let $T:\mathfrak{D}(T)\to Y$ be a map, where $\mathfrak{D}(T)\subset X$. If $\Gr(T)$ is closed in $X\times Y$ (given the product topology), then $T$ is said to have a closed graph.

\paragraph{Lemma 3.18.\label{lemma:3.18}} Let $X$ and $Y$ be two topological spaces, and let $Y$ be Hausdorff. Let $T:\mathfrak{D}(T)\to Y$ be a continuous operator, and $\mathfrak{D}(T)\subset X$. If $\mathfrak{D}(T)$ is closed, then $T$ has closed graph.
\begin{proof}
Let $(x_0,y_0)$ be a limit point of $\Gr(T)=\left\{(x,Tx):x\in\mathfrak{D}(T)\right\}$. Then every neighborhood of $(x_0,y_0)$ has at least one point of $\Gr(T)$, and $x_0$ is a limit point of $\mathfrak{D}(T)$. Since $\mathfrak{D}(T)$ is closed, $x_0\in\mathfrak{D}(T)$.

If $y_0\neq Tx_0$, there exists disjoint open subsets $U$ and $V$ of $Y$ that contains $y_0$ and $Tx_0$, respectively. By continuity of $T$, the set $T^{-1}V\times U$ is an open neighborhood of $(x_0,y_0)$ in $X\times Y$. However, it does not contain any point of $\Gr(T)$, contradicting the fact that $(x_0,y_0)$ is a limit point of $\Gr(T)$. Hence $y_0=Tx_0$.
\end{proof}

\paragraph{Example 3.19.} (Differential operator). We define $T:C^1([a,b])\to C([a,b])$ to be the differential operator:
\begin{align*}
	(Tf)(t) = f^\prime(t),\ f\in C^1([a,b]),\ t\in[a,b].
\end{align*}
Give $C^1([a,b])$ the supremum norm on $C([a,b])$. Clearly, $T$ is unbounded: if $f_n(T)=\sin(nt)\in C([0,2\pi])$, so that $\Vert f_n\Vert=1$, then
\begin{align*}
	\Vert Tf_n\Vert = \sup_{t\in[0,2\pi]} n\cos nt = n\to\infty.
\end{align*}
Interestingly, $T$ has a closed graph. To see this, let $(f_n)$ be a sequence in $C^1([a,b])$ such that $f_n\rightrightarrows f$ and $f_n^\prime\rightrightarrows g$. The uniform convergence of derivatives implies $f\in C^1([a,b])$ and $f^\prime = g$.

\paragraph{Theorem 3.20\label{thm:3.20}} (Closed graph theorem). Let $X$ and $Y$ be Banach spaces. Let $T$ be a linear operator from $\mathfrak{D}(T)$ into $Y$, where $\mathfrak{D}(T)$ is a closed subspace of $X$. Then $T$ is continuous if and only if it has a closed graph.
\begin{proof}
Following \hyperref[lemma:3.18]{Lemma 3.18}, it remains to show the continuity of linear operator $T$ with a closed graph. 

Define norm $\Vert(x,y)\Vert=\sqrt{\Vert x\Vert^2 + \Vert y\Vert^2}$ on $X\times Y$. Since $X$ and $Y$ are Banach spaces, $X\times Y$ becomes a Banach space under norm $\Vert\cdot\Vert$. Clearly, the closed subspaces $\mathfrak{D}(T)$ and $\Gr(T)$ are also Banach spaces.

Define $\pi:\Gr(T)\to\mathfrak{D}(T),\ (x,Tx)\mapsto x$. Then $\Vert\pi\Vert\leq 1$, and $\pi$ is bounded. By \hyperref[thm:3.12]{Theorem 3.12}, the inverse $\pi^{-1}:x\mapsto (x,Tx)$ is also bounded, and
\begin{align*}
	\Vert Tx\Vert\leq \Vert(x,Tx)\Vert = \Vert\pi^{-1}(x)\Vert \leq \Vert\pi^{-1}\Vert\left\Vert x\right\Vert,\ \forall x\in\mathfrak{D}(T).
\end{align*}
Hence $T\in\mathfrak{B}(\mathfrak{D}(T),Y)$ is continuous.
\end{proof}

Following are applications of closed graph theorem.
\paragraph{Example 3.21.\label{example:3.21}} Let $f$ be a measurable function on $[0,1]$. If $fg\in L^1([0,1])$ for all $g\in L^2([0,1])$, then $f\in L^2([0,1])$.
\begin{proof}
Define $T:L^2([0,1])\to L^1([0,1]),\ g\mapsto fg$. We show that $T$ has closed graph. 

Let $g_n$ be a sequence in $L^2([0,1])$ such that $\Vert g_n - g\Vert_2\to 0$ and $\Vert fg_n - h\Vert_1\to 0$. By Chebyshev inequality, for all $\sigma>0$, 
\begin{align*}
	m(\vert g_n - g\vert \geq \sigma) \leq \frac{1}{\sigma^2}\Vert g_n - g\Vert_2^2,\quad	m(\vert fg_n - h\vert \geq \sigma)\leq \frac{1}{\sigma}\Vert fg-h \Vert_1.
\end{align*}
Hence $g_n\to g$, and $fg_n\to h$ in Lebesgue measure, and there exists subsequence $(g_{n_k})$ such that $g_{n_k}\to g$ a.e., and $fg_{n_k}\to h$ a.e.. Then $fg=h$, and $T$ has closed graph.

By \hyperref[thm:3.20]{Theorem 3.20}, $T$ is continuous. Choose $f\chi_{\{\vert f\vert< n\}}\in L^2([0,1])$, then
\begin{align*}
	\Vert f\chi_{\{\vert f\vert < n\}}\Vert_2 = \frac{\Vert f^2\chi_{\{\vert f\vert < n\}}\Vert_1}{\Vert f\chi_{\{\vert f\vert < n\}}\Vert_2} \leq \Vert T\Vert.
\end{align*}
Let $n\to\infty$, we have $\Vert f\Vert_2\leq\Vert T\Vert$. Hence $f\in L^2([0,1])$.
\end{proof}

\paragraph{Example 3.22.\label{example:3.22}} Let $X$ and $Y$ be Banach spaces. Let $T$ be an linear operator from $X$ into $Y$. If $f\circ T\in X^*$ for all $f\in Y^*$, then $T\in\mathfrak{B}(X,Y)$.
\begin{proof}
Following \hyperref[thm:3.20]{Theorem 3.20}, we show that $T$ has a closed graph. Let $(x_n)$ be a sequence of points of $X$ such that $x_n\to x\in X$, and $Tx_n\to y\in Y$. We need to show that $y=Tx$.

By continuity of $f\in Y^*$, we have $f(Tx_n)\to f(y)$. By continuity of $f\circ T$, $f(Tx_n)\to f(Tx)$. Then for $f\in Y^*$, $f(y)=f(Tx)$. If $y\neq Tx$, by Hahn-Banach theorem, there exists $f_0\in Y^*$ such that $f(y)\neq f(Tx)$, a contradiction! Hence $y=Tx$.
\end{proof}

\newpage
\subsection{Banach-Steinhaus Theorem}
\paragraph{Theorem 3.23\label{thm:3.23}} (Banach-Steinhaus theorem/uniform boundedness principle). Let $X$ be a Banach space, and  $Y$ a normed space. Let $\left\{T_\lambda\right\}_{\lambda\in\Lambda}\subset\mathfrak{B}(X,Y)$. If $\sup_{\lambda\in\Lambda}\Vert T_\lambda x\Vert < \infty$ for all $x\in X$, then $\sup_{\lambda\in\Lambda}\Vert T_\lambda\Vert < \infty$.
\begin{proof}
Since $\sup_{\lambda\in\Lambda}\Vert T_\lambda x\Vert < \infty$ for all $x\in X$, we define a norm on $X$ by
\begin{align*}
	\Vert x\Vert_1 := \max\left\{\Vert x\Vert,\ \sup_{\lambda\in\Lambda}\Vert T_\lambda x\Vert\right\}.
\end{align*}
We claim that $(X,\Vert\cdot\Vert_1)$ is a Banach space. Let $(x_n)$ be a Cauchy sequence in $(X,\Vert\cdot\Vert_1)$: for all $\epsilon>0$, there exists $N$ such that $\Vert x_n-x_m\Vert_1<\epsilon/2$ for all $n,m\geq N$. Since $\Vert x\Vert \leq\Vert x\Vert_1$ for all $x\in X$, $(x_n)$ is also a Cauchy sequence in $(X,\Vert\cdot\Vert)$. Hence there exists $x_0\in X$ such that $\lim_{n\to\infty}\Vert x_n-x_0\Vert=0$.

Fix $\epsilon>0$. Since $(x_n)$ is Cauchy relative to $\Vert\cdot\Vert_1$, there exists $N$ such that for all $\lambda\in\Lambda$ and all $n,m\geq N$,
\begin{align*}
	\left\Vert T_\lambda(x_n-x_m)\right\Vert<\frac{\epsilon}{2}.\tag{3.1}\label{eq:3.1}
\end{align*}
Let $m\to\infty$ in \hyperref[eq:3.1]{(3.1)}, we have $\Vert T_\lambda(x_n-x_0)\Vert\leq\epsilon/2$ for all $\lambda\in\Lambda$ and all $n\geq N$, which implies $$\sup_{\lambda\in\Lambda}\Vert T_\lambda(x_n-x_0)\Vert\leq\frac{\epsilon}{2} < \epsilon,\ \forall n\geq N.$$ 
Hence $\lim_{n\to\infty}\Vert x_n-x_0\Vert_1=0$, and $(X,\Vert\cdot\Vert_1)$ is complete. By \hyperref[thm:3.14]{Theorem 3.14}, there exists $c>0$ such that $\Vert x\Vert_1\leq c\Vert x\Vert$ for all $x\in X$. As a result, $\sup_{\lambda\in\Lambda}\Vert T_\lambda x\Vert\leq c\Vert x\Vert$ for all $x\in X$, and $\sup_{\lambda\in\Lambda}\Vert T_\lambda\Vert\leq c$.
\end{proof}
\paragraph{Remark.} The hypothesis of completeness of $X$ cannot be removed. Following is a simple counterexample.

Consider the space $(C_c(\mathbb{R}),\Vert\cdot\Vert_\infty)$, where $C_c(\mathbb{R})$ is the set of compactly supported continuous functions on $\mathbb{R}$, and $\Vert f\Vert_\infty=\sup_{t\in\mathbb{R}}\vert f(t)\vert$ for all $f\in C_c(\mathbb{R})$. Clearly, $(C_c(\mathbb{R}),\Vert\cdot\Vert_\infty)$ is not a Banach space, because the Cauchy sequence $f_n(t) = \exp(-t^2)\chi_{[-n,n]}(t)$ does not converges in $C_c(\mathbb{R})$.

We define operators $T_n$ for all $n\in\mathbb{N}$ as follows:
\begin{align*}
	(T_n f)(t) = t\chi_{[-n,n]}(t)f(t),\ \forall f\in C_c(\mathbb{R}).
\end{align*}
Then for all $f\in C_c(\mathbb{R})$, $t\mapsto tf(t)$ is also compactly supported and continuous. Then we have
\begin{align*}
	\sup_{n\in\mathbb{N}}\Vert T_n f\Vert = \sup_{t\in\mathbb{R}} tf(t) < \infty.
\end{align*}
However, $\Vert T_n\Vert = n$, which implies that $\{T_n\}_{n\in\mathbb{N}}$ is not uniformly bounded.

\paragraph{Theorem 3.24\label{thm:3.24}} (Banach-Steinhaus, Baire category version). Let $X$ be a Banach space, and let $Y$ be a normed space. Let $\left\{T_\lambda\right\}_{\lambda\in\Lambda}\subset\mathfrak{B}(X,Y)$. If the set 
\begin{align*}
	R:=\left\{x\in X:\sup_{\lambda\in\Lambda}\Vert T_\lambda x\Vert < \infty\right\}
\end{align*}
is of the second category in $X$, then $\sup_{\lambda\in\Lambda}\Vert T_\lambda\Vert < \infty$.
\begin{proof}
Define $p:X\to[0,\infty],\ x\mapsto\sup_{\lambda\in\Lambda}\Vert T_\lambda x\Vert$. Then $p$ is a seminorm on $X$, and
\begin{align*}
	R=\left\{x\in X:p(x)<\infty\right\} = \bigcup_{k=1}^\infty\underbrace{\left\{x\in X:p(x)\leq k\right\}}_{=:X_k} = \bigcup_{k=1}^\infty\bigcap_{\lambda\in\Lambda}\left\{x\in X:\Vert T_\lambda x\Vert\leq k\right\}
\end{align*}
By continuity of $T_\lambda$, $\left\{x\in X:\Vert T_\lambda x\Vert\leq k\right\}$ is closed in $X$, and $X_k$ is closed for all $k\in\mathbb{N}$. Since $R$ is of the second category, there exists $X_k$ that is not nowhere dense. Moreover, there exists $O(x_0,\epsilon)$ contained in $X_k$.

Let $N=k+p(x_0)$. Then $O(0,\epsilon)\subset X_N$, which implies
\begin{align*}
	p\left(\frac{\epsilon x}{2\Vert x\Vert}\right)\leq N,\ \forall x\in X\ \Rightarrow\ p\left(x\right)\leq \frac{2N}{\epsilon}\Vert x\Vert,\ \forall x\in X.
\end{align*}
As a result,  $\sup_{\lambda\in\Lambda}\Vert T_\lambda\Vert\leq\frac{2N}{\epsilon}$, as desired.
\end{proof}

\paragraph{Example 3.25.\label{example:3.25}} By Hölder's inequality, we know that $L^2([0,1])\subset L^1([0,1])$. In fact, $L^2([0,1])$ is a first-category subset of of $L^1([0,1])$.
\begin{proof}
	Let $f_n=n\chi_{[0,n^{-3}]}$ for all $n\in\mathbb{N}$. Define $F_n\in(L^1([0,1]))^*$ as
	\begin{align*}
		F_n(g) = \int_{[0,1]} f_ng\,dm,\ \forall g\in L^1([0,1]).
	\end{align*}
	Then $\Vert F_n\Vert = \Vert f_n\Vert_\infty=n$. Meanwhile, for all $h\in L^2([0,1])$,
	\begin{align*}
		F_n(h) \leq\Vert f_n\Vert_2\left\Vert h\right\Vert_2 = \frac{1}{\sqrt{n}}\Vert h\Vert_2 \leq\Vert h\Vert_2<\infty,\ \forall n\in\mathbb{N}.
	\end{align*}
	If $L^2([0,1])$ is of the second category, \hyperref[thm:3.24]{Theorem 3.24} implies that $\sup_{n\in\mathbb{N}}\Vert F_n\Vert < \infty$, a contradiction!
\end{proof}

Another version of Banach-Steinhaus theorem is based on countable collections of operators.

\paragraph{Theorem 3.26\label{thm:3.26}} (Banach-Steinhaus). Let $X$ be a Banach space, and  $Y$ a normed space. Let $(T_n)$ be a sequence of operators in $\mathfrak{B}(X,Y)$. If $(T_n x)$ converges in $Y$ for all $x\in X$, then there exists $T\in\mathfrak{B}(X,Y)$ such that $\lim_{n\to\infty} T_nx = Tx$, and $\Vert T\Vert\leq\liminf_{n\to\infty}\Vert T_n\Vert$.
\begin{proof}
Define $T:X\to Y,\ x\mapsto\lim_{n\to\infty}T_nx$. The linearity of $T$ follows immediately from $(T_n)$. Clearly, $\left\{x\in X:\sup_{n\in\mathbb{N}}\Vert T_n x\Vert\right\}=X$ is complete, hence of the second category. By \hyperref[thm:3.24]{Theorem 3.24}, $\sup_{n\in\mathbb{N}}\Vert T_\lambda\Vert < \infty$. Furthermore,
\begin{align*}
\Vert Tx\Vert = \lim_{n\to\infty}\Vert T_n x\Vert = \liminf_{n\to\infty}\Vert T_n x\Vert \leq\liminf_{n\to\infty}\Vert T_n\Vert\left\Vert x\right\Vert,\ \forall x\in X.
\end{align*}
Hence $\Vert T\Vert\leq\liminf_{n\to\infty}\Vert T_n\Vert$, as desired.
\end{proof}

\paragraph{Example 3.27.\label{example:3.27}} Let $1\leq p\leq\infty$. Let $f$ be a Lebesgue measurable function on $[a,b]$. If $fg\in L^1([a,b])$ for all $g\in L^p([a,b])$, then $f\in L^q([a,b])$, where $p^{-1}+q^{-1}=1$.
\begin{proof}
	Choose $g=\chi_{[a,b]}$, we know that $f\in L^1([a,b])$. For all $n\in\mathbb{N}$, define sequence of bounded functions on $[a,b]$ by $f_n = f\chi_{\vert f\vert < n}$. Then $f_n\to f$ a.e. on $[a,b]$. We then define
	\begin{align*}
		F_n(g) = \int_{[a,b]} f_n g\,dm,\ g\in L^p([a,b]).
	\end{align*}
	By Hölder's inequality, $F_n\in (L^p([a,b]))^*$, and $\Vert F_n\Vert=\Vert f_n\Vert_q$. Since $\vert f_n g\vert\leq\vert fg\vert$, the Lebesgue dominated convergence theorem implies
	\begin{align*}
		\lim_{n\to\infty} F_n(g) = \lim_{n\to\infty} \int_{[a,b]} f_n g\,dm = \int_{[a,b]} fg\,dm,\ \forall g\in L^p([a,b]).
	\end{align*}
	Define linear functional $F(g)=\int_{[a,b]} fg\,dm$ on $L^p([a,b])$. Using \hyperref[thm:3.26]{Theorem 3.26}, we have $F\in(L^p([a,b]))^*$, and $\Vert f\Vert_q=\Vert F\Vert\leq\liminf_{n\to\infty}\Vert F_n\Vert$, which implies $f\in L^q([a,b])$.
\end{proof}

Analogous to the weak topology in dual spaces, we also use some weaker convergences in the space of operators in lieu of convergence in operator norm.

\paragraph{Definition 3.28\label{def:3.28}} Let $X$ and $Y$ be normed spaces. Let $(T_n)$ be a sequence of operators in $\mathfrak{B}(X,Y)$, and $T\in\mathfrak{B}(X,Y)$.
\begin{itemize}
\item [(i)] (Convergence in strong operator topology, SOT). $(T_n)$ is said to \textit{converges to} $T$ \textit{in strong operator topology}, if $\lim_{n\to\infty}\Vert T_n x-Tx\Vert=0$ for all $x\in X$. We write $T_n\overset{SOT}{\to} T$.
\item [(ii)] (Convergence in weak operator topology, WOT). $(T_n)$ is said to \textit{converges to} $T$ \textit{in weak operator topology}, if $T_n x\overset{w}{\to} Tx$ for all $x\in X$, namely, $f(T_n x)\to f(Tx)$ for all $f\in Y^*$ and all $x\in X$. We write $T_n\overset{WOT}{\to} T$.
\end{itemize}
\paragraph{Remark.} Clearly, $\Vert Tx\Vert\leq\Vert T\Vert\left\Vert x\right\Vert$, and $\Vert f(Tx)\Vert\leq\Vert f\Vert\left\Vert Tx\right\Vert$. Therefore,
\begin{align*}
	T_n\overset{\Vert\cdot\Vert}{\to} T\ \Rightarrow\ T_n\overset{SOT}{\to} T\ \Rightarrow\ T_n\overset{WOT}{\to} T.
\end{align*}

The converse does not hold in general. Let $X=Y=l^2(\mathbb{N})$, and consider the left-shift operator $S$ and right-shift operator $T$. 
\begin{itemize}
	\vspace{0.1cm}
	\item[(i)] $S^n\overset{SOT}{\to} 0$, but $\Vert S^n\Vert=1$ for all $n\in\mathbb{N}$.
	\vspace{0.1cm}
	\item[(ii)] $T^n\overset{WOT}{\to} 0$, but $\Vert T^n x\Vert = \Vert x\Vert$ for all $x\in X$ and $n\in\mathbb{N}$, namely, $T^n$ does not converges to $0$ in strong operator topology.
\end{itemize}

\paragraph{Theorem 3.29\label{thm:3.29}} (Banach-Steinhaus). Let $X$ and $Y$ be Banach spaces. Let $(T_n)$ be a sequence of operators in $\mathfrak{B}(X,Y)$ such that $T_n\overset{WOT}{\to} T$, where $T\in\mathfrak{B}(X,Y)$. Then $\sup_{n\in\mathbb{N}}\Vert T_n\Vert<\infty$.
\begin{proof}
By convergence in weak operator topology, $f(T_nx)\to f(Tx)$ for all $x\in X$ and all $f\in Y^*$. Then
\begin{align*}
	R_x=\left\{f\in Y^*:\sup_{n\in\mathbb{N}}\left\vert f(T_n x)\right\vert<\infty\right\}=Y^*
\end{align*}
is of the second category. By \hyperref[thm:3.24]{Theorem 3.24}, $\sup_{n\in\mathbb{N}}\Vert T_n x\Vert < \infty$ for all $x\in X$. Again by \hyperref[thm:3.23]{Theorem 3.23}, $\sup_{n\in\mathbb{N}}\Vert T_n\Vert < \infty$.
\end{proof}

\newpage
\subsection{Adjoint Operators}
\subsubsection{Adjoint Operators in Normed Spaces}
\paragraph{Definition 3.30\label{def:3.30}} (Adjoint operators/conjugate operators). Let $X$ and $Y$ be normed spaces, and $T\in\mathfrak{B}(X,Y)$. If there exists $T^*\in\mathfrak{B}(Y^*,X^*)$ such that $(T^*f)(x)=f(Tx)$ for all $x\in X$ and $f\in Y^*$, then $T^*$ is said to be the \textit{adjoint (operator)/conjugate operator} of $T$.

\paragraph{Example 3.31\label{example:3.31}} Following are some instances for adjoint operators.
\begin{itemize}
\vspace{0.1cm}
\item[(i)] Let $X$ be an $n$-dimensional normed space, and $\{e_1,\cdots,e_n\}$ a basis of $X$. Let $Y$ be an $m$-dimensional normed space, and $\{f_1,\cdots,f_m\}$ a basis of $Y$. Then any linear operator $T:X\to Y$ is determined by an $m$-by-$n$ matrix $A=(a_{ij})_{m\times n}$:
\begin{align*}
	Te_j = \sum_{k=1}^m a_{kj}f_k\ \overset{def}{\Leftrightarrow}\ T\,(e_1,\cdots,e_n) = (f_1,\cdots,f_m)\begin{pmatrix}
		a_{11} & \cdots & a_{1n}\\
		\vdots & \ddots & \vdots\\
		a_{m1} & \cdots & a_{mn}
	\end{pmatrix}
\end{align*}
Let $e_j^*\in X^*$ be such that $e_j^*e_k = \delta_{jk}$ for $k=1,\cdots,n$. Then $\{e_1^*,\cdots,e_n^*\}$ is a basis of $X^*$. Similarly we choose a dual basis $\{f_1^*,\cdots,f_m^*\}$ for $Y^*$. Then
\begin{align*}
	\left(T^*f_i^*\right)e_j = f_i^*(Te_j) = \sum_{k=1}^n a_{kj}f_i^*f_k = a_{ij}\ \Rightarrow\ T^*\left(f_1^*,\cdots,f_m^*\right) = (e_1^*,\cdots,e_n^*)\begin{pmatrix}
		a_{11} & \cdots & a_{m1}\\
		\vdots & \ddots & \vdots\\
		a_{1n} & \cdots & a_{mn}
	\end{pmatrix}.
\end{align*}
It is seen that under the dual basis, the adjoint of $T$ is the matrix transpose.
\vspace{0.1cm}
\item[(ii)] We define an operator $T$ on $L^1([a,b])$ by
\begin{align*}
	(Tf)(x) = \int_a^x f(t)\,dt,\ \forall f\in L^1([a,b]).
\end{align*}
We view $T$ as an operator from $L^1([a,b])$ into $C([a,b])$. Let's find its adjoint $T^*:V_0([a,b])\to L^\infty([a,b])$, such that for all $\varphi\in V_0([a,b])$ and all $f\in L^1([a,b])$,
\begin{align*}
	(T^*\varphi)(f) = \langle Tf,\varphi\rangle = \int_a^b(Tf)(t)\,d\varphi(t) = \int_a^b\int_a^t f(s)\,ds\,d\varphi(t).
\end{align*}
By Fubini's theorem, since the mapping $(s,t)\mapsto f(s)$ lies in $L^1([a,b]\times[a,b])$, we have
\begin{align*}
	\int_a^b\int_a^t f(s)\,ds\,d\varphi(t) = \int_a^b f(s)\left(\int_s^b d\varphi(t)\right)\,ds.
\end{align*}
Therefore $(T^*\varphi)(s) = \int_s^b d\varphi(t)$, $\forall \varphi\in V_0([a,b])$.
\vspace{0.1cm}
\item[(iii)] We view $T$ as an operator from $L^1([a,b])$ into $L^1([a,b])$. Let's find its adjoint $T^*:L^\infty([a,b])\to L^\infty([a,b])$, such that for all $g\in L^\infty([a,b])$ and all $f\in L^1([a,b])$,
\begin{align*}
	(T^*g)(f) = \langle Tf,g\rangle = \int_a^b(Tf)(t)g(t)\,dt = \int_a^b\int_a^t f(s)g(t)\,ds\,dt = \int_a^b f(s)\left(\int_s^b g(t)\,dt\right)\,ds.
\end{align*}
Therefore $(T^*g)(s) = \int_s^b g(t)\,dt$, $\forall g\in L^\infty([a,b])$.
\end{itemize}

\paragraph{Theorem 3.32\label{thm:3.32}} (Properties of adjoint operators). Let $X$, $Y$ and $Z$ be normed spaces.
\begin{itemize}
	\vspace{0.1cm}
	\item[(i)] For all $T\in\mathfrak{B}(X,Y)$, its has a unique adjoint $T^*\in\mathfrak{B}(Y^*,X^*)$.
	\vspace{0.1cm}
	\item[(ii)] The mapping $T\mapsto T^*,\ \mathfrak{B}(X,Y)\to\mathfrak{B}(Y^*,X^*)$ is linear and norm-preserving.
	\vspace{0.1cm}
	\item[(iii)] $Id_X^* = Id_{X^*}$.
	\vspace{0.1cm}
	\item[(iv)] For all $T\in\mathfrak{B}(X,Y)$ and $S\in\mathfrak{B}(Y,Z)$, $(S T)^* = T^* S^*$.
	\item[(v)] Whenever $T\in\mathfrak{B}(X,Y)$ is invertible, so is $T^*$. Moreover, $$(T^*)^{-1}=(T^{-1})^*.$$
	\item[(vi)] For all $T\in\mathfrak{B}(X,Y)$, $$\ker(T^*) = \mathfrak{R}(T)^\perp,\ \ker(T) =\, ^\perp\mathfrak{R}(T^*).$$
	As a result, $\overline{\mathfrak{R}(T)} =\, ^\perp\ker(T^*)$.
	\vspace{0.1cm}
	\item[(vii)] View $X$ and $Y$ as subspaces of $X^{**}$ and $Y^{**}$, respectively. Then for all $T\in\mathfrak{B}(X,Y)$, the biconjugate $T^{**} := (T^*)^* \in\mathfrak{B}(X^{**},Y^{**})$, and $T^{**}|_X = T$.
\end{itemize}
\begin{proof}
(i) Clearly, $\vert f(Tx)\vert \leq\left\Vert f\right\Vert\left\Vert T\right\Vert\left\Vert x\right\Vert$ for all $f\in Y^*$ and $x\in X$. Given $f\in Y^*$, define
\begin{align*}
	(T^*f)(x) = f(Tx),\ \forall x\in X.
\end{align*}

Then $T^*f\in X^*$, and $\Vert T^* f\Vert\leq\left\Vert f\right\Vert\left\Vert T\right\Vert$. Furthermore, $T^*\in\mathfrak{B}(Y^*,X^*)$, and $\Vert T^*\Vert\leq \Vert T\Vert$.\vspace{0.1cm}

(ii) The linearity of $T\mapsto T^*$ is clear. Following (i), it remains to show $\Vert T^*\Vert\geq\Vert T\Vert$: if $T\neq 0$,
\begin{align*}
	\Vert Tx\Vert = \sup_{f\in Y^*,\,\Vert f\Vert=1} \vert f(Tx)\vert = \sup_{f\in Y^*,\,\Vert f\Vert=1} \vert (T^*f)(x)\vert\leq\sup_{f\in Y^*,\,\Vert f\Vert=1}\left\Vert T^*f\right\Vert\left\Vert x\right\Vert \leq \left\Vert T^*\right\Vert\left\Vert x\right\Vert.
\end{align*}

(iii) By definition, for all $f\in X^*$,
\begin{align*}
	(Id_X^* f)(x) = f(Id_X(x)) = f(x),\ \forall x\in X.
\end{align*}

(iv) For all $f\in Z^*$, we have
\begin{align*}
	\left((S T)^*f\right)(x) = f\left(S(Tx)\right) = (S^*f)(Tx) = (T^*(S^*f))(x),\ \forall x\in X.
\end{align*}

(v) Let $V=T^{-1}$. Then $VT=Id_X$, and $TV=Id_Y$. By (iii) and (iv), we have
\begin{align*}
	T^*V^* = (VT)^* = Id_{X^*},\ V^*T^* = (TV)^* = Id_{Y^*}.
\end{align*}

(vi) By definition, we have
\begin{align*}
	&y^*\in\ker(T^*)\ \Leftrightarrow\ T^*y^* = 0\ \Leftrightarrow\ 0=(T^*y^*)(x) = y^*(Tx),\ \forall x\in X\ \Leftrightarrow\ y^*\in\mathfrak{R}(T)^\perp.\\
	&x\in\ker(T)\ \Leftrightarrow\ Tx = 0\ \Leftrightarrow\ 0=y^*(Tx) = (T^*y^*)(x),\ \forall y^*\in Y^*\ \Leftrightarrow\ x\in\, ^\perp\mathfrak{R}(T^*).
\end{align*}

By \hyperref[thm:2.49]{Theorem 2.49}, $\overline{\mathfrak{R}(T)} =\, ^\perp(\mathfrak{R}(T)^\perp) =\, ^\perp\ker(T^*)$.
\vspace{0.1cm}

(vii) For all $x\in X$, let $x^{**}=J_X(x)$, where $J_X:X\to X^{**}$ is the canonical map. Then
\begin{align*}
	(T^{**}x^{**})f = x^{**}(T^* f) = (T^* f)(x) = f(Tx),\ \forall f\in Y^*.
\end{align*}

Then $T^{**}x^{**} = (Tx)^{**}$, which is the embedding of $Tx$ into $Y^{**}$. As a result, $T^{**}|_X = T$.
\end{proof}

\paragraph{Remark.} We have an immediate corollary of \hyperref[thm:3.32]{Theorem 3.32 (vi)}: Let $X$ and $Y$ be normed spaces, and $T\in\mathfrak{B}(X,Y)$. (i) $\mathfrak{R}(T)$ is dense in $Y$ if and only if $T^*$ is injective; (ii) If $\mathfrak{R}(T^*)$ is dense in $X^*$, then $T$ is injective. Furthermore, we have the following conclusion.

\paragraph{Lemma 3.33.\label{lemma:3.33}} Let $X$ and $Y$ be Banach spaces, and $T\in\mathfrak{B}(X,Y)$. If $T^*$ is injective, and $\mathfrak{R}(T^*)$ is closed, then $T$ is surjective.
\begin{proof}
If $\mathfrak{R}(T^*)$ is closed, then $T^*:Y^*\to\mathfrak{R}(T^*)$ is a bijection between Banach spaces. By bounded inverse theorem, there exists $\delta>0$ such that $\Vert T^*y^*\Vert\geq\delta\Vert y^*\Vert$ for all $y^*\in Y^*$. We claim that $O_{Y}(0,\delta)\subset\overline{TB_{X}(0,1)}$. Then akin to Step II in the proof of open mapping theorem (\hyperref[thm:3.13]{Theorem 3.13}), we have $O_Y\bigl(0,\frac{\delta}{2}\bigr)\subset TB_X(0,1)$. Hence $T$ is surjective.

Let's prove our claim. If there exists $y_0\in Y$ such that $\Vert y\Vert < \delta$ and $y_0\notin \overline{TB(0,1)}$. Since $\overline{TB_X(0,1)}$ is a closed convex subset of $Y$, by hyperplane separation theorem, there exists $f\in Y^*$ such that $f(y_0)>1$ and $f(y)\leq 1$ for all $y\in\overline{TB(0,1)}$. Then for all $x\in B_X(0,1)$,
\begin{align*}
	\vert (T^*f)(x)\vert = \vert f(Tx)\vert \leq 1,
\end{align*}
which implies $\Vert T^*f\Vert\leq 1$. However,
\begin{align*}
	\Vert f\Vert \geq \frac{\vert f(y_0)\vert}{\Vert y_0\Vert} > \frac{1}{\delta},
\end{align*}
which implies $\Vert T^*f\Vert \geq \delta\Vert f\Vert>1\geq \Vert T^*f\Vert$, a contradiction! Hence $O_{Y}(0,\delta)\subset\overline{TB_{X}(0,1)}$.
\end{proof}

Now we introduce the closed range theorem.

\paragraph{Theorem 3.34\label{thm:3.34}} (Closed range theorem). Let $X$ and $Y$ be Banach spaces, and $T\in\mathfrak{B}(X,Y)$. The following are equivalent: (i) $\mathfrak{R}(T)$ is closed; (ii) $\mathfrak{R}(T^*)$ is closed; (iii) $\mathfrak{R}(T)=\,^\perp\ker(T^*)$; (iv) $\mathfrak{R}(T^*) = \ker(T)^\perp$.
\begin{proof}
(i) $\Rightarrow$ (iii) is clear by \hyperref[thm:3.32]{Theorem 3.32 (vi)}; (iii) $\Rightarrow$ (i) and (iv) $\Rightarrow$ (ii) are trivial.

Now we prove (ii) $\Rightarrow$ (i) $\Rightarrow$ (iv). We first decompose $T$ as
\begin{align*}
	T=\iota\circ\widetilde{T}\circ\pi:\ X\overset{\pi}{\longrightarrow}X/\ker(T)\overset{\widetilde{T}}{\longrightarrow} \overline{\mathfrak{R}(T)}\overset{\iota}{\hookrightarrow} Y,
\end{align*}
where $\pi$ is the quotient map from $X$ onto $X/\ker(T)$, $\widetilde{T}[x]=Tx$ is the induced map from $X/\ker(T)$ to $\overline{\mathfrak{R}(T)}$, and $\iota:\overline{\mathfrak{R}(T)}\to Y$ is the identity embedding. Correspondingly, we decompose $T^*$ as
\begin{align*}
	T^* = \pi^*\circ \widetilde{T}^*\circ\iota^*: X^*\overset{\pi^*}{\longleftarrow}(X/\ker(T))^*\overset{\widetilde{T}^*}{\longleftarrow}\left(\overline{\mathfrak{R}(T)}\right)^*\overset{\iota^*}{\longleftarrow} Y.
\end{align*}

We first check $\pi^*$. For all $g\in(X/\ker(T))^*$ and all $x\in X$, we have $(\pi^* g)(x) = g(\pi(x))$. By \hyperref[thm:2.26]{Theorem 2.26}, $\pi^*:g\mapsto g\circ\pi$ is a norm-preserving embedding from $(X/\ker(T))^*$ into $X^*$, and $\mathfrak{R}(\pi^*)=\ker(T)^\perp$.

Next we check $\iota^*$. For all $f\in Y^*$ and all $\xi\in\overline{\mathfrak{R}(T)}$, we have $(\iota^*f)(\xi) = f(\iota(\xi)) = f(\xi)$. It is seen that $\iota^*$ is in fact the restriction: $\iota^* f=f|_{\overline{\mathfrak{R}(T)}}$. By Hahn-Banach theorem, $\iota^*$ is surjective.

Now we check $\widetilde{T}:X/\ker(T)\to\overline{\mathfrak{R}(T)}$. Clearly, $\mathfrak{R}(\widetilde{T})=\mathfrak{R}(T)$. Then $\widetilde{T}$ has dense range, and $\widetilde{T}^*$ is injective.
If $\mathfrak{R}(T^*)$ is closed, so is $\mathfrak{R}(\widetilde{T}^*)=\mathfrak{R}(T^*)\circ\pi$, because $\iota^*$ is surjective and $\pi^*$ is a norm-preserving embedding. By \hyperref[lemma:3.33]{Lemma 3.33}, $\widetilde{T}$ is surjective, and $\mathfrak{R}(T) = \mathfrak{R}(\widetilde{T}) = \overline{\mathfrak{R}(T)}$. Hence (ii) $\Rightarrow$ (iv).

If $\mathfrak{R}(T)$ is closed, $\widetilde{T}:X/\ker(T)\to\overline{\mathfrak{R}(T)}$ is a bijection between Banach spaces. By bounded inverse theorem, $\widetilde{T}$ is invertible, so is $\widetilde{T}^*$. As a result, $\widetilde{T}^*:(\mathfrak{R}(T))^*\to(X/\ker(T))^*$ is a bijection. Since $\iota^*$ is surjective, we have $\mathfrak{R}(T^*)=\mathfrak{R}(\pi^*)=\ker(T)^\perp$. Hence (i) $\Rightarrow$ (iv).
\end{proof}

Using \hyperref[thm:3.34]{Theorem 3.34}, we obtain the converse of \hyperref[thm:3.32]{Theorem 3.32 (v)} in Banach spaces.

\paragraph{Corollary 3.35.\label{cor:3.35}} Let $X$ and $Y$ be Banach spaces, and $T\in\mathfrak{B}(X,Y)$. Then $T$ is invertible if and only if $T^*$ is invertible.
\begin{proof}
Following \hyperref[thm:3.32]{Theorem 3.32 (v)}, it remains to show that $T$ is invertible whenever $T^*$ is invertible. If $T^*$ is invertible, $\mathfrak{R}(T^*)$ is closed. By \hyperref[thm:3.34]{Theorem 3.34},
\begin{align*}
	\ker(T)^\perp = \mathfrak{R}(T^*) = X^*,\ \mathfrak{R}(T)=\,^\perp\ker(T^*) = \,^\perp\{0\} = Y.
\end{align*}
By Hahn-Banach theorem, $\ker(T)=\{0\}$. Hence $T:X\to Y$ is a bijection. Using the bounded inverse theorem, $T$ is an invertible operator between Banach spaces.
\end{proof}

\subsubsection{Adjoint Operators in Hilbert Spaces}

Now we discuss adjoint operators in Hilbert spaces. Since any Hilbert space $H$ is isomorphic to its dual space $H^*$, we can define adjoint operators on primal spaces.

\paragraph{Definition 3.36.\label{def:3.36}} (Adjoints). Let $H_1$ and $H_2$ be Hilbert spaces. Then for all $T\in\mathfrak{B}(H_1,H_2)$, there exists a unique operator $T^*\in\mathfrak{B}(H_2,H_1)$ such that
\begin{align*}
	\langle Tx,y\rangle = \langle x,T^*y\rangle,\ \forall x\in H_1,\ \forall y\in H_2.\label{eq:3.2}\tag{3.2}
\end{align*}
Furthermore, $\Vert T^*\Vert = \Vert T\Vert$. The operator $T^*$ is said to be the \textit{adjoint (operator)} of $T$.
\begin{proof}
Given $y\in H_2$, we have $\vert\langle Tx,y\rangle\vert\leq\left\Vert T\right\Vert\left\Vert x\right\Vert\left\Vert y\right\Vert$ for all $x\in H_1$. Hence the mapping $x\mapsto\langle Tx,y\rangle$ is a bounded linear functional on $H_1$. By Riesz representation theorem, there exists a unique $\xi_y\in H_1$ such that $\langle Tx,y\rangle=\langle x,\xi_y\rangle$ for all $x\in X$. Define $T^*:H_2\to H_1,\ y\to\xi_y$. Clearly, $T^*$ is linear and satisfies \hyperref[eq:3.2]{(3.2)}. Furthermore, $T^*$ is bounded: $\Vert\xi_y\Vert^2=\langle T\xi_y,y\rangle\leq\left\Vert T\right\Vert\left\Vert \xi_y\right\Vert\left\Vert y\right\Vert$, which implies $\Vert T^*\Vert\leq\Vert T\Vert$. Furthermore,
\begin{align*}
	\Vert Tx\Vert^2 = \langle x,T^*Tx\rangle \leq \left\Vert x\right\Vert\left\Vert T^*\right\Vert\left\Vert Tx\right\Vert,\ \forall x\in X,
\end{align*}
which implies $\Vert T\Vert\leq\Vert T^*\Vert$. Hence $\Vert T^*\Vert=\Vert T\Vert$.
\end{proof}

\paragraph{Example 3.37.\label{example:3.37}} Following are instances for adjoint operators in Hilbert spaces.
\begin{itemize}
\vspace{0.1cm}
\item[(i)] Let $H_1$ be an $n$-dimensional Hilbert space, and $\{e_1,\cdots,e_n\}$ an orthonormal basis of $H_1$. Let $H_2$ be an $m$-dimensional normed space, and $\{f_1,\cdots,f_m\}$ an orthonormal basis of $H_2$. Then any linear operator $T:H_1\to H_2$ is determined by an $m$-by-$n$ matrix $A=(a_{ij})_{m\times n}$:
\begin{align*}
	Te_i = \sum_{k=1}^m a_{ki}f_k\ \overset{def}{\Leftrightarrow}\ T\,(e_1,\cdots,e_n) = (f_1,\cdots,f_m)\begin{pmatrix}
		a_{11} & \cdots & a_{1n}\\
		\vdots & \ddots & \vdots\\
		a_{m1} & \cdots & a_{mn}
	\end{pmatrix}
\end{align*}
By definition of orthonormal basis, $a_{ij}=\langle Te_j,f_i\rangle = \langle e_j,T^*f_i\rangle = \overline{\langle T^*f_i,e_j\rangle}$. Hence
\begin{align*}
	T^*\,(f_1,\cdots,f_m) = (e_1,\cdots,e_n)\begin{pmatrix}
		\overline{a_{11}} & \cdots & \overline{a_{m1}}\\
		\vdots & \ddots & \vdots\\
		\overline{a_{1n}} & \cdots & \overline{a_{mn}}
	\end{pmatrix}
\end{align*}
Under the orthonormal basis, the adjoint of $T$ is its conjugate transpose.

\item[(ii)] (Fredholm integral operator). Let $H=L^2([a,b])$, and $K\in L^2([a,b]\times[a,b])$. Define $T_K:H\to H$ by
\begin{align*}
	(T_K f)(x):=\int_a^b K(x,y)f(y)\,dy,\ \forall f\in L^2([a,b]),
\end{align*}
Then
\begin{align*}
	\Vert T_Kf\Vert_2^2 = \int_a^b\biggl\vert\int_a^b K(x,y)f(y)\,dy\biggr\vert^2 dx \leq \int_a^b\int_a^b \left\vert K(x,y)\right\vert^2\,dy\left\Vert f\right\Vert_2^2dx = \Vert K\Vert^2_2\left\Vert f\right\Vert^2_2.
\end{align*}
Hence $T_K\in\mathfrak{B}(H)$, and $\Vert T_K\Vert\leq\Vert K\Vert_2$. Now let's find the adjoint of $T_K$. For all $f,g\in L^2([a,b])$, by Fubini's theorem, we have
\begin{align*}
	\langle T_Kf, g\rangle = \int_a^b
	\left(\int_a^b f(s)K(t,s)\,ds\right)\overline{g(t)}\,dt = \int_a^b f(s)\left(\int_a^b K(t,s)\overline{g(t)}\,dt\right)ds.\label{eq:3.3}\tag{3.3}
\end{align*}
Since $\langle T_Kf, g\rangle = \langle f,T_K^*g\rangle = \int_a^b f(s)\overline{(T_K^*g)(s)}\,ds$, if we define $(T_K^*g)(s) = \int_a^b \overline{K(t,s)}g(t)\,dt$, we have $\langle T_Kf,g\rangle = \langle f,T_K^*g\rangle$ for all $f,g\in L^2([a,b])$.
\end{itemize}
\paragraph{Remark.} To apply Fubini's theorem in \hyperref[eq:3.3]{(3.3)}, we need to show $K(s,t)f(t)\overline{g(s)}\in L^1([a,b]\times[a,b])$:
\begin{align*}
	\int_{[a,b]\times[a,b]}\vert K(s,t) f(t)g(s)\vert\,ds\,dt \leq \Vert K\Vert_2\sqrt{\int_{[a,b]\times[a,b]}\vert f(t)g(s)\vert^2\,ds\,dt} = \left\Vert K\right\Vert_2\left\Vert f\right\Vert_2\left\Vert g\right\Vert_2.
\end{align*}
Similar to the conjugate transpose of matrices, we define the conjugate transpose of $K$ by $K^*(s,t)=\overline{K(t,s)}$, where $s,t\in[a,b]$. Then $T_K^*=T_{K^*}$.

\paragraph{Theorem 3.38\label{thm:3.38}} (Properties of adjoints in Hilbert spaces). Let $H$, $G$ and $K$ be Hilbert spaces.
\begin{itemize}
	\vspace{0.1cm}
	\item[(i)] For all $T\in\mathfrak{B}(H,G)$, all $x\in H$ and all $y\in G$, $\langle y,Tx\rangle = \langle T^*y,x\rangle$. As a result, $(T^*)^*=T$.
	\vspace{0.1cm}
	\item[(ii)] For all $T,S\in\mathfrak{B}(H,G)$ and all $\alpha,\beta\in\mathbb{C}$, $(\alpha S+\beta T)^* = \overline{\alpha}S^*+\overline{\beta}T^*$.
	\vspace{0.1cm}
	\item[(iii)] For all $T\in\mathfrak{B}(H,G)$ and all $S\in\mathfrak{B}(G,K)$, $(ST)^* = T^*S^*$.
	\vspace{0.1cm}
	\item[(iv)] For all $T\in\mathfrak{B}(H,G)$, $\Vert T\Vert^2=\Vert T^*T\Vert = \Vert TT^*\Vert$.
	\vspace{0.1cm}
	\item[(v)] For all $T\in\mathfrak{B}(H,G)$, $T$ is invertible if and only if $T^*$ is invertible. Moreover, $(T^*)^{-1}=(T^{-1})^*$.
	\vspace{0.1cm}
	\item[(vi)] For all $T\in\mathfrak{B}(H,G)$, $$\ker(T^*) = \mathfrak{R}(T)^\perp,\ \ker(T) = \mathfrak{R}(T^*)^\perp,\ \overline{\mathfrak{R}(T)} = \ker(T^*)^\perp,\ \overline{\mathfrak{R}(T^*)} = \ker(T)^\perp.$$
\end{itemize}
\begin{proof}
(i) For all $T\in\mathfrak{B}(H,G)$, all $x\in H$ and all $y\in G$,
\begin{align*}
	\langle y,Tx\rangle = \overline{\langle Tx,y\rangle} = \overline{\langle x,T^*y\rangle} = \langle T^*y,x\rangle.
\end{align*}

(ii) For all $x\in H$ and all $y\in G$,
\begin{align*}	
	\langle(\alpha S+\beta T)^*y, x\rangle = \langle y, (\alpha S+\beta T)x\rangle = \overline{\alpha}\langle y,Sx\rangle + \overline{\beta}\langle y,Tx\rangle = \overline{\alpha}\langle S^*y,x\rangle + \overline{\beta}\langle T^*y,x\rangle.
\end{align*}

(iii) For all $x\in H$ and all $z\in K$,
\begin{align*}
	\langle (ST)^*z,x\rangle = \langle z, S(Tx)\rangle = \langle S^*z, Tx\rangle = \langle T^*(S^*z), x\rangle.
\end{align*}
	
(iv) Clearly, $\Vert T^*T\Vert \leq \Vert T^*\Vert\left\Vert T\right\Vert = \Vert T\Vert^2$. For the other side,
\begin{align*}
	\langle Tx,Tx\rangle = \langle T^*Tx, x\rangle \leq \Vert T^*Tx\Vert\left\Vert x\right\Vert \leq \Vert T^*T\Vert\left\Vert x\right\Vert^2,\ \forall x\in H,\ \Rightarrow\ \Vert T\Vert^2 \leq \Vert T^*T\Vert.
\end{align*}

Similarly, we have $\Vert TT^*\Vert = \Vert T\Vert^2$.\vspace{0.1cm}
	
(v) Let $V=T^{-1}$. Then $VT=Id_H$, and $TV=Id_G$. By (iii) and (iv), we have
\begin{align*}
	T^*V^* = (VT)^* = Id_{H},\ V^*T^* = (TV)^* = Id_{G}.
\end{align*}

Hence $T^*$ is invertible, and $(T^{-1})^*=(T^*)^{-1}$. If $T^*$ is invertible, by (i), $T=(T^*)^*$ is also invertible.
	
(vi) By definition, we have
\begin{align*}
	y\in\ker(T^*)\ \Leftrightarrow\ T^*y = 0\ \Leftrightarrow\ \langle x,T^*y\rangle = \langle Tx,y\rangle = 0,\ \forall x\in H\ \Leftrightarrow\ y\in\mathfrak{R}(T)^\perp.
\end{align*}
\begin{align*}
	x\in\ker(T)\ \Leftrightarrow\ Tx = 0\ \Leftrightarrow\ \langle Tx,y\rangle = \langle x,T^*y\rangle = 0,\ \forall y\in H\ \Leftrightarrow\ x\in\mathfrak{R}(T^*)^\perp.
\end{align*}

By \hyperref[cor:1.38]{Corollary 1.38}, $\overline{\mathfrak{R}(T)}=(\mathfrak{R}(T)^\perp)^\perp = \ker(T^*)^\perp$, and $\overline{\mathfrak{R}(T^*)}=(\mathfrak{R}(T^*)^\perp)^\perp = \ker(T)^\perp$.
\end{proof}

Now we introduce some special operators, which is the generalization of unitary matrices, Hermitian matrices and normal matrices.

\paragraph{Definition 3.39.\label{def:3.39}} Let $H$ be a Hilbert space, and let $T\in\mathfrak{B}(H)$.
\begin{itemize}
	\item[(i)] (Unitary operators). $T$ is said to be a \textit{unitary operator} if $T^*T=TT^*=Id_H$.
	\item[(ii)] (Self-adjoint operators). $T$ is said to be a \textit{self-adjoint operator} if $T^*=T$.
	\item[(iii)] (Normal operators). $T$ is said to be a \textit{normal operator} if $T^*T=TT^*$. By definition, both unitary and self-adjoint operators are unitary.
\end{itemize}

\paragraph{Example 3.40.\label{example:3.40}} Let $L$ be a subspace of a Hilbert space $H$. Let $P_L:H\to L$ be the projection operator. Then $P_L$ is a self-adjoint operator.
\begin{proof} For all $x,y\in H$, let $x=x_0+x_1$ and $y=y_0+y_1$, where $x_0,y_0\in L$ and $x_1,y_1\in L^\perp$. Then
\begin{align*}
	\langle x,P_L^*y\rangle = \langle P_L x,y\rangle = \langle x_0,y_0+y_1\rangle = \langle x_0,y_0\rangle = \langle x_0+x_1,y_0 \rangle = \langle x,P_L y\rangle,\ \forall x\in H.
\end{align*}
Hence $P_L^*=P_L$.
\end{proof}

\paragraph{Lemma 3.41. \label{lemma:3.41}} Let $H$ be a complex-valued Hilbert space, and $T\in\mathfrak{B}(H)$. Then $T$ is self-adjoint if and only if $\langle Tx,x\rangle\in\mathbb{R}$ for all $x\in H$.
\begin{proof}
If $T$ is self-adjoint, then
\begin{align*}
	\overline{\langle Tx,x\rangle} = \langle x,Tx\rangle = \langle T^*x,x\rangle = \langle Tx,x\rangle,\ \forall x\in X.
\end{align*}
Conversely, if $\langle Tx,x\rangle\in\mathbb{R}$ for all $x\in X$, then
\begin{align*}
	\langle T(x+y),x+y\rangle = \langle Tx,x\rangle + \langle Ty,x\rangle + \langle Tx,y\rangle + \langle Ty,y\rangle \in\mathbb{R}, \forall x,y\in H\ &\Rightarrow\ \Im(\langle Tx,y\rangle + \langle Ty,x\rangle)=0\\
	\langle T(x+\i y),x+\i y\rangle = \langle Tx,x\rangle + \i\langle Ty,x\rangle - \i\langle Tx,y\rangle + \langle Ty,y\rangle \in\mathbb{R}, \forall x,y\in H\  &\Rightarrow\ \Re(\langle Tx,y\rangle - \langle Ty,x\rangle) =0.
\end{align*}
Therefore $\langle Tx,y\rangle = \overline{\langle Ty,x\rangle} = \langle T^*x,y\rangle$ for all $x,y\in H$, and $T$ is self-adjoint.
\end{proof}

\paragraph{Lemma 3.42.\label{lemma:3.42}} Let $H$ be a Hilbert space, and $U\in\mathfrak{B}(H)$. Then $U$ is a unitary operator if and only if $U$ is surjective and norm-preserving.
\begin{proof}
If $U$ is unitary, then $U$ is bounded and invertible. Clearly, $U$ is surjective. Furthermore, $\Vert U\Vert = \Vert U^*\Vert = \sqrt{\Vert U^*U\Vert} = 1$.
\begin{align*}
	\Vert x\Vert = \Vert U^*Ux\Vert \leq \Vert U^*\Vert\left\Vert Ux\right\Vert = \Vert Ux\Vert \leq \Vert U\Vert\left\Vert x\right\Vert = \Vert x\Vert,\ \forall x\in H.
\end{align*}
Hence $U$ is norm-preserving, i.e. $\Vert Ux\Vert = \Vert x\Vert$ for all $x\in H$. \vspace{0.1cm}

Conversely, suppose $U\in\mathfrak{B}(H)$ is surjective and norm-preserving. We first prove that $U$ is and inner-product-preserving. By polarization identity,
\begin{align*}
	\langle Ux,Uy\rangle = \sum_{k=0}^3 \i^k\Vert Ux+\i^kUy\Vert^2 = \sum_{k=0}^3 \i^k\Vert x+\i^k y\Vert^2 = \langle x,y\rangle,\ \forall x,y\in H.
\end{align*}
Since $U$ preserves inner product, we have
\begin{align*}
	\langle U^*Ux, y\rangle = \langle Ux, Uy\rangle = \langle x,y\rangle,\ \forall x,y\in H.
\end{align*} 
Hence $U^*U=Id_H$. Moreover, for all $y\in H$, by surjectivity of $U$, there exists $\xi_y\in H$ such that $U\xi_y=y$, and
\begin{align*}
	\langle UU^*x,y\rangle = \langle UU^*x,U\xi_y\rangle = \langle U^*x,\xi_y\rangle = \langle x,U\xi_y\rangle = \langle x,y\rangle,\ \forall x,y\in H. 
\end{align*}
Therefore $UU^*=Id_H$, and $U$ is unitary.
\end{proof}

\paragraph{Lemma 3.43.\label{lemma:3.43}} Let $H$ be a Hilbert space, and $T\in\mathfrak{B}(H)$ is a normal operator on $H$. Then $\ker(T)=\ker(T^*)$, and $\ker(T)\perp\mathfrak{R}(T)$.
\begin{proof}
For all $x\in H$,
\begin{align*}
	\Vert Tx\Vert^2 = \langle Tx,Tx\rangle = \langle x,T^*Tx\rangle = \langle x,TT^*x\rangle = \langle T^*x,T^*x\rangle = \Vert T^*x\Vert^2.
\end{align*}
Hence $\ker(T)=\ker(T^*)$. The second result follows from $\ker(T^*)=\mathfrak{R}(T)^\perp$.
\end{proof}

\newpage
\section{Spectral Theory}
Without specification, the vector spaces we are going to discuss in this section are all complex.
\subsection{Resolvent Sets and Spectra}
Recall that in matrix theory, the scalar-vector couple $(\lambda,v)$ is said to be an eigenpair of a matrix $A$, if $v\neq 0$ and $Av = \lambda v$. $\lambda$ is said to be an eigenvalue of $A$, and $v$ is said to be the related eigenvector of $\lambda$. Clearly, $A$ is a linear mapping defined on a finite-dimensional space. We can extend this definition to linear operators on general vector spaces.

\paragraph{Definition 4.1.\label{def:4.1}} Let $X$ be a complex vector space, and let $T:X\to X$ be a linear operator on $X$.
\begin{itemize}
	\item[(i)] (Eigenvalues and eigenvectors). $\lambda\in\mathbb{C}$ is said to be an \textit{eigenvalue} of $T$, if there exists nonzero vector $x\in X$ such that $Tx=\lambda x$. The vector $x$ is said to be an \textit{eigenvector} of $T$ associated with $\lambda$.
	\item[(ii)] (Eigenspaces). The \textit{eigenspace} (or \textit{characteristic subspace}) of $T$ associated with eigenvalue $\lambda$ is defined as the set $E_\lambda=\{x\in X: Tx=\lambda x\}$. Clearly, $E_\lambda$ is a subspace of $X$. The dimension of $E_\lambda$ is said to be the $\textit{multiplicity}$ of $\lambda$.
\end{itemize}

\paragraph{} Let's find eigenvalues of some linear operators.

\paragraph{Example 4.2.\label{example:4.2}} (i) Let $P:H\to M$ be the projection operator onto a subspace $M$ of a Hilbert space $H$. For all $x\in M$, $Px=x$; and for all $x\in M^\perp$, $Px=0$. If $\lambda\notin\{0,1\}$, $P-\lambda\,Id_H$ is invertible. Hence $P$ has eigenvalues $1$ and $0$, and the corresponding eigenspaces are $E_1=M$, and $E_0=M^\perp$. \vspace{0.1cm}

(ii) Define $T:L^2([a,b])\to L^2([a,b])$, $(Tf)(x)=\int_a^x f(t)\,dt$, $\forall f\in L^2([a,b])$. We solve the characteristic equation $Tf=\lambda f$ as follows:
\begin{itemize}
	\vspace{0.1cm}
	\item If $\lambda=0$, then $F(x)=\int_a^x f(t)\,dt=0$ for all $x\in[a,b]$, which implies $F^\prime = f = 0$ (a.e.) on $[a,b]$.
	\vspace{0.1cm}
	\item If $\lambda\neq 0$, then $f(x)=\frac{1}{\lambda}\int_a^x f(t)\,dt$ for all $x\in[a,b]$, and $f^\prime = \frac{1}{\lambda}f$. By solving the differential equation, $f(t) = C\mathrm{e}^{-t/\lambda}$ for some constant $C$. Since $f(a)=0$, we have $C=0$, and $f\equiv 0$.\vspace{0.1cm}
\end{itemize}
Hence $T$ has no eigenvalue.

\paragraph{Remark.} By \hyperref[example:4.2]{Example 4.2 (ii)}, we see that linear operators on infinite-dimensional spaces possibly have no eigenvalue. According to \hyperref[def:4.1]{Definition 4.1}, we can equivalently define eigenvalues of operator $T$ as the numbers $\lambda\in\mathbb{C}$ such that $T-\lambda\,Id_X$ is not injective. If $X$ finite-dimensional, a linear operator $T:X\to X$ is invertible if and only if it is injective. However, it is not the case when the dimension of $X$ becomes infinite. Inspiring by this observation, we introduce the definition of spectra.

\paragraph{Definition 4.3 \label{def:4.3}} Let $X$ be a complex normed space, and $T\in\mathfrak{B}(X)$. Let $I$ be the identity operator on $X$.
\begin{itemize}
	\item[(i)] (Regular value). Given $\lambda\in\mathbb{C}$, if $T-\lambda I$ is invertible, i.e. $T-\lambda I$ is a bijection $X\to Y$, and the inverse $R_\lambda(T)=(T-\lambda I)^{-1}$ is bounded, then $\lambda$ is said to be a \textit{regular value} of $T$. The inverse operator $R_\lambda(T)$ is said to be the \textit{resolvent} of $T$.
	\item[(ii)] (Resolvent sets). The \textit{resolvent set} of $T$ is the set of all regular values of $T$:
	\begin{align*}
		\rho(T) = \left\{\lambda\in\mathbb{C}:T-\lambda I\in\mathfrak{B}(X)\right\}.
	\end{align*}
    \item[(iii)] (Spectra). The \textit{spectrum} of $T$ is the complement of the resolvent set: $\sigma(L)=\mathbb{C}\backslash\rho(L).$ In other words, the spectrum $\sigma(T)$ of $T$ is the set of all $\lambda\in\mathbb{C}$ such that $T-\lambda I$ is not invertible.
\end{itemize}

\paragraph{Proposition 4.4.\label{prop:4.4}} Let $X$ be a complex Banach space, and $T\in\mathfrak{B}(X)$.
\begin{itemize}
	\vspace{0.1cm}
	\item[(i)] Given a polynomial $p(z)=\sum_{k=0}^n a_kz^k\ (a_n\neq 0)$ defined on $C$, define $p(T)=\sum_{k=0}^n a_k T^k$. Then 
	\begin{align*}
		\sigma(p(T))=p(\sigma(T)) := \left\{p(\lambda):\lambda\in\sigma(T)\right\}.
	\end{align*}
	\item[(ii)] If $T$ is invertible, then 
	\begin{align*}
		\sigma(T^{-1})=\sigma(T)^{-1} := \left\{\frac{1}{\lambda}:\lambda\in\sigma(T)\right\}.
	\end{align*}
\end{itemize}
\begin{proof}
(i) We first prove a technical lemma: Let $T_1,T_2\in\mathfrak{B}(X)$, and $T_1T_2=T_2T_1$. Then $T_1T_2$ is invertible if and only if both $T_1$ and $T_2$ are invertible. If both $T_1$ and $T_2$ are invertible, then $T_2^{-1}T_1^{-1}\in\mathfrak{B}(X)$ is the inverse of $T_1T_2$. Conversely, if $T_1T_2$ is invertible, then $(T_1T_2)^{-1}T_2 = T_2(T_1T_2)^{-1}$ is the bounded inverse of $T_1$, and $(T_1T_2)^{-1}T_1 = T_1(T_1T_2)^{-1}$ is the bounded inverse of $T_2$.\vspace{0.1cm}

Let $\mu\in\mathbb{C}$, and let $p(z) - \mu = a_n\prod_{k=1}^n(z-\lambda_k)$ be the factorization of polynomial $p(z)-\mu$, where $\lambda_1,\cdots,\lambda_n\in\mathbb{C}$. Then $\mu=p(\lambda_k)$ for all $k=1,\cdots, n$. By above lemma,
\begin{align*}
	p(T) - \mu I = a_n\prod_{k=1}^n (T-\lambda_k I)
\end{align*}
is invertible if and only if $T-\lambda_k I$ is invertible for all $k=1,\cdots,n$. Then
\begin{align*}
	\mu\in\sigma(p(T))\ \Leftrightarrow\ p(T)-\mu I\ \text{is not invertible}\ &\Leftrightarrow\ \text{there exists}\ \lambda_k\ \text{such that}\ T-\lambda_k I\ \text{is not invertible}\\
	&\Leftrightarrow\ \text{there exists}\ \lambda_k\ \text{such that}\ \lambda_k\in \sigma(T)\\
	&\Leftrightarrow\ \text{there exists}\ \lambda\in\sigma(T)\ \text{such that}\ p(\lambda)-\mu = 0.
\end{align*}

(ii) Clearly, $0\notin\sigma(T)$. If $\lambda\neq 0$, then $T-\lambda I$ is invertible if and only if $\frac{1}{\lambda} - T^{-1}$ is invertible, as desired.
\end{proof}

\subsubsection{Classification of Points in the Spectrum}
Now we discuss the spectrum of bounded linear operators on Banach spaces.
\paragraph{Definition 4.5.\label{def:4.5}} Let $X$ be a Banach space, and $T\in\mathfrak{B}(X)$. Let $\lambda\in\sigma(T)$. Then $\lambda$ is one of the three cases:
\begin{itemize}
\vspace{0.1cm}
\item[(i)] If $T - \lambda I$ is not injective, by definition $\lambda$ is an eigenvalue of $T$. The set of all eigenvalues of $T$ is said to be the \textit{point spectrum} of $T$:
\begin{align*}
	\sigma_p(T) = \left\{\lambda\in\sigma(T):\ \ker(T-\lambda I)\neq 0\right\}.
\end{align*}
\item[(ii)]  If $T-\lambda I$ is injective but does not have dense range, $\lambda$ is said to belong to the \textit{residual spectrum} of $T$:
\begin{align*}
	\sigma_r(T) = \left\{\lambda\in\sigma(T):\ \ker(T-\lambda I)=0,\ \overline{\mathfrak{R}(T-\lambda I)}\neq X\right\}.
\end{align*}
\item[(iii)]  If $T-\lambda I$ is injective and has dense range, $\lambda$ is said to belong to the \textit{continuous spectrum} of $T$:
\begin{align*}
	\sigma_c(T) = \left\{\lambda\in\sigma(T):\ \ker(T-\lambda I)=0,\ \overline{\mathfrak{R}(T-\lambda I)}= X\right\}.
\end{align*}
In this case, $T-\lambda I$ is not bounded from below. In fact, if there exists $c>0$ such that $\Vert Tx\Vert\geq c\Vert x\Vert$ for all $x\in X$, by \hyperref[thm:3.15]{Theorem 3.15}, $\mathfrak{R}(T-\lambda I)$ is closed. Hence $\mathfrak{R}(T-\lambda I) = \overline{\mathfrak{R}(T-\lambda I)}=X$, and $T-\lambda I\in\mathfrak{B}(X)$ by bounded inverse theorem. But $\lambda\in\sigma(T)$, a contradiction!
\end{itemize}
\paragraph{Remark.}  Since $X$ is a Banach space, all bijections on $X$ are invertible. Hence there exists no $\lambda\in\sigma(T)$ such that $T-\lambda I$ is a bijection that has unbounded inverse. As a result, we have the following decomposition of the spectrum of $T$:
\begin{align*}
	\sigma(T) = \sigma_p(T)\amalg\sigma_r(T)\amalg\sigma_c(T).
\end{align*}

\paragraph{Example 4.6.\label{example:4.6}} (i) Let $X=C([0,1])$. Define $T:X\to X$ by
\begin{align*}
	(Tf)(x) = xf(x),\ \forall f\in X.
\end{align*}
Then $T\in\mathfrak{B}(X)$, and $\Vert T\Vert=1$. We find the spectrum of $T$ as follows.
\begin{itemize}
\vspace{0.1cm}
\item If $\lambda\notin [0,1]$, then for all $g\in C([0,1])$, the equation $(T-\lambda I)f=g$ has a unique solution $f(x)=\frac{g(x)}{x-\lambda}$, and
\begin{align*}
	\frac{\Vert f\Vert_\infty}{\Vert g\Vert_\infty} = \frac{\sup_{x\in[0,1]}\frac{g(x)}{x-\lambda}}{\sup_{x\in[0,1]} g(x)} \leq\sup_{x\in[0,1]}\frac{1}{x-\lambda} = \max\left\{\frac{1}{1-\lambda},-\frac{1}{\lambda}\right\}< \infty.
\end{align*}
Hence $T-\lambda I$ is invertible, and $\lambda\in\rho(T)$.
\vspace{0.1cm}
\item If $\lambda\in [0,1]$, we have $\ker(T-\lambda I)=0$: If $Tf=0$, $f(x)=0$ for all $x\neq\lambda$, and $f\equiv 0$ by continuity. Furthermore, $\mathfrak{R}(T-\lambda I)\subset\left\{g\in C([a,b]): g(\lambda)=0\right\}$, and
\begin{align*}
	\overline{\mathfrak{R}(T-\lambda I)}\subset\overline{\left\{g\in C([a,b]): g(\lambda)=0\right\}} = \left\{g\in C([a,b]): g(\lambda)=0\right\}\neq C([a,b]).
\end{align*}
Hence $\lambda\in\sigma_r(T)$. To summarize, $\sigma(T)=\sigma_r(T)=[0,1]$. \vspace{0.2cm}
\end{itemize}
(ii) We shift to $X=L^2([0,1])$. Still, $T\in\mathfrak{B}(X)$, and $\Vert T\Vert=1$. We find the spectrum of $T$ as follows.
\begin{itemize}
	\vspace{0.1cm}
	\item If $\lambda\notin [0,1]$, similar to (i), $T-\lambda I$ is invertible, and $\lambda\in\rho(T)$.
	\vspace{0.1cm}
	\item If $\lambda\in [0,1]$, we have $\ker(T-\lambda I)=0$: If $Tf=0$, then $f=0$ a.e. on $[0,1]\backslash\{\lambda\}$, and the modification at single point $\lambda$ does not change $f\in L^2([0,1])$. However, $f$ is not surjective, since $\chi_{[0,1]}\notin\mathfrak{R}(T-\lambda I)$.
	
	Given $g\in L^2([0,1])$, we choose the sequence $g_n = g\chi_{\{x:\vert x-\lambda\vert > n^{-1}\}}$. By Lebesgue dominated convergence theorem, $\Vert g_n-g\Vert_2\to 0$ as $n\to\infty$. Furthermore, define $f_n(x) = \frac{g_n(x)}{x-\lambda}$ for $x\neq\lambda$ and $f_n(\lambda)=0$, then
	\begin{align*}
		\int_{[0,1]} \vert f_n(x)\vert^2\,dx \leq \int_{\{x:\vert x-\lambda\vert > n^{-1}\}}\vert ng(x)\vert^2\,dx = n^2\Vert g\Vert_2^2 < \infty.
	\end{align*}
    Hence $f_n\in L^2([0,1])$, and $g_n$ is a sequence in $\mathfrak{R}(T-\lambda I)$ that converges to $g$. As a result, $\overline{\mathfrak{R}(T-\lambda I)}=L^2([0,1])$, and $\lambda\in\sigma_c(T)$. To summarize, $\sigma(T)=\sigma_c(T)=[0,1]$.
\end{itemize}

\paragraph{} Now we discuss the spectrum of adjoint operators.

\paragraph{Theorem 4.7.\label{thm:4.7}} Let $X$ be a Banach space, and let $T\in\mathfrak{B}(X)$. Then (i) $\sigma(T)=\sigma(T^*)$; (ii) $\sigma_r(T^*)\subset\sigma_p(T)$, and $\sigma_r(T)\subset\sigma_p(T^*)$; (iii) $\sigma_c(T^*)=\sigma_c(T)$.
\begin{proof}
(i) By \hyperref[cor:3.35]{Corollary 3.35}, $T-\lambda I_X$ is invertible if and only if $(T-\lambda I_X)^*=T^*-\lambda I_{X^*}$ is invertible.
\vspace{0.1cm}

(ii) If $\lambda\in\sigma_r(T^*)$, then $\overline{\mathfrak{R}(T^*-\lambda I_{X^*})}\neq X^*$, and \begin{align*}
	\ker(T-\lambda I_X) =\, ^\perp\mathfrak{R}(T^*-\lambda I_{X^*})=\, ^\perp\overline{\mathfrak{R}(T^*-\lambda I_{X^*})} \neq \{0\}.
\end{align*}
Hence $\lambda\in\sigma_p(T)$, and $\sigma_r(T^*)\subset\sigma_p(T)$. Similarly, $\sigma_r(T)\subset\sigma_p(T^*)$.

(iii) Following \hyperref[thm:3.32]{Theorem 3.32 (vi)} and Remark of \hyperref[def:2.25]{Definition 2.25},
\begin{align*}
	\ker(T^*-\lambda I_{X^*})=\overline{\mathfrak{R}(T-\lambda I_X)}^\perp,\ \ker(T-\lambda I_X)=\,^\perp\overline{\mathfrak{R}(T^*-\lambda I_{X^*})}.
\end{align*}
Then
\begin{align*}
	\lambda\in\sigma_c(T)\ &\Leftrightarrow\ \ker(T-\lambda I_X)=0,\ \overline{\mathfrak{R}(T-\lambda I_X)}=X\\
	&\Leftrightarrow\ \overline{\mathfrak{R}(T^*-\lambda I_{X^*})}=X^*,\ \ker(T^*-I_{X^*})=0\ \Leftrightarrow\ \lambda\in\sigma_c(T^*).
\end{align*}
Therefore, $\sigma_c(T^*)=\sigma_c(T)$.
\end{proof}

When we discuss adjoints in Hilbert spaces, \hyperref[thm:4.7]{Theorem 4.7} need modification. 

\paragraph{Theorem 4.8.\label{thm:4.8}} Let $H$ be a Hilbert space, and let $T\in\mathfrak{B}(H)$. Then (i) $\sigma(T^*)=\overline{\sigma(T)}:=\left\{\overline{\lambda}:\lambda\in\sigma(T)\right\}$;\quad (ii) $\overline{\sigma_r(T^*)}\subset\sigma_p(T)$, and $\overline{\sigma_r(T)}\subset\sigma_p(T^*)$; (iii) $\sigma_c(T^*)=\overline{\sigma_c(T)}$.
\begin{proof}
	Similar to \hyperref[thm:4.7]{Theorem 4.7}. Note that in Hilbert space $H$, $(T-\lambda I)^* = T^* - \overline{\lambda}I$.
\end{proof}

\subsubsection{Properties of the Spectrum}
\paragraph{Lemma 4.9\label{lemma:4.9}} (Neumann series). Let $X$ be a Banach space, and let $T\in\mathfrak{B}(X)$. If $\Vert T\Vert < 1$, then $I-T$ is invertible, and
\begin{align*}
	(I-T)^{-1}= \sum_{k=0}^\infty T^k.
\end{align*}
\begin{proof}
We first verify that the limit $\lim_{n\to\infty}\sum_{k=1}^n T^k$ exists. By completeness of $\mathfrak{B}(X)$, it suffices to show that $\left(\sum_{k=1}^n T^k\right)_{n\in\mathbb{N}}$ is a Cauchy sequence:
\begin{align*}
	\left\Vert\sum_{k=m+1}^n T^k\right\Vert\leq\sum_{k=m+1}^n \Vert T\Vert^k = \frac{\Vert T\Vert^{m+1}(1-\Vert T\Vert^{n-m})}{1-\Vert T\Vert},\ \forall n>m.
\end{align*}
Since $\Vert T\Vert <1$, $\left(\sum_{k=1}^n T^k\right)_{n\in\mathbb{N}}$ is a Cauchy sequence, hence converges in $\mathfrak{B}(X)$. Furthermore,
\begin{align*}
	\sum_{k=0}^\infty T^k(I-T) = (I-T)\sum_{k=0}^\infty T^k = \lim_{n\to\infty} \sum_{k=0}^n(I-T)T^k = \lim_{n\to\infty} I-T^{n+1} = I.
\end{align*}
Hence $(I-T)^{-1}=\sum_{k=0}^\infty T^k$.
\end{proof}

\paragraph{Corollary 4.10.\label{cor:4.10}} Let $X$ be a Banach space, and let $T\in\mathfrak{B}(X)$ be invertible. If $S\in\mathfrak{B}(X)$ satisfies $\Vert S-T\Vert < \frac{1}{2\Vert T^{-1}\Vert}$, then $S$ is invertible, and $\Vert S^{-1}-T^{-1}\Vert\leq 2\Vert T^{-1}\Vert^2\Vert T-S\Vert$.
\begin{proof}
Since $T$ is invertible, we have
\begin{align*}
	S = T + (S-T) = T\left(I + T^{-1}(S-T)\right),\quad \Vert T^{-1}(S-T)\Vert \leq \left\Vert T^{-1}\right\Vert\left\Vert S-T\right\Vert < \frac{1}{2}.
\end{align*}
By \hyperref[lemma:4.9]{Lemma 4.9}, $I+T^{-1}(S-T)$ is invertible, hence $S$ is invertible. Furthermore,
\begin{align*}
	\left\Vert S^{-1}\right\Vert = \left\Vert\left(I + T^{-1}(S-T)\right)^{-1}T^{-1}\right\Vert\leq\left\Vert\left(I + T^{-1}(S-T)\right)^{-1}\right\Vert\left\Vert T^{-1}\right\Vert\leq 2\left\Vert T^{-1}\right\Vert.\label{eq:4.1}\tag{4.1}
\end{align*}
We use \hyperref[eq;4.1]{(4.1)} to bound $\left\Vert S^{-1}-T^{-1}\right\Vert$:
\begin{align*}
	\left\Vert S^{-1}-T^{-1}\right\Vert = \left\Vert S^{-1}(T-S)T^{-1}\right\Vert\leq\left\Vert S^{-1}\right\Vert\left\Vert T-S\right\Vert\left\Vert T^{-1}\right\Vert\leq 2\left\Vert T^{-1}\right\Vert^2\Vert T-S\Vert.\label{eq:4.2}\tag{4.2}
\end{align*}
\paragraph{Remark.} Following our discussion, the set of all invertible linear operators in $\mathfrak{B}(H)$ is an open set, and the map $T\mapsto T^{-1}$ is continuous.
\end{proof}

\paragraph{Theorem 4.11.\label{thm:4.11}} Let $X$ be a Banach space, and $T\in\mathfrak{B}(X)$. 
\begin{itemize}
	\vspace{0.1cm}
	\item[(i)] If $\vert\lambda\vert>\Vert T\Vert$, then $\lambda\in\rho(T)$;
	\vspace{0.1cm} 
	\item[(ii)] $\rho(T)$ is open in $\mathbb{C}$; 
	\vspace{0.1cm}
	\item[(iii)] $\sigma(T)$ is compact.
\end{itemize}
\begin{proof}
(i) When $\vert\lambda\vert>\Vert T\Vert$, $T-\lambda I= \lambda\left(\frac{T}{\lambda} - I\right)$ is invertible by \hyperref[lemma:4.9]{Lemma 4.9}. \vspace{0.1cm}

(ii) By \hyperref[cor:4.10]{Corollary 4.10}, if $\lambda\in\rho(T)$, namely, $T-\lambda I$ is invertible, then $T-\mu I$ is invertible for all $$\vert\mu-\lambda\vert < \frac{1}{2\Vert (T-\lambda I)^{-1}\Vert}.$$
Hence $\lambda$ is in the interior of $\rho(T)$. As a result, $\rho(T)$ is open in $\mathbb{C}$.\vspace{0.1cm}

(iii) By (i) and (ii), $\sigma(T) = \mathbb{C}\backslash\rho(T)\subset\{z\in\mathbb{C}:\vert z\vert\leq\Vert T\Vert\}$. Then $\sigma(T)$ is a bounded closed subset of $\mathbb{C}$, hence is compact.
\end{proof}

\paragraph{Definition 4.12\label{def:4.12}} (Spectral radii). The \textit{spectral radius} of operator $T$ is defined as
\begin{align*}
	r(T) := \sup_{\lambda\in\sigma(T)} \vert\lambda\vert.
\end{align*}
\paragraph{Remark.} Following \hyperref[thm:4.11]{Theorem 4.11}, we have $r(T)\leq\Vert T\Vert$. Generally, $r(T)=\Vert T\Vert$ does not hold.

\paragraph{Example 4.13.\label{example:4.13}} (i) Consider the space $\mathbb{C}^2$. Let $A=\begin{pmatrix}
	0 & 1 \\ 0 & 0
\end{pmatrix}$. Then $\Vert A\Vert=1$, $\sigma(A)=\{0\}$, and $r(A)=0$.
\vspace{0.1cm}

(ii) Let $l^2$ be the space of all square-summable sequences. Define the left-shift and right-shift operators:
\begin{align*}
	S:(x_1,x_2,\cdots)\mapsto (x_2,x_3,\cdots),\quad T:(x_1,x_2,\cdots)\mapsto(0,x_1,x_2,\cdots).
\end{align*}
Choose an orthonormal basis $e_n=(0,\cdots,0,\underset{n\text{-th}}{1},0,\cdots), n\in\mathbb{N}$ of $l^2$. Then $Te_{n}=e_{n+1}$, $Se_{n+1}=e_n$, and $Se_1=0$. As a result,
\begin{align*}
	T\left(\sum_{n=1}^\infty x_ne_n\right) = \sum_{n=1}^\infty x_ne_{n+1},\quad S\left(\sum_{n=1}^\infty x_ne_n\right) = \sum_{n=1}^\infty x_{n+1}e_n.
\end{align*}
Then $\Vert S\Vert=\Vert T\Vert =1$, $r(S)\leq 1$, and $r(T)\leq 1$. Moreover, we can verify $T=S^*$, which implies $\sigma(T)=\overline{\sigma(S)}$.\vspace{0.1cm}

Consider the operator $S-\lambda I$ for $\vert\lambda\vert\leq 1$. Note that
\begin{align*}
	(S-\lambda I)(x_1,x_2,\cdots)=0\ \Rightarrow\ x_{n+1}=\lambda x_n,\ \forall n\in\mathbb{N}.
\end{align*}
If $\vert\lambda\vert<1$, then $(1,\lambda,\lambda^2,\cdots)\in\ker(S)$ for all $\vert\lambda\vert<1$, which implies $\lambda\in\sigma_p(S)$. By \hyperref[thm:4.11]{Theorem 4.11}, the spectrum of $S$ is closed, hence $\sigma(S)=\left\{z\in\mathbb{C}:\vert z\vert\leq 1\right\}$.

In fact, $\sigma_p(S)=\left\{z\in\mathbb{C}:\vert z\vert< 1\right\}$ is then open unit disk, and $\sigma_c(S)=\left\{z\in\mathbb{C}:\vert z\vert= 1\right\}$ is the unit circle. To see this, let $\vert\lambda\vert=1$, and fix $(y_1,y_2,\cdots)\in l^2$. Given $\epsilon>0$, choose $n$ such that $\sum_{k=n+1}^\infty\vert y_k\vert^2 < \epsilon$, and choose the sequence
\begin{align*}
	x_k=\begin{cases}
		\sum_{j=0}^{n-k} \lambda^j y_{k+j},\ &k=1,\cdots,n.\\
		0,\ &k>n.
	\end{cases}
\end{align*}
Then $(x_1,x_2,\cdots)\in l^2$, and $(S-\lambda I)(x_1,x_2,\cdots) = (y_1,\cdots,y_n,0,\cdots)$. Therefore $(y_1,y_2,\cdots)\in\mathfrak{R}(S)$, and $\lambda\in\sigma_c(S)$.
\vspace{0.1cm}

(iii) Let $H$ be a Hilbert space, and let $U$ be a unitary operator on $H$. Clearly, $\Vert U\Vert = 1$, which implies $\sigma(U)\subset\left\{z\in\mathbb{C}:\vert z\vert\leq 1\right\}$. Then $\sigma(U^*)=\overline{\sigma(U)}\subset\left\{z\in\mathbb{C}:\vert z\vert\leq 1\right\}$, and $\sigma(U^{-1})\subset\left\{z\in\mathbb{C}:\vert z\vert\geq 1\right\}$. Note that $U^*=U^{-1}$, we conclude that $\sigma(U)\subset\left\{z\in\mathbb{C}:\vert z\vert= 1\right\}$.
\vspace{0.1cm}

(iv) Let $H$ be a Hilbert space, and let $T\in\mathfrak{B}(H)$ be a self-adjoint operator on $H$. Then $\sigma(T)=\overline{\sigma(T^*)} = \overline{\sigma(T)}$, which implies $\sigma(T)\subset\mathbb{R}$.\vspace{0.1cm}

(v) Let $H$ be a Hilbert space, and let $T\in\mathfrak{B}(H)$ be a normal operator on $H$. If there exists $\lambda\in\sigma_r(T)$, then $\overline{\lambda}\in\sigma_p(T^*)$, and there exists $x\neq 0$ such that $T^*x=\overline{\lambda}x$. By normality of $T$, 
\begin{align*}
	\ker(T-\lambda I) = \ker(T^* - \overline{\lambda} I) \neq 0,
\end{align*}
contradicting $\lambda\in\sigma_r(T)$! Hence $\sigma_r(T)=\emptyset$, and $\sigma(T)=\sigma_p(T)\amalg\sigma_c(T)$.

\paragraph{Example 4.14.\label{example:4.14}} Given a Lebesgue measurable function $\varphi\in L^\infty([0,1])$, we define $M_\varphi\in\mathfrak{B}(L^2([0,1]))$ by
\begin{align*}
	(M_\varphi f)(x) = \varphi(t) f(t),\ f\in L^2([0,1]), t\in[0,1].
\end{align*}
Clearly, $\Vert M_\varphi\Vert \leq\Vert \varphi\Vert_\infty$. To prove the other side, note that by choosing $E_\epsilon=\left\{x\in[0,1]:\vert \varphi(x)\vert\geq\Vert \varphi\Vert_\infty - \epsilon\right\}$, we have
\begin{align*}
	\Vert M_\varphi\chi_{E_\epsilon}\Vert_2 = \sqrt{\int_{E_\epsilon} \vert\varphi(x)\vert^2\,dx}\geq \left(\Vert\varphi\Vert_\infty - \epsilon\right)\sqrt{\mu(E_\epsilon)} = \left(\Vert\varphi\Vert_\infty - \epsilon\right)\Vert\chi_{E_\epsilon}\Vert_2,\ \forall\epsilon>0.
\end{align*}
Hence $\Vert M_\varphi\Vert=\Vert\varphi\Vert_\infty$, and $r(M_\varphi)\leq\Vert\varphi\Vert_\infty$. Now we determine the adjoint of $M_\varphi$:
\begin{align*}
	\langle M_\varphi f,g\rangle = \int_{[0,1]}\left(\varphi f\right)\overline{g}\,dm = \int_{[0,1]}f\,\overline{\left(\overline{\varphi}g\right)}\,dm = \langle f,M_{\overline{\varphi}}g\rangle,\ \forall f,g\in L^2([0,1]).
\end{align*}
Hence $M_\varphi^* = M_{\overline{\varphi}}$, and $M_\varphi$ is a normal operator on $L^2([0,1])$. As a result, $\sigma(M_\varphi)=\sigma_p(M_\varphi)\amalg\sigma_c(M_\varphi)$.
\vspace{0.1cm}

Now let's find the spectrum of $M_\varphi$. We define the essential range of $\varphi\in L^\infty([0,1])$ as
\begin{align*}
	\mathrm{ess}\,\mathrm{ran}\,\varphi = \left\{\lambda\in\mathbb{C}:\ m\left(\{\vert \varphi(x)-\lambda\vert <\epsilon\}\right)\neq 0,\ \forall\epsilon>0\right\}
\end{align*}

If $\mu\notin\mathrm{ess}\,\mathrm{ran}\,\varphi$, there exists $\epsilon>0$ such that $m(E_\mu^\epsilon)=0$, where $E_\mu^\epsilon=\left\{x\in[0,1]:\vert \varphi(x)-\mu\vert < \epsilon\right\}$. Let $f\in L^2([0,1])$ be given, we define
\begin{align*}
	g_f(x)=\begin{cases}
		\frac{f(x)}{\varphi(x)-\mu},\ & x\notin E_\mu^\epsilon\\
		0,\ & x\in E_\mu^\epsilon
	\end{cases}\ \Rightarrow\ \int_{[0,1]} \vert g_f\vert^2\,dm\leq\int_{x\notin E_\mu^\epsilon} \left\vert \frac{f(x)}{\varphi(x)-\mu}\right\vert^2\,dx \leq\frac{\Vert f\Vert^2_2}{\epsilon^2} < \infty.\tag{4.3}\label{eq:4.3}
\end{align*}
Define $T:L^2([0,1])\to L^2([0,1]),\ f\mapsto g_f$. By \hyperref[eq:4.3]{(4.3)}, $T$ is linear and bounded: $\Vert T\Vert < \epsilon^{-1}$. Furthermore, we have $T(M_\varphi - \mu I) = (M_\varphi - \mu I) T = I$. Therefore, $\mu\in\rho(M_\varphi)$.\vspace{0.1cm}

Conversely, if $\mu\in\rho(M_\varphi)$, then for all $g\in L^2([0,1])$, there exists $f\in L^2([0,1])$ such that $(M_\varphi-\mu I) f = g$. In other words, $\frac{g}{\varphi-\mu}\in L^2([0,1])$. We prove that $\frac{1}{\varphi - \mu}\in L^\infty([0,1])$. If not, then
\begin{align*}
	m\biggl(\underbrace{\left\{\left\vert\frac{1}{\varphi-\mu}\right\vert\geq n\right\}}_{=:E_n}\biggr) >0,\ \forall n\in\mathbb{N}.
\end{align*}
Clearly, $\frac{1}{\varphi-\mu}\in L^2([0,1])$, which implies $\lim_{n\to\infty}m(E_n)=0$. Then we can choose a subsequence such that $m(E_{n_k}\backslash E_{n_{k+1}})>0$, and define $g\in L^2([0,1])$ as follows:
\begin{align*}
	g = \sum_{k=1}^\infty\frac{\chi_{E_{n_k}\backslash E_{n_{k+1}}}}{n_k\sqrt{m(E_{n_k}\backslash E_{n_{k+1}})}}\ \Rightarrow\ \int_{[0,1]}\vert g\vert^2\,dm \leq \sum_{k=1}^\infty \frac{1}{n_k^2}\leq\sum_{n=1}^\infty\frac{1}{n^2} =\frac{\pi^2}{6}.
\end{align*}
However,
\begin{align*}
	\int_{[0,1]}\left\vert\frac{g}{\varphi-\mu}\right\vert^2 dm =\sum_{k=1}^\infty \frac{\int_{E_{n_k}\backslash E_{n_{k+1}}}\frac{1}{\vert\varphi-\mu\vert^2}\,dm}{n_k^2\, m(E_{n_k}\backslash E_{n_{k+1}})} \geq \sum_{k=1}^\infty \frac{n_k^2\, m(E_{n_k}\backslash E_{n_{k+1}})}{n_k^2\, m(E_{n_k}\backslash E_{n_{k+1}})} = \infty,
\end{align*}
a contradiction! Hence $\frac{1}{\varphi-\mu}\in L^\infty([0,1])$, which implies $\mu\notin\mathrm{ess}\,\mathrm{ran}\,\varphi$. Therefore, $\sigma(M_\varphi)=\mathrm{ess}\,\mathrm{ran}\,\varphi$.\vspace{0.1cm}

Finally we determine the point spectrum of $M_\varphi$. If $\lambda\in\sigma_p(M_\varphi)$, there exists $f\in L^2([0,1])$ such that $m(\{f\neq 0\})>0$ and $(M_\varphi - \lambda I)f=0$, which implies $m(\{x\in[0,1]:\varphi(x)=\lambda\})\geq m(\{f\neq 0\})>0$. Conversely, if $m(\{x\in[0,1]:\varphi(x)=\lambda\})>0$, we have $(M_\varphi-\lambda I)\chi_{\{\varphi(x)=\lambda\}} = 0$, which implies $\lambda\in\sigma_p(M_\varphi)$. Hence 
\begin{align*}
	\sigma_p(M_\varphi)=\{\lambda\in\mathbb{C}:m(\{x\in[0,1]:\varphi(x)=\lambda\}>0\}.
\end{align*}
Since $\sigma(M_\varphi)=\sigma_p(M_\varphi)\amalg\sigma_c(M_\varphi)$, we can obtain $\sigma_c(M_\varphi)$ by choose the complement.

\paragraph{Theorem 4.15.\label{thm:4.15}} Let $X$ be a Banach space, $T\in\mathfrak{B}(X)$. Given $f\in\mathfrak{B}(X)^*$, define $F:\rho(T)\to\mathbb{C}$ by
\begin{align*}
	F(\lambda) = f\left((T-\lambda I)^{-1}\right).
\end{align*}
Then $F$ is analytic on $\rho(T)$.
\begin{proof}
For all $\lambda,\mu\in\rho(T)$, we have $(T-\lambda I)^{-1} - (T-\mu I)^{-1} = (\lambda-\mu)(T-\lambda I)^{-1}(T-\mu I)^{-1}$. Then $F$ is differentiable on $\rho(T)$:
\begin{align*}
	\lim_{\lambda\to\lambda_0} \frac{f\left((T-\lambda I)^{-1}\right)-f\left((T-\lambda_0 I)^{-1}\right)}{\lambda-\lambda_0} = f\left((T-\lambda_0 I)^{-2}\right).
\end{align*}
Since $\rho(T)$ is open, $F$ is analytic on $\rho(T)$. 
\end{proof}

\paragraph{Corollary 4.16.\label{cor:4.16}} Let $X$ be a Banach space, and $T\in\mathfrak{B}(X)$. Then $\sigma(T)\neq\emptyset$.
\begin{proof}
If $\sigma(T)=\emptyset$, $\rho(T)=\mathbb{C}$. Given $f\in\mathfrak{B}(X)^*$, let $F(\lambda)=f\left((T-\lambda I)^{-1}\right)$. While $\vert\lambda\vert > \Vert T\Vert$,
\begin{align*}
	(T-\lambda I)^{-1} = -\sum_{n=0}^\infty\frac{T^n}{\lambda^{n+1}}\ \Rightarrow\ \left\Vert(T-\lambda I)^{-1}\right\Vert\leq\sum_{n=0}^\infty\frac{\Vert T\Vert^n}{\vert\lambda\vert^{n+1}}\leq\frac{1}{\vert\lambda\vert - \Vert T\Vert},
\end{align*}
\begin{align*}
	F(\lambda)=f\left((T-\lambda I)^{-1}\right)\leq\left\Vert f\right\Vert\left\Vert(T-\lambda I)^{-1}\right\Vert \leq\frac{\Vert f\Vert}{\vert\lambda\vert - \Vert T\Vert}\ \Rightarrow\ \lim_{\lambda\to\infty} F(\lambda) = 0.
\end{align*}
Since $F$ is analytic on $\mathbb{C}$, by Liouville's theorem, $F\equiv 0$. Then for all $\lambda\in\mathbb{C}$, $f\left((T-\lambda I)^{-1}\right)=0$ for all $f\in\mathfrak{B}(X)^*$. By Hahn-Banach theorem, $\left(T-\lambda I\right)^{-1}=0$, a contradiction!
\end{proof}

It is seen that any bounded linear operator on Banach spaces has non-empty compact spectrum. Using the Laurent series, we obtain the exact formula for spectral radii.

\paragraph{Theorem 4.17\label{thm:4.17}} (Gelfand). Let $X$ be a Banach space, and $T\in\mathfrak{B}(X)$. Then
\begin{align*}
	r(T) = \lim_{n\to\infty}\Vert T^n\Vert^{1/n}.
\end{align*}
\begin{proof}
\textit{Step I:} Let $a=\inf_{n\geq 1}\Vert T^n\Vert^{1/n}$. We claim that $\lim_{n\to\infty}\Vert T^n\Vert^{1/n}=a$.

By definition, for all $\epsilon>0$, there exists $m\geq 1$ such that $\Vert T^m\Vert^{1/m}<a+\epsilon$. For all $n\in\mathbb{N}$, let $n=km+l$ where $k\in\mathbb{N}_0$ and $l\in\{0,1,\cdots,m-1\}$. Then
\begin{align*}
	\Vert T^n\Vert^{1/n}\leq\left(\Vert T^m\Vert^k\left\Vert T\right\Vert^l\right)^{1/n}\leq(a+\epsilon)^{km/n}\Vert T\Vert^{l/n}
\end{align*}
Let $n\to\infty$, we have $\limsup_{n\to\infty}\Vert T^n\Vert^{1/n}\leq a+\epsilon$ for all $\epsilon>0$. Hence
\begin{align*}
	a\leq\liminf_{n\to\infty}\Vert T^n\Vert^{1/n}\leq\limsup_{n\to\infty}\Vert T^n\Vert^{1/n}\leq a.
\end{align*}

\textit{Step II:} If $\vert\lambda\vert > a$, we have
\begin{align*}
	\lim_{n\to\infty}\left(\frac{\Vert T^n\Vert}{\vert\lambda\vert^{n+1}}\right)^{1/n} = \frac{a}{\vert\lambda\vert} < 1.
\end{align*}
Then $S=-\sum_{n=1}^\infty\frac{T^n}{\lambda^{n+1}}$ converges in norm, and $S(T-\lambda I)=(T-\lambda I)S= I$. Hence $\lambda\in\rho(T)$ for all $\vert\lambda\vert > a$, which implies $r(T)\leq a=\lim_{n\to\infty}\Vert T^n\Vert^{1/n}$. Furthermore,
\begin{align*}
	(T-\lambda I)^{-1}=-\sum_{n=1}^\infty\frac{T^n}{\lambda^{n+1}},\ \vert\lambda\vert > a.
\end{align*}

\textit{Step III:} We prove the other side. For all $f\in\mathfrak{B}(X)^*$, use Laurent series:
\begin{align*}
	f\left((T-\lambda I)^{-1}\right) = -\sum_{n=1}^\infty\frac{f(T^n)}{\lambda^{n+1}},\ \vert\lambda\vert > a. \tag{4.4}\label{eq:4.4}
\end{align*}
By uniqueness of Laurent series, \hyperref[eq:4.4]{(4.4)} holds for all $\vert\lambda\vert > r(T)$. Hence for all $\epsilon>0$,
\begin{align*}
	\sum_{n=1}^\infty\frac{\vert f(T^n)\vert}{\left(r(T)+\epsilon\right)^{n+1}} < \infty.
\end{align*}

Let $U_n = \frac{T^n}{(r(T)+\epsilon)^{n+1}}$. Since $\sup_{n\geq 1}\vert f(U_n)\vert<\infty$ holds for all $f\in\mathfrak{B}(X)^*$, by Banach-Steinhaus theorem, there exists $M>0$ such that $\sup_{n\geq 1}\Vert U_n\Vert \leq M$. Hence
\begin{align*}
	\Vert T^n\Vert\leq M\left(r(T)+\epsilon\right)^{n+1}
\end{align*}
for all $n\in\mathbb{N}$, and $\lim_{n\to\infty}\Vert T^n\Vert^{1/n}\leq r(T)+\epsilon$. Let $\epsilon\to 0$, we have $\lim_{n\to\infty}\Vert T^n\Vert^{1/n}\leq r(T)$, as desired.
\end{proof}

Now we show some applications of Gelfand spectral radius theorem.
\paragraph{Corollary 4.18\label{cor:4.18}} (F. Riesz). Let $S$ and $T$ be bounded linear operators on a Banach space $X$.
\begin{itemize}
	\vspace{0.1cm}
	\item[(i)] $r(ST)=r(TS)$. 
	\vspace{0.1cm}
	\item[(ii)] if $ST=TS$, then $r(S+T)\leq r(S)+r(T)$.
\end{itemize} 
\begin{proof}
(i) Using \hyperref[thm:4.17]{Theorem 4.17}, we have
\begin{align*}
	r(ST)=\lim_{n\to\infty}\Vert(ST)^n\Vert^{1/n} = \lim_{n\to\infty}\Vert S(TS)^{n-1}T\Vert^{1/n} = \lim_{n\to\infty}\left\Vert S\right\Vert^{1/n}\left\Vert (TS)^{n-1}\right\Vert^{1/n}\left\Vert T\right\Vert^{1/n} = r(TS).
\end{align*}
Similarly, we have $r(TS)\leq r(ST)$, which concludes the proof of (i).\vspace{0.1cm} 

(ii) Suppose $ST=TS$. Given $\epsilon>0$, we choose $M>0$ such that $\Vert S^n\Vert^{1/n} < r(S)+\epsilon$ and $\Vert T^n\Vert^{1/n} < r(T)+\epsilon$ for all $n> M$. For sufficiently large $n$, we have
\begin{align*}
	\Vert (S+T)^n\Vert&\leq\sum_{k=0}^n {n\choose k}\left\Vert S^k\right\Vert\left\Vert T^{n-k}\right\Vert\\
	&\leq \sum_{k=0}^{M} {n\choose k}\Vert S\Vert^k\left(r(T)+\epsilon\right)^{n-k} + \sum_{k=M+1}^{n-M-1} {n\choose k}\left(r(S)+\epsilon\right)^k\left(r(T)+\epsilon\right)^{n-k}\\
	&\quad + \sum_{k=n-M}^{n} {n\choose k}\left(r(S)+\epsilon\right)^k\Vert T\Vert^{n-k}\\
	&\leq \sum_{k=0}^{M} {n\choose k}\left(\frac{\Vert S\Vert}{r(S)+\epsilon}\right)^k\left(r(S)+\epsilon\right)^k\left(r(T)+\epsilon\right)^{n-k} + \sum_{k=M+1}^{n-M-1} {n\choose k}\left(r(S)+\epsilon\right)^k\left(r(T)+\epsilon\right)^{n-k}\\
	&\quad + \sum_{k=n-M}^{n} \left(\frac{\Vert T\Vert}{r(T)+\epsilon}\right)^{n-k}{n\choose k}\left(r(S)+\epsilon\right)^k\left(r(T)+\epsilon\right)^{n-k}\\
	&\leq\underbrace{\max\left\{\max_{0\leq k\leq M}\left(\frac{\Vert S\Vert}{r(S)+\epsilon}\right)^k,\ 1,\ \max_{0\leq k\leq M}\left(\frac{\Vert T\Vert}{r(T)+\epsilon}\right)^k\right\}}_{=:L}\sum_{k=0}^n{n\choose k}\left(r(S)+\epsilon\right)^k\left(r(T)+\epsilon\right)^{n-k}\\
	&= L\left(r(S)+r(T)+2\epsilon\right)^n,
\end{align*}
where $L$ is a constant independent of $n$. Let $n\to\infty$, we have $r(S+T)\leq r(S)+r(T)+2\epsilon$. Since $\epsilon>0$ is arbitrary, the result follows when $\epsilon\to 0$.
\end{proof}

\paragraph{Remark.} (i) In fact, we have $\sigma(ST)\backslash\{0\}=\sigma(TS)\backslash\{0\}$. To see this, note that
\begin{align*}
	(I-ST)\left(I+S(I-TS)^{-1}T\right) = \left(I+S(I-TS)^{-1}T\right)(I-ST) = I,\\
	(I-TS)\left(I+T(I-ST)^{-1}S\right) = \left(I+T(I-ST)^{-1}S\right)(I-TS) = I.
\end{align*}
Hence $I-ST$ is invertible if and only if $I-TS$ is invertible.  As a result, for all $\lambda\neq 0$,  $ST-\lambda I$ is invertible if and only if $TS-\lambda I$ is invertible.
\vspace{0.1cm} 

(ii) The second statement in \hyperref[cor:4.18]{Corollary 4.18} fails when $S$ and $T$ are not commutable, i.e. $ST\neq TS$. For instance, consider $$S=\begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix},\quad T=\begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix},$$ which are linear operators on $\mathbb{C}^2$. Then $r(S)=r(T)=0$, but $r(S+T)=1$.

\paragraph{Corollary 4.19.\label{cor:4.19}} Let $H$ be a Hilbert space, and let $T\in\mathfrak{B}(H)$ be a normal operator on $H$. Then $r(T)=\Vert T\Vert$.
\begin{proof}
First, let $T$ be self-adjoint. Then $\Vert T\Vert^2 = \Vert T^*T\Vert = \Vert T^2\Vert$, and $T^2$ is also self-adjoint. By induction,
\begin{align*}
	\Vert T\Vert^2 = \Vert T^2\Vert\ \Rightarrow\ \Vert T\Vert^4 = \Vert T^4\Vert\ \Rightarrow\ \cdots\ \Rightarrow\ \Vert T\Vert^{2^k} = \bigl\Vert T^{2^k}\bigr\Vert,\ \forall k\in\mathbb{N}.
\end{align*}
Hence $r(T)=\lim_{k\to\infty}\bigl\Vert T^{2^k}\bigr\Vert^{1/2^k} = \Vert T\Vert$. Now let $T$ be normal. If $(T^n)^*T^n = (T^*T)^n$, then
\begin{align*}
	(T^{n+1})^*T^{n+1} = T^*(T^n)^*T^n T = T^*(T^*T)^nT = T^*(TT^*)^nT = (T^*T)^{n+1}.
\end{align*}
By induction, $(T^n)^*T^n = (T^*T)^n$ for all $n\in\mathbb{N}$. Furthermore, we have
\begin{align*}
r(T)^2=\lim_{n\to\infty}\Vert T^n\Vert^{2/n} = \lim_{n\to\infty}\Vert (T^n)^*T^n\Vert^{1/n}  =\lim_{n\to\infty}\Vert (T^*T)^n\Vert^{1/n} = r(T^*T).
\end{align*}
Since $T^*T$ is self-adjoint, $r(T^*T)=\Vert T^*T\Vert = \Vert T\Vert^2$. Hence $r(T)=\Vert T\Vert$.
\end{proof}

\paragraph{Example 4.20.\label{example:4.20}} Suppose $f\in C([a,b])$, and $K\in C(\mathcal{D})$, where $\mathcal{D}=\left\{(x,y)\in\mathbb{R}^2: a\leq x\leq b, a\leq y\leq x\right\}$. Define $T:C([a,b])\to C([a,b])$ by
\begin{align*}
	(Tf)(x):=\int_a^x K(x,y)f(y)\,dy,\ \forall f\in C([a,b]),
\end{align*}
Following \hyperref[example:1.69]{Example 1.69},
\begin{align*}
	\left\vert(T^n f)(x)\right\vert \leq \frac{1}{n!}M^n(x-a)^n\Vert f\Vert_\infty,\ \forall x\in[a,b].
\end{align*}
where $M=\sup_{(x,y)\in\mathcal{D}}\vert K(x,y)\vert$. As a result,
\begin{align*}
	r(T) = \lim_{n\to\infty}\Vert T^n\Vert^{1/n} \leq \lim_{n\to\infty}\frac{M(b-a)}{\sqrt[n]{n!}} = 0.
\end{align*}
Since $\sigma(T)\neq\emptyset$, we have $\sigma(T)=\{0\}$.
\newpage

\subsection{Compact Operators}
\subsubsection{Finite-rank Operators and Compact Operators}
\paragraph{Definition 4.21\label{def:4.21}} (Finite-rank operators). Let $X$ and $Y$ be vector spaces, and let $T:X\to Y$ be a linear operator. $T$ is said to be a \textit{finite-rank operator} if $TX$ is a finite-dimensional subspace of $Y$.

\paragraph{Remark.} By definition, if $Y$ is finite-dimensional, all linear operators from $X$ into $Y$ are of finite rank.

\paragraph{Proposition 4.22.\label{prop:4.22}} Let $X$ and $Y$ be vector spaces, and let $T:X\to Y$ be a linear operator. Then $T$ is a finite-rank operator if and only if there exist linear functionals $f_1,\cdots,f_n$ on $X$ and linear independent vectors $y_1,\cdots,y_n$ of $Y$ such that
\begin{align*}
	Tx = \sum_{j=1}^n f_j(x)\,y_j,\ \forall x\in X.
\end{align*}
\begin{proof}
We only show the ``only if'' case, since the other direction is trivial. Let $T:X\to Y$ be a finite rank operator. We choose a basis $\{y_1,\cdots,y_n\}$ of $TX$. Then for all $x\in X$, there exist uniquely determined $f_1(x),\cdots,f_n(x)\in\mathbb{F}$ such that $Tx=\sum_{j=1}^n f_j(x)\,y_j$. It remains to verify $f_j$ is linear for each $j$.

Given $x,x^\prime\in X$ and $\alpha,\beta\in\mathbb{F}$, we have
\begin{align*}
	T(\alpha x_1 + \beta x_2) = \alpha Tx_1 + \beta Tx_2\ \Rightarrow\ \sum_{j=1}^n f_j(\alpha x_1+\beta x_2)y_j = \sum_{j=1}^n \left(\alpha f_j(x_1) + \beta f_j(x_2)\right)y_j.
\end{align*}
Since $y_1,\cdots,y_n$ are linearly independent, $f_j(\alpha x_1+\beta x_2)=\alpha f_j(x_1) + \beta f_j(x_2)$ for each $j$. Hence $f_j$ is linear.
\end{proof}

\paragraph{Proposition 4.23.\label{prop:4.23}} Let $X$ and $Y$ be normed spaces, and let $T:X\to Y$ be a linear operator. Then $T$ is a bounded finite-rank operator if and only if there exist bounded linear functionals $f_1,\cdots,f_n\in X^*$ and linear independent vectors $y_1,\cdots,y_n$ of $Y$ such that
\begin{align*}
	Tx = \sum_{j=1}^n f_j(x)\,y_j,\ \forall x\in X.
\end{align*}
\begin{proof}
``$\Leftarrow$'': Clearly $T$ is of finite rank. Furthermore, $\Vert Tx\Vert\leq\sum_{j=1}^n\left\Vert f_j\right\Vert\left\Vert y_j\right\Vert\left\Vert x\right\Vert$.

``$\Rightarrow$'': By \hyperref[prop:4.22]{Proposition 4.22}, there exist linear functionals $f_1,\cdots,f_n$ on $X$ and points $y_1,\cdots,y_n$ of $Y$ such that $Tx=\sum_{j=1}^n f_j(x)\,y_j$ for all $x\in X$. It remains to show $f_j$ is bounded for all $j\in\{1,\cdots,n\}$.

Let $L_{-j}=\mathrm{span}\,\{y_1,\cdots,y_{j-1},y_{j+1},\cdots,y_n\}$. By Hahn-Banach theorem, there exists $f\in Y^*$ such that $f(L_{-j})=0$, and $f(y_j)=1$. Then
\begin{align*}
	f(Tx) = f\Biggl(\sum_{j=1}^n f_j(x)\,y_j\Biggr) = f_n(x),\ \forall x\in X.
\end{align*}
As a result, $f_n=f\circ T\in X^*$.
\end{proof}

\paragraph{Example 4.24\label{example:4.24}} (Finite-rank operators on infinite-dimensional spaces). Let $X$ be an infinite-dimensional Banach space, and let $T\in\mathfrak{B}(X)$ be a finite-rank operator. By \hyperref[prop:4.23]{Proposition 4.23}, there exist $\alpha_1,\cdots,\alpha_n\in X^*$ and linear independent vectors $x_1,\cdots,x_n\in X$ such that
\begin{align*}
	Tx = \sum_{j=1}^n\alpha_j(x)\,x_j,\ \forall x\in X.
\end{align*}

To find the eigenvalues of $T$, we solve the equation $Tx=\lambda x$. If $\lambda=0$, we have $\alpha_1(x)=\cdots=\alpha_n(x)=0$. For each $j$, the induced map $\tilde{\alpha}_j:X/\ker\alpha_j\to\mathbb{C},\ [x]\mapsto \alpha_j(x)$ is an injection into $\mathbb{C}$, which implies
\begin{align*}
	\mathrm{codim} \ker\alpha_j=\dim(X/\ker\alpha_j)\leq 1\ \Rightarrow\ \mathrm{codim}\left(\bigcap_{j=1}^n\ker\alpha_j\right)\leq\sum_{j=1}^n\mathrm{codim}\ker\alpha_j\leq n.
\end{align*}
Hence $\bigcap_{j=1}^n\ker\alpha_j$ is an infinite-dimensional subspace of $X$. As a result, there exists nonzero $x\in\bigcap_{j=1}^n\ker\alpha_j$ such that $Tx=0$, which implies $0\in\sigma_p(T)$. \vspace{0.1cm}

If $\lambda\neq 0$, we have $x\in\mathrm{span}\left\{x_1,\cdots,x_n\right\}$, because
\begin{align*}
	x = \frac{1}{\lambda} Tx = \sum_{j=1}^n \beta_j x_j,\ \beta_j = \frac{\alpha_j(x)}{\lambda},\ j=1,\cdots,n.\tag{4.5}\label{eq:4.5}
\end{align*}
Plugging \hyperref[eq:4.5]{(4.5)} into $Tx=\lambda x$, we have
\begin{align*}
	 \sum_{j=1}^n\lambda\beta_j x_j = \sum_{k=1}^n \beta_k Tx_k = \sum_{k=1}^n\sum_{j=1}^n\beta_k\alpha_j(x_k) x_j\ \Rightarrow\ \lambda\beta_j = \sum_{k=1}^n\alpha_j(x_k)\beta_k.
\end{align*}
Hence $\lambda$ is an eigenvalue of matrix $A=(A_{jk})_{n\times n}=\left(\alpha_j(x_k)\right)_{n\times n}$, and $\beta=(\beta_1,\cdots,\beta_n)^\top$ is the associated eigenvector. Conversely, if $(\lambda,\beta)$ is an eigenpair of matrix $A$, we have
\begin{align*}
	T\left(\sum_{j=1}^n\beta_j x_j\right) = \sum_{j=1}^n\sum_{k=1}^n\beta_j\alpha_k(x_j)x_k = \left(x_1,\cdots,x_n\right)A\beta = \lambda\left(x_1,\cdots,x_n\right)\beta = \lambda\left(\sum_{j=1}^n\beta_j x_j\right).
\end{align*}
Hence $\sigma_p(T)=\sigma_p(A)\cup\{0\}$.

\paragraph{Definition 4.25\label{def:4.25}} (Compact operators). Let $X$ and $Y$ be normed spaces, and let $T:X\to Y$ be a linear operator. Then $T$ is said to be a \textit{compact operator} if $T$ maps every bounded subset of $X$ to a relatively compact subset of $Y$, i.e., for all $A\subset X$ such that $\sup_{x\in A}\Vert x\Vert < \infty$, $\overline{TA}$ is a compact subset of $Y$.

\paragraph{Remark.} By definition, a compact operator is automatically bounded, since it maps bounded subsets to bounded subsets.

\paragraph{Lemma 4.26.\label{lemma:4.26}} Bounded linear finite-rank operators are compact operators.
\begin{proof}
Let $X$ and $Y$ be normed spaces, and let $T\in\mathfrak{B}(X,Y)$ be finite-rank linear operators. Then $TX$ is a finite-dimensional subspace of $Y$. By \hyperref[thm:1.56]{Theorem 1.56}, $TX$ is complete.

Let $A$ be a bounded subset of $X$, then $TA$ is a bounded subset of $TX$. Since $TX$ is finite-dimensional, all bounded subsets of $TX$ are totally bounded, hence relatively compact.
\end{proof}

\paragraph{Example 4.27} (Fredholm integral operators). Given $K\in C([a,b]\times[a,b])$, define the corresponding Fredholm operator $T_K:C([a,b])\to C([a,b])$ as follows:
\begin{align*}
	(T_K\varphi)(x)=\int_a^b K(x,y)\varphi(y)\,dy,\ \forall \varphi\in C([a,b]).
\end{align*}
Then $T_K$ is a compact operator. To prove this, let $\mathcal{A}$ be a bounded subset of $C([a,b])$. By Arzelà-Ascoli theorem (\hyperref[thm:1.77]{Theorem 1.77}), it suffices to show that $T_K\mathcal{A}$ is bounded and uniformly equicontinuous. 

Choose $M>0$ such that $\Vert\varphi\Vert_\infty\leq M$ for all $\varphi\in\mathcal{A}$. Then
\begin{align*}
	\Vert T_K\varphi\Vert_\infty = \sup_{x\in[a,b]}\left\vert\int_a^b K(x,y)\varphi(y)\,dy\right\vert\leq (b-a)\left\Vert K\right\Vert_\infty\left\Vert\varphi\right\Vert_\infty \leq (b-a)M\left\Vert K\right\Vert_\infty,\ \forall\varphi\in\mathcal{A}.
\end{align*}
Hence $T_K\mathcal{A}$ is bounded. Furthermore,
\begin{align*}
	\vert (T_K\varphi)(x) - (T_K\varphi)(x^\prime)\vert &= \left\vert\int_a^b \left(K(x,y)-K(x^\prime,y)\right)\varphi(y)\,dy\right\vert\\
	&\leq \left\vert\int_a^b \left(K(x,y)-K(x^\prime,y)\right)dy\right\vert\left\Vert\varphi\right\Vert_\infty.\tag{4.6}\label{eq:4.6}
\end{align*}
Note that $K$ is uniformly continuous. Given $\epsilon>0$, choose $\delta>0$ such that $\vert K(x,y) - K(x^\prime,y)\vert < \frac{\epsilon}{M(b-a)}$ for all $x,x^\prime\in[a,b]$ such that $\vert x-x^\prime\vert < \delta$ and all $y\in[a,b]$. By \hyperref[eq:4.6]{(4.6)}, we have $\vert (T_K\varphi)(x) - (T_K\varphi)(x^\prime)\vert < \epsilon$ for all $\varphi\in\mathcal{A}$. Hence $T_K\mathcal{A}$ is equicontinuous.

\paragraph{Theorem 4.28.\label{thm:4.28}} Let $X$, $Y$ and $Z$ be normed spaces. Denote by $\mathcal{K}(X,Y)$ the set of all compact operators from $X$ into $Y$. Then:
\begin{itemize}
	\vspace{0.1cm}
	\item[(i)] $\mathcal{K}(X,Y)$ is a linear subspace of $\mathfrak{B}(X,Y)$.
	\vspace{0.1cm}
	\item[(ii)] $\mathfrak{B}(Y,Z)\circ\mathcal{K}(X,Y)\subset\mathcal{K}(X,Z)$, and $\mathcal{K}(X,Y)\circ\mathfrak{B}(Z,X)\subset\mathcal{K}(Z,Y)$.
	\vspace{0.1cm}
	\item[(iii)] If $Y$ is a Banach space, then $\mathcal{K}(X,Y)$ is a closed subspace of $Y$.
\end{itemize}
\begin{proof}
(i) Let $S,T\in\mathcal{K}(X,Y)$, and $\alpha\in\mathbb{C}$. Clearly, $\alpha S\in\mathcal{K}(X,Y)$. To show that $S+T\in\mathcal{K}(X,Y)$, let $A$ be a bounded subset of $X$, and choose a sequence $(x_n)$ of points of $A$. Since $TA$ is relatively compact, we can find a subsequence $(x_{n_k})$ that $Sx_{n_k}$ converges in $Y$. Also, we choose a subsequence $(x_{n_k^\prime})$ of $(x_{n_k})$ such that $Tx_{n^\prime_k}$ converges in $Y$. Hence $\left(S+T\right)x_{n_k^\prime}$ converges in $Y$, and $(S+T)A$ is relatively compact.\vspace{0.1cm}

(ii) Let $S\in\mathcal{K}(X,Y)$, and $T\in\mathfrak{B}(Y,Z)$. If $A\subset X$ is bounded, then $SA\subset Y$ is relatively compact. Since $T$ is continuous, $T(SA)\subset Z$ is relatively compact. Hence $TS\in\mathcal{K}(X,Z)$.

Now let $S\in\mathfrak{B}(Z,X)$, and $T\in\mathcal{K}(X,Y)$. If $B\subset Z$ is bounded, then $SB\subset Z$ is also bounded, and $T(SB)\subset Y$ is relatively compact. Hence $TS\in\mathcal{K}(Z,Y)$.\vspace{0.1cm}

(iii) Clearly, $\mathfrak{B}(X,Y)$ is a Banach space. Let $T_n:X\to Y$ be a sequence of compact operators that converges to $T\in\mathfrak{B}(X,Y)$. It suffices to show that $T\in\mathcal{K}(X,Y)$: Let $A$ be a bounded subset of $X$ such that $L=\sup_{x\in A}\Vert x\Vert> 0$. We prove that $TA$ is totally bounded.

Given $\epsilon>0$, we choose $N>0$ such that $\Vert T_n - T\Vert <\frac{\epsilon}{3L}$ for all $n\geq N$. By definition, $T_NA$ is totally bounded, so we choose an $\epsilon/3$-net $\{T_Nx_1,\cdots,T_Nx_m\}$ of $T_NA$. Then $\{Tx_1,\cdots,Tx_m\}$ is an $\epsilon$-net of $TA$: for each $x\in A$, choose $x_k$ such that $\Vert T_Nx - T_Nx_k\Vert < \epsilon/3$, hence
\begin{align*}
	\Vert Tx - Tx_k\Vert &\leq \Vert Tx - T_N x\Vert + \Vert T_N x - T_N x_k\Vert + \Vert T_N x_k - Tx_k\Vert\\
	&\leq \left\Vert T-T_N\right\Vert\left\Vert x\right\Vert + \Vert T_N x - T_N x_k\Vert + \left\Vert T-T_N\right\Vert\left\Vert x_k\right\Vert\\
	&< \frac{\epsilon}{3L} L + \frac{\epsilon}{3} + \frac{\epsilon}{3L} L = \epsilon
\end{align*}
Therefore $TA$ is totally bounded, and $T$ is a compact operator.
\end{proof}

\paragraph{Corollary 4.29.\label{cor:4.29}} Let $X$ be a normed space, let $Y$ be a Banach space, and let $T_n:X\to Y$ be a sequence of bounded finite-rank operators. If $T_n\to T\in\mathfrak{B}(X,Y)$ in norm, $T$ is a compact operator.
\begin{proof}
By \hyperref[thm:4.28]{Theorem 4.28 (iii)}.
\end{proof}

\paragraph{Review: separable Hilbert spaces.} Recall that every Hilbert space $H$ has an orthonormal basis $\{e_\lambda,\lambda\in\Lambda\}$ such that $H=\overline{\mathrm{span}}\left\{e_\lambda,\lambda\in\Lambda\right\}$. If $H$ is separable, we take a countable dense subset $Q$ of $H$. For every $x\in Q$, there are at most countably many basis element $e_\lambda$ such that $\langle x,e_\lambda\rangle\neq 0$. Take $E_x = \left\{e_\lambda:\langle x,e_\lambda\rangle\neq 0\right\}$, then $x\in\overline{\mathrm{span}}\,E_x$. Furthermore, $E=\bigcup_{x\in Q} E_x$ is a countable basis of $H$:
\begin{align*}
	Q\subset\overline{\mathrm{span}}\,E\ \Rightarrow\ H=\overline{Q} = \overline{\mathrm{span}}\,E.
\end{align*}
Therefore, every separable Hilbert space $H$ has a countable basis $\{e_n,n\in\mathbb{N}\}$.

\paragraph{Remark.} Let $X$ be a Banach space, and $T\in\mathfrak{B}(X)$. If $T$ is a compact operator, so is $T^2$. Conversely, even if $T^2$ is a compact operator, $T$ is possibly not a compact operator.

Here is a counterexample. Let $H_1$ and $H_2$ be two infinite-dimensional separable Hilbert spaces. Let $\{e_n,n\in\mathbb{N}\}$ be an orthonormal basis of $H_1$, and $\{f_n,n\in\mathbb{N}\}$ an orthonormal basis for $H_2$. Define
\begin{align*}
	T = \overset{H_1\ H_2}{\begin{pmatrix}
			0 & 1\\ 0 & 0
	\end{pmatrix}},\ \text{i.e.}\ Te_n = 0,\ Tf_n=e_n,\ \forall n\in\mathbb{N}.
\end{align*}
Clearly, $T^2=0$ is a compact operator. However, $T$ maps unit ball in $H_2$ to unit ball in $H_1$, which is not relatively compact! Hence $T$ is not a compact operator.

\paragraph{Corollary 4.30.\label{cor:4.30}} Let $H$ be a separable Hilbert space, and $T\in\mathfrak{B}(H)$. Then $T$ is a compact operator if and only if $T$ is the limit of a sequence of bounded finite-rank operators.
\begin{proof}
Following \hyperref[cor:4.29]{Corollary 4.29}, it suffices to show the ``only if'' case. Let $T\in\mathcal{K}(H)$, and let $\{e_n,n\in\mathbb{N}\}$ be a basis of $H$. Define $P_n$ to be the projection operator from $H$ into the subspace $\mathrm{span}\left\{e_1,\cdots,e_n\right\}$, i.e.
\begin{align*}
	P_nx=\sum_{j=1}^n\langle x,e_j\rangle e_j,\ \forall x\in H.
\end{align*}
Clearly, $P_nT$ is a sequence of bounded finite-rank operators. It remains to show that $P_nT\to T$ in norm. Since $T$ is a compact operator, $TB(0,1)$ is relatively compact, hence totally bounded. Given $\epsilon>0$, we choose a $\epsilon/2$-net $\{Tx_1,\cdots,Tx_m\}$ of $TB(0,1)$, where $x_1,\cdots,x_m\in B(0,1)$. Then there exists $N>0$ such that $\Vert (I-P_n)Tx_j\Vert < \epsilon/2$ for all $j\in\{1,\cdots,m\}$. Then for each $x\in B(0,1)$, choose $x_j$ such that $\Vert Tx-Tx_j\Vert < \epsilon/2$. Once $n\geq N$, we have
\begin{align*}
	\Vert(I-P_n)Tx\Vert &\leq \Vert (I-P_n)T(x-x_j)\Vert + \Vert (I-P_n)Tx_j\Vert\\
	&\leq \Vert T(x-x_j)\Vert + \Vert (I-P_n)Tx_j\Vert\\
	&< \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon.
\end{align*}
Hence $\Vert(I-P_n)T\Vert < \epsilon$ for all $n\geq N$. Since $\epsilon>0$ is arbitrary, $P_nT$ converges to $T$ in norm.
\end{proof}

\paragraph{Example 4.31\label{example:4.31}} (Fredholm integral operators). Given $K\in L^2([a,b]\times[a,b])$, define the corresponding Fredholm operator $T_K:L^2([a,b])\to L^2([a,b])$ as follows:
\begin{align*}
	(T_K\varphi)(x)=\int_a^b K(x,y)\varphi(y)\,dy,\ \forall \varphi\in L^2([a,b]).
\end{align*}
Following \hyperref[example:3.37]{Example 3.37 (ii)}, $\Vert T_K\Vert\leq\Vert K\Vert_2$. Furthermore, $T_K$ is a compact operator.
\begin{proof}
We approximate $K\in L^2([a,b]\times[a,b])$ by a sequence of simple functions
\begin{align*}
	K_n(s,t) = \sum_{k=1}^{m_n}\alpha_{n,k}\chi_{D_{n,k}},
\end{align*}
where $D_{n,k}=(a_{n,k},b_{n,k})\times(c_{n,k},d_{n,k})$ is an open rectangle, and $\Vert T_K-T_{K_n}\Vert = \Vert T_{(K-K_n)}\Vert\leq\Vert K-K_n\Vert_2\to 0$, hence $T_{K_n}\to T_K$ in norm. By \hyperref[cor:4.29]{Corollary 4.29}, it suffices to show that every $T_{K_n}$ is of finite rank:
\begin{align*}
	(T_{K_n}\varphi)(x) = \int_a^b\sum_{k=1}^{m_n}\alpha_{n,k}\chi_{D_{n,k}}(x,y)\varphi(y)\,dy = \sum_{k=1}^{m_n}\alpha_{n,k}\left(\int_{c_{n,k}}^{d_{n,k}}\varphi(y)\,dy\right)\chi_{(a_{n,k},b_{n,k})}(x).
\end{align*}
Hence $\mathfrak{R}(T_{K_n})\subset\mathrm{span}\left\{\chi_{(a_{n,k},b_{n,k})}\right\}_{k=1}^{m_n}$, which is of finite dimension.
\end{proof}

Finally, we discuss the adjoints of compact operators.
\paragraph{Proposition 4.32.\label{prop:4.32}} Let $X$ and $Y$ be normed spaces, and $T\in\mathcal{K}(X,Y)$. Then $TX$ is a separable subset of $Y$.
\begin{proof}
By definition, $TB(0,n)$ is a relatively compact subset of $Y$ for all $n\in\mathbb{N}$. By \hyperref[lemma:1.73]{Lemma 1.73}, $TB(0,n)$ is separable. As a result, $TX=\bigcup_{n=1}^\infty TB(0,n)$ is separable.
\end{proof}

\paragraph{Theorem 4.33.\label{thm:4.33}} Let $X$ and $Y$ be normed spaces, and $T\in\mathfrak{B}(X,Y)$. Let $T^*\in\mathfrak{B}(Y^*,X^*)$ be the adjoint.
\begin{itemize}
	\item[(i)] If $T$ is a compact operator, so is $T^*$. 
	\item[(ii)] If $Y$ is a Banach space and $T^*$ is a compact operator, so is $T$.
\end{itemize}
\begin{proof}
(i) Let $(f_n)$ be a bounded sequence in $Y^*$ such that $\Vert f_n\Vert\leq M$ for all $n\in\mathbb{N}$. We want to prove that there exists a subsequence $(f_{n_k})$ such that $(T^*f_{n_k})$ converges in $X^*$.

\textit{Step I:} Let $Y_0=\overline{TX}$, which is a separable subspace of $Y$. We define $T_0:X\to Y_0,\ x\to Tx$. Then for all $f\in Y^*$, we have $T^*f=T_0^*f|_{Y_0}$. Hence $(T^*f_{n_k})$ converges in $X^*$ if and only if $(T^*_0f_{n_k}|_{Y_0})$ converges in $X^*$. Without loss of generality, we suppose $Y$ is separable.

\textit{Step II:} By Banach-Alaoglu theorem (\hyperref[thm:2.55]{Theorem 2.55}), there exists a subsequence $(f_{n_k})$ that converges in the weak-$^*$ topology on $Y^*$:
\begin{align*}
	\lim_{k\to\infty} f_{n_k}(y)= f(y).
\end{align*}

\textit{Step III:} We verify that $(T^*f_{n_k})$ converges in norm. Let $S=\{x\in X:\Vert x\Vert=1\}$ be the unit sphere in $X$. Then we have
\begin{align*}
	\left\Vert T^*f_{n_k} - T^*f\right\Vert &= \sup_{x\in S}\left\vert (T^*f_{n_k} - T^*f)(x)\right\vert =\sup_{x\in S}\left\vert f_{n_k}(Tx) - f(Tx)\right\vert =\sup_{y\in TS}\left\vert f_{n_k}(y) - f(y)\right\vert.\tag{4.7}\label{eq:4.7}
\end{align*}
Since $TS$ is relatively compact, given $\epsilon>0$, we choose an $\frac{\epsilon}{3M}$-net $\{y_1,\cdots,y_m\}$ of $TS$. Then for all $y\in TS$, there exists $y_j$ such that $\Vert y-y_j\Vert<\frac{\epsilon}{3M}$. Furthermore, we choose $K>0$ such that $\vert f_{n_k}(y_j) - f(y_j)\vert<\epsilon/3$ for all $j\in\{1,\cdots,m\}$ and all $k\geq K$. Then
\begin{align*}
	\left\vert f_{n_k}(y) - f(y)\right\vert &\leq \left\vert f_{n_k}(y) - f_{n_k}(y_j)\right\vert + \left\vert f_{n_k}(y_j) - f(y_j)\right\vert + \left\vert f(y_j) - f(y)\right\vert\\
	&\leq \Vert f_{n_k}\Vert\left\Vert y-y_j\right\Vert + \left\vert f_{n_k}(y_j) - f(y_j)\right\vert + \Vert f\Vert\left\Vert y-y_j\right\Vert \\
	&< \frac{\epsilon}{3M}M +  \frac{\epsilon}{3} +  \frac{\epsilon}{3M}M = \epsilon,\ \forall y\in TS,\ k\geq K.
\end{align*}
Since $\epsilon>0$ is arbitrary, by \hyperref[eq:4.7]{(4.7)}, $\Vert T^*f_{n_k}- T^*f\Vert\to 0$ as $k\to\infty$.\vspace{0.1cm}

(ii) Since $T^*\in\mathcal{K}(Y^*,X^*)$, by (i), $T^{**}\in\mathcal{K}(X^{**},Y^{**})$. We view $X$ and $Y$ as subspaces of $X^{**}$ and $Y^{**}$, respectively. Then the unit ball $B_X(0,1)\subset B_{X^{**}}(0,1)$ is a bounded subset of $X^{**}$, and $T^{**}B_X(0,1)$ is relatively compact, hence totally bounded in $Y^{**}$. By \hyperref[thm:3.32]{Theorem 3.32 (vii)}, $TB(0,1)=TB^{**}(0,1)$ is totally bounded in $Y^{**}$, so is in $Y$. Since $Y$ is a Banach space, $TB(0,1)$ is relatively compact in $Y$.
\end{proof}

\subsubsection{Spectra of Compact Operators}
\paragraph{Theorem 4.34\label{thm:4.34}} (Riesz-Schauder). Let $X$ be a Banach space, and $T\in\mathcal{K}(X)$.
\begin{itemize}
	\item[(i)] If $\dim X=\infty$, $0\in\sigma(T)$. In other words, $T$ is not invertible.
	\item[(ii)] If $\lambda\in\sigma(T)\backslash\{0\}$, there exists $x\neq 0$ such that $Tx=\lambda x$. Namely, every nonzero point of $\sigma(T)$ is an eigenvalue of $T$. Following (i), if $\dim X=\infty$, then $\sigma(T)=\sigma_p(T)\cup\{0\}$.
	\item[(iii)] If $\lambda\in\sigma(T)\backslash\{0\}$, $\dim\ker(T-\lambda I)<\infty$, i.e. the eigenspace  of $\lambda$ is a finite-dimensional subspace of $X$.
	\item[(iv)] Eigenvectors associated with distinct eigenvalues of $T$ are linearly independent.
	\item[(v)] $\sigma(T)$ has at most one limit point, which would necessarily be zero.
\end{itemize}
\begin{proof}
We leave the proof of (ii) for later.

(i) If $T$ is invertible, $T^{-1}\in\mathfrak{B}(X)$, and $I=T^{-1}T$ is a compact operator on $X$. Nevertheless, by \hyperref[thm:1.76]{Theorem 1.76}, the unit ball $B(0,1)$ is not relatively compact, a contradiction!

(iii) For every $x_0\in B_\lambda = \{x\in\ker(T-\lambda I):\Vert x\Vert\leq 1\}$, we have $x_0=\lambda^{-1}Tx_0 = T(\lambda^{-1}x_0)$. As a result, $B_\lambda\subset TB(0,\vert\lambda\vert^{-1})$ is relatively compact. Since $B_\lambda$ is the unit ball in $\ker(T-\lambda I)$, $\dim\ker(T-\lambda I)<\infty$.

(iv) Let $\lambda_1,\cdots,\lambda_n$ be distinct eigenvalues of $T$, and let $x_1,\cdots,x_n$ be the associated eigenvectors. Suppose $\alpha_1 x_1 + \cdots + \alpha_n x_n=0$. Then
\begin{align*}
\begin{pmatrix}
	I & I & \cdots & I\\
	\lambda_1 I & \lambda_2 I & \cdots & \lambda_n I\\
	\vdots & \vdots & \ddots & \vdots\\
	\lambda_1^{n-1} I & \lambda_2^{n-1} I & \cdots & \lambda_n^{n-1} I
\end{pmatrix}
\begin{pmatrix}
	\alpha_1 x_1\\ \alpha_2 x_2\\ \vdots\\ \alpha_n x_n
\end{pmatrix}
=
\begin{pmatrix}
	\alpha_1 x_1 + \cdots + \alpha_n x_n\\
	T(\alpha_1 x_1 + \cdots + \alpha_n x_n)\\
	\vdots\\
	T^{n-1}(\alpha_1 x_1 + \cdots + \alpha_n x_n)
\end{pmatrix}
= \begin{pmatrix}
	0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}
\end{align*}
Since the Vandermonde matrix is invertible, $\alpha_1 x_1= \alpha_2 x_2 = \cdots = \alpha_n x_n=0$.

(v) We prove an equivalent statement: for all $\epsilon>0$, the set $\{\lambda\in\sigma(T):\vert\lambda\vert\geq\epsilon\}$ is finite. If not, choose a sequence $(\lambda_n)$ of distinct eigenvalues, and let $(x_n)$ be the sequence of associated eigenvectors. Denote $L_n=\mathrm{span}\left\{x_1,\cdots,x_n\right\}$. By \hyperref[lemma:1.75]{Lemma 1.75}, there exists sequence $(y_n)$ of unit vectors such that $y_n\in L_n$ and $d(y_n,L_{n-1})>1/2$. Note that $y_n - \frac{Ty_n}{\lambda_n}\in L_{n-1}$. Furthermore, once $n>m$,
\begin{align*}
	\left\Vert\frac{Ty_n}{\lambda_n} - \frac{Ty_m}{\lambda_m}\right\Vert = \biggl\Vert y_n - \underbrace{\left(y_n - \frac{Ty_n}{\lambda_n} + \frac{Ty_m}{\lambda_m}\right)}_{\in L_{n-1}}\biggr\Vert > \frac{1}{2}.
\end{align*}
However, $\left\{\frac{Ty_n}{\lambda_n},n\in\mathbb{N}\right\}\subset TB(0,\epsilon^{-1})$ is relatively sequentially compact, a contradiction!
\end{proof}

\paragraph{Remark.} The statement (v) also gives a characterization of the spectrum of compact operator $T$: $\sigma(T)$ is discrete, i.e. $\sigma(T)$ has at most countably elements:
\begin{align*}
	\sigma(T) = \bigcup_{n=1}^\infty\left\{\lambda\in\sigma(T):\vert\lambda\vert\geq n^{-1}\right\}.
\end{align*}

As a result, if $T$ has infinitely many eigenvalues, we can make a sequence $(\lambda_n)_{n\in\mathbb{N}}$ of these eigenvalues, which satisfies $\lim_{n\to\infty}\vert\lambda_n\vert = 0$. Clearly, we can permute them in a decreasing order: $\vert\lambda_1\vert\geq\vert\lambda_2\vert\geq\cdots$. 


The proof of \hyperref[thm:4.34]{Theorem 4.34 (ii)} is a bit complicated, which requires some technical lemmas.
\paragraph{Lemma 4.35.\label{lemma:4.35}} Let $X$ be a Banach space, $T\in\mathcal{K}(X)$, and $\lambda\in\mathbb{C}\backslash\{0\}$. If $(T-\lambda I)X=X$, then $\lambda\in\rho(T)$.
\begin{proof}
We assume $\dim X=\infty$, since the finite-dimensional case is clear. By bounded inverse theorem, it remains to show $T-\lambda I$ is injective. We choose $L_n=\{x\in X:(T-\lambda I)^n x=0\} = \ker(T-\lambda I)^n$. Then we obtain a sequence $L_1\subset L_2\subset\cdots$ of subspaces of $X$. We wish to show $L_1=\{0\}$.

If $L_1\neq\{0\}$, choose $x_1\in L_1$ such that $x_1\neq 0$, and generate a sequence by choosing $(T-\lambda I)x_n=x_{n-1}$. Then $x_n\in L_n\backslash L_{n-1}$. By \hyperref[lemma:1.75]{Lemma 1.75}, we can choose a sequence $(y_n)$ of unit vectors such that $y_n\in L_n\backslash L_{n-1}$ and that $d(y_n,L_{n-1})>1/2$. Once $p>q$, we have $L_q\subset L_{p-1}\subsetneq L_p$, and
\begin{align*}
	\left\Vert\frac{Ty_p}{\lambda}-\frac{Ty_q}{\lambda}\right\Vert = \biggl\Vert y_p - \underbrace{\left(y_q - \frac{(T-\lambda I)y_p}{\lambda} + \frac{(T-\lambda I)y_q}{\lambda}\right)}_{\in L_{p-1}}\biggr\Vert > \frac{1}{2}.
\end{align*}
However, $\left\{\frac{Ty_n}{\lambda},n\in\mathbb{N}\right\}\subset TB(0,\lambda^{-1})$ is relatively sequentially compact, a contradiction!
\end{proof}

\paragraph{Lemma 4.36.\label{lemma:4.36}} Let $X$ be a Banach space, $T\in\mathcal{K}(X)$, and $\lambda\in\mathbb{C}\backslash\{0\}$. $\mathfrak{R}(T-\lambda I)$ is a closed subspace of $X$.
\begin{proof}
Let $(y_n)$ be a sequence of points of $\mathfrak{R}(T-\lambda I)$ that converges to $y\in Y$, and choose sequence $(x_n)$ such that $(T-\lambda I)x_n=y_n$ for all $n\in\mathbb{N}$. We need to show $y\in\mathfrak{R}(T-\lambda I)$.

\textit{Step I:} If $(x_n)$ is a bounded sequence, by compactness of $T$, there exists subsequence $(x_{n_k})$ such that $(Tx_{n_k})$ converges in $X$. As a result, the subsequence $x_{n_k}=\lambda^{-1}(Tx_{n_k} - y_{n_k})$ also converges. Let $x=\lim_{k\to\infty}x_{n_k}$, then $y=\lim_{k\to\infty} y_{n_k} =(T-\lambda I)x$, which implies $y\in\mathfrak{R}(T-\lambda I)$.

\textit{Step II:} If $(x_n)$ is not bounded, let $\alpha_n=d(x_n,\ker(T-\lambda I))>0$. Then there exists sequence $(w_n)\subset\ker(T-\lambda I)$ such that $\alpha_n\leq\Vert x_n-w_n\Vert\leq\left(1+\frac{1}{n}\right)\alpha_n$. Define $x_n^\prime=x_n - w_n$, then $(T-\lambda I)x_n^\prime=y_n$, and $\alpha_n\leq\Vert x_n^\prime\Vert\leq\left(1+\frac{1}{n}\right)\alpha_n$. If $(\alpha_n)$ is bounded, so is $(x_n^\prime)$. Back to Step I.

\textit{Step III:} If $(\alpha_n)$ is not bounded, choose subsequence $a_{n_k}\to \infty$, and let $z_{k}=\frac{x_{n_k}^\prime}{\Vert x_{n_k}^\prime\Vert}$. Then $\Vert z_k\Vert=1$, and $(T-\lambda I)z_k=\frac{y_{n_k}}{\Vert x_{n_k}^\prime\Vert}\to 0$. Since $T$ is compact, there exists subsequence $z_{k_l}=\lambda^{-1}\left(Tz_{k_l} - (T-\lambda I)z_{k_l}\right)$ such that $(z_{k_l})$ converges to some $z\in X$. Clearly, $(T-\lambda I)z=0$. Furthermore,
\begin{align*}
	x_{n_{k_l}} - \underbrace{\left(w_{n_{k_l}} + z\bigl\Vert x_{n_{k_l}}-w_{n_{k_l}}\bigr\Vert\right)}_{\in\,\ker(T-\lambda I)} = (z_{{k_l}}-z)\bigl\Vert x_{n_{k_l}}-w_{n_{k_l}}\bigr\Vert.
\end{align*}
As a result, we have
\begin{align*}
	\alpha_{n_{k_l}}\leq \bigl\Vert z_{{k_l}}-z\bigr\Vert\bigl\Vert x_{n_{k_l}}-w_{n_{k_l}}\bigr\Vert\leq\bigl\Vert z_{{k_l}}-z\bigr\Vert\left(1+\frac{1}{n_{k_l}}\right)\alpha_{n_{k_l}}\ \Rightarrow\ \bigl\Vert z_{{k_l}}-z\bigr\Vert\geq\frac{n_{k_l}}{1+n_{k_l}}\geq\frac{1}{2}.
\end{align*}
However, $z_{{k_l}}\to z$, a contradiction! Hence $(\alpha_n)$ is bounded, and $\mathfrak{R}(T-\lambda I)$ is closed.
\end{proof}

Now we are prepared to prove \hyperref[thm:4.34]{Theorem 4.34 (ii)}.

\renewcommand{\proofname}{Proof of \hyperref[thm:4.34]{Theorem 4.34 (ii)}}
\begin{proof}
If $\lambda\in\sigma(T)\backslash\{0\}$ is not an eigenvalue of $T$, $\ker(T-\lambda I_X)=\{0\}$. By \hyperref[lemma:4.36]{Lemma 4.36} and \hyperref[thm:3.34]{Theorem 3.34}, $\mathfrak{R}(T-\lambda I_X)$ is closed, and
\begin{align*}
	\mathfrak{R}(T^*-\lambda I_{X^*}) = \ker(T-\lambda I_X)^\perp = X^*.
\end{align*}
By \hyperref[thm:4.33]{Theorem 4.33} and \hyperref[lemma:4.35]{Lemma 4.35}, $T^*\in\mathcal{K}(X^*)$, and $\lambda\in\rho(T^*)$. However $\lambda\in\sigma(T)=\sigma(T^*)$, a contradiction! Therefore, $\lambda\in\sigma(T)\backslash\{0\}$ is an eigenvalue of $T$.
\end{proof}
\renewcommand{\proofname}{Proof}

\paragraph{Theorem 4.37\label{thm:4.37}} (Riesz-Schauder). Let $X$ be a Banach space, and $T\in\mathcal{K}(X)$. Let $T^*\in\mathcal{K}(X^*)$ be the adjoint.
\begin{itemize}
	\item[(i)] $\sigma(T)=\sigma(T^*)$.
	\item[(ii)] If $\lambda\in\sigma(T)\backslash\{0\}$, then $$\dim\ker(T-\lambda I_X) = \dim\ker(T^*-\lambda I_{X^*}) = \mathrm{codim}\,\mathfrak{R}(T-\lambda I_X) = \mathrm{codim}\,\mathfrak{R}(T^*-\lambda I_{X^*}).$$
	\item[(iii)] If $\lambda,\mu$ are distinct eigenvalues of $T$, then $f(x)=0$ for all $x\in\ker(T-\lambda I_X)$ and all $f\in\ker(T^*-\mu I_{X^*})$.
	\item[(iv)] If $\lambda\in\sigma(T)\backslash\{0\}$, then $$\mathfrak{R}(T-\lambda I_X) =\,^\perp\ker(T^*-\lambda I_{X^*}),\quad \mathfrak{R}(T^*-\lambda I_{X^*})= \ker(T-\lambda I_X)^\perp.$$
\end{itemize}
\begin{proof}
(ii) We first claim that $\mathrm{codim}\,\mathfrak{R}(T-\lambda I_X)\leq\dim\ker(T-\lambda I_X)$. Clearly, $n=\dim\ker(T-\lambda I_X)>0$, and we choose a basis $\{x_1,\cdots,x_n\}$ of $\ker(T-\lambda I_X)$. If $\mathrm{codim}\,\mathfrak{R}(T-\lambda I_X)>n$, there exists $y_1,\cdots,y_{n+1}\in X$ such that $\{[y_1],\cdots,[y_{n+1}]\}$ are linearly independent in $X/\mathfrak{R}(T-\lambda I_X)$. 

By Hahn-Banach theorem, there exist $f_1,\cdots,f_n\in X^*$ such that $f_j(x_k)=\delta_{jk}$ for all $j,k\in\{1,\cdots,n\}$. Let 
\begin{align*}
	Ax= Tx - \sum_{j=1}^n f_j(x)\,y_j,\ \forall x\in X.
\end{align*}
Then $A\in\mathcal{K}(X)$. We will verify that $A-\lambda I_X$ is injective. If $(A-\lambda I_X)x=0$, then
\begin{align*}
	(T-\lambda I_X) x = \sum_{j=1}^n f_j(x)\,y_j\ \Rightarrow\ 0=\sum_{j=1}^n f_j(x)[y_j]\ \Rightarrow\ f_1(x)=\cdots=f_n(x)=0\ \Rightarrow\ (T-\lambda I_X)x=0.
\end{align*}
Let $x=\sum_{k=1}^n c_kx_k\in\ker(T-\lambda I_X)$. Then $0=f_j(x) = c_j\sum_{k=1}^n f_j(x_k) = c_j$ for all $j$, which implies $x=0$. Hence $A-\lambda I_X$ is injective. Since $\lambda\neq 0$, and $A\in\mathcal{K}(X)$, we have $\lambda\in\rho(A)$. As a result, $A-\lambda I$ is invertible, and there exists $x_{n+1}\in X$ such that $(A-\lambda I_X)x_{n+1} = y_{n+1}$. Then in $X/\mathfrak{R}(T-\lambda I_X)$,
\begin{align*}
	[y_{n+1}] = \left[(A-\lambda I_X)x_{n+1}\right] = \left[(T-\lambda I_X) x_{n+1} - \sum_{j=1}^n f_j(x_{n+1})y_j\right] = -\sum_{j=1}^n f_j(x_{n+1})[y_j].
\end{align*}
However $\{[y_1],\cdots,[y_{n+1}]\}$ are linearly independent in $X/\mathfrak{R}(T-\lambda I_X)$, a contradiction!

Similarly, we know that $\mathrm{codim}\,\mathfrak{R}(T^*-\lambda I_{X^*})\leq\dim\ker(T^*-\lambda I_{X^*})$. By \hyperref[lemma:4.36]{Lemma 4.36}, $T-\lambda I_X$ has closed range. Using \hyperref[thm:3.34]{Theorem 3.34} and \hyperref[thm:2.26]{Theorem 2.26}, we have
\begin{align*}
	\dim\ker(T-\lambda I_X) &\geq \dim X/\mathfrak{R}(T-\lambda I_X) = \dim \left(X/\mathfrak{R}(T-\lambda I_X)\right)^* = \dim\mathfrak{R}(T-\lambda I_X)^\perp\\
	&= \dim\ker(T^*-\lambda I_{X^*}) \geq \dim X^*/\mathfrak{R}(T^*-\lambda I_{X^*}) = \dim X^*/\ker(T-\lambda I_X)^\perp\\
	&= \dim\left(\ker(T-\lambda I_X)\right)^* = \dim\ker(T-\lambda I_X).\\
	&\hspace{4cm}\Downarrow\\
	\dim\ker(T-\lambda I_X) &= \dim\ker(T^*-\lambda I_{X^*}) = \mathrm{codim}\,\mathfrak{R}(T-\lambda I_X) = \mathrm{codim}\,\mathfrak{R}(T^*-\lambda I_{X^*}).
\end{align*}
(iii) Let $x\in\ker(T-\lambda I_X)$ and all $f\in\ker(T^*-\mu I_{X^*})$. Since $\mu\neq\mu$, we have
\begin{align*}
	Tx = \lambda x,\ T^* f = \mu f\ \Rightarrow\ (\lambda - \mu)f(x) = f(\lambda x) - (\mu f)(x) = f(Tx) - (T^*f)(x)= 0\ \Rightarrow\ f(x)=0.
\end{align*}
(iv) is a corollary of \hyperref[lemma:4.36]{Lemma 4.36} and \hyperref[thm:3.34]{Theorem 3.34}.
\end{proof}

\newpage
\subsection{Compact Self-adjoint Operators}
Let $T$ be a compact operator on a Hilbert space. If $T^*=T$, then $T$ is a compact self-adjoint operator. The spectrum of $T$ possesses some nice properties.
\paragraph{Lemma 4.38.\label{lemma:4.38}} Let $H$ be a Hilbert space, and let $T$ be a compact self-adjoint operator on $H$.
\begin{itemize}
	\item[(i)] If $\lambda$ is an eigenvalue of $T$, then $\lambda\in\mathbb{R}$.
	\item[(ii)] If $\lambda$ and $\mu$ are distinct eigenvalues of $T$, the eigenvectors associated with $\lambda$ and $\mu$ are orthogonal.
	\item[(iii)] $\max_{\lambda\in\sigma_p(T)}\vert\lambda\vert = \Vert T\Vert$.
\end{itemize}
\begin{proof}
(i) Let $Tx=\lambda x$, where $x\neq 0$. Then
\begin{align*}
	\lambda\langle x,x\rangle = \langle \lambda x,x\rangle = \langle Tx,x\rangle = \langle x,Tx\rangle = \langle x,\lambda x\rangle = \overline{\lambda}\langle x,x\rangle.
\end{align*}
(ii) By (i), $\lambda,\mu\in\mathbb{R}$. Let $Tx=\lambda x$, and $Ty=\mu y$, where $x,y\neq 0$. Then
\begin{align*}
	(\lambda-\mu)\langle x,y\rangle = \langle \lambda x,y\rangle - \langle x,\mu y\rangle = \langle Tx,y\rangle - \langle x,Ty\rangle = 0.
\end{align*}
(iii) The case $T=0$ is trivial. If $T\neq 0$, by \hyperref[cor:4.19]{Corollary 4.19}, $r(T)=\Vert T\Vert> 0$. By \hyperref[thm:4.34]{Theorem 4.34 (v)}, there exists $\lambda_1\in\sigma(T)$ such that $\vert\lambda_1\vert = \max_{\lambda\in\sigma(T)}\vert\lambda\vert =r(T)=\Vert T\Vert$. Since $\lambda_1\neq 0$, we have $\lambda_1\in\sigma_p(T)$.
\end{proof}

\paragraph{Theorem 4.39.\label{thm:4.39}} Let $T$ be a compact self-adjoint operator on a Hilbert space $H$. Then there exist eigenvectors $\{e_\lambda,\lambda\in\Lambda\}$ of $T$ that form a orthonormal basis of $H$.
\begin{proof}
Since $T$ is compact, let $\{\lambda_k\}_{k\in J}$ be the nonzero eigenvalues of $T$, where $J$ is finite or countable. By Riesz-Schauder theorem, $n_k=\dim\ker(T-\lambda_k I)<\infty$ for all $k\in J$, and $\ker(T-\lambda_k I)\perp\ker(T-\lambda_l I)$ for all $k\neq l$. For every $k\in J$, we choose an orthonormal basis $\{e_{k,j}\}_{j=1}^{n_k}$ of $\ker(T-\lambda_k I)$. By \hyperref[lemma:4.38]{Lemma 4.38 (ii)}, we obtain an orthonormal system on $H$:\vspace{0.30cm}

$\hspace{5cm}\mathscr{F}_1 = \left\{e_{k,j}:k\in J,\ j=1,\cdots,n_k\right\}.\vspace{0.30cm}$

If $\mathscr{F}_1^\perp=\{0\}$, then $\mathscr{F}_1$ is an orthonormal basis of $H$, and the result holds.

If $\mathscr{F}_1^\perp\neq\{0\}$, let $H_1=\overline{\mathrm{span}}\,\mathscr{F}_1$, and $H_0=H_1^\perp=\mathscr{F}_1^\perp$. Then $TH_1=H_1$. Furthermore,
\begin{align*}
	\langle x,Ty\rangle = \langle Tx,y\rangle,\ \forall x\in H_1,y\in H_0\ \Rightarrow\ Ty\in H_0,\ \forall y\in H_0\ \Rightarrow\ TH_0\subset H_0.
\end{align*}

Since $H_0$ is an invariant subspace of $T$, we use its restriction $\widetilde{T}=T|_{H_0}$, which is also a compact self-adjoint operator. If $\widetilde{T}\neq 0$, by  \hyperref[lemma:4.38]{Lemma 4.38 (iii)}, $\widetilde{T}$ has at least one nonzero eigenvalue $\lambda_0$, with a corresponding eigenvector $x_0\in H_0\backslash\{0\}$. However, $Tx_0 = \widetilde{T}x_0=\lambda_0x_0$, which implies $x_0\in H_1$, contradicting $x_0\in H_0$! Therefore $\widetilde{T}=0$, and $H_0$ is the eigenspace of $0\in\sigma_p(T)$. We choose an orthonormal basis $\mathscr{F}_0$ of $H_0$. Then $\mathscr{F}_1\cup\mathscr{F}_0$ is the desired orthonormal basis of $H=H_1\oplus H_0$.
\end{proof}

\paragraph{Remark.} If $T$ has only finitely many nonzero eigenvalues $\lambda_1,\cdots,\lambda_n$, then $H_1$ is finite-dimensional. Let $E_k=\ker(T-\lambda_k I)$ be the eigenspace of $\lambda_k$, where $k=1,\cdots,n$. Then $H_1=E_1\oplus\cdots\oplus E_n$. For all $x\in H$, let $x=x_1+x_0$, where $x_1\in H_1$ and $x_0\in H_0$. Then
\begin{align*}
	Tx = Tx_1 = T\left(\sum_{k=1}^n P_{E_k}x_1\right) = \sum_{k=1}^n \lambda_kP_{E_k} x_1 = \sum_{k=1}^n \lambda_kP_{E_k} x.
\end{align*}
Hence we have $T=\sum_{k=1}^n\lambda_kP_{E_k}$. In fact, we can extend this result to the case where $T$ has infinitely many nonzero eigenvalues. 

\paragraph{Theorem 4.40.\label{thm:4.40}} Let $T$ be a compact self-adjoint operator on a Hilbert space $H$. If $T$ has infinitely many nonzero eigenvalues, we sequentialize them in decreasing order: $\vert\lambda_1\vert\geq\vert\lambda_2\vert\geq\vert\lambda_{n-1}\vert\geq\vert\lambda_n\vert\geq\cdots$. Let $E_n=\ker(T-\lambda_n I)$ be the eigenspace of $\lambda_n$. Then
\begin{align*}
	T = \sum_{n=1}^\infty \lambda_n P_{E_n}\quad \text{(convergence in norm)}.
\end{align*}
\begin{proof}
For any $n\geq m$, define $S_{n,m}=\sum_{k=m}^n\lambda_k P_{E_k}$. Then $\Vert S_{n,m}\Vert=\vert\lambda_m\vert\to 0$ as $n,m\to 0$. As a result, $\sum_{n=1}^\infty\lambda_n P_{E_n}$ converges in norm. Take the orthonormal basis $\mathscr{F}_1\cup\mathscr{F}_0$ defined in the proof of \hyperref[thm:4.39]{Theorem 4.39}. Since $x=\sum_{e_\lambda\in\mathscr{F}_1\cup\mathscr{F}_0}\langle x,e_\lambda\rangle\, e_\lambda$,
\begin{align*}
	\left\Vert Tx-\sum_{k=1}^n\lambda_kP_{E_k}x\right\Vert^2 &= \left\Vert \sum_{k=1}^\infty\sum_{j=1}^{n_k}\lambda_k\left\langle x,e_{k,j}\right\rangle e_{k,j}-\sum_{k=1}^n\lambda_k\sum_{j=1}^{n_k}\left\langle x,e_{k,j}\right\rangle e_{k,j}\right\Vert^2 =\left\Vert \sum_{k=n+1}^\infty\sum_{j=1}^{n_k}\lambda_k\left\langle x,e_{k,j}\right\rangle e_{k,j}\right\Vert^2\\
	&\leq \left\vert \lambda_{n+1}\right\vert^2\sum_{k=n+1}^\infty\sum_{j=1}^{n_k}\vert\left\langle x,e_{k,j}\right\rangle\vert^2\leq\left\vert\lambda_{n+1}\right\vert^2\left\Vert x\right\Vert^2.\ \tag{Bessel's inequality}
\end{align*}
Hence $\left\Vert T-\sum_{k=1}^n\lambda_kP_{E_k}\right\Vert\leq\left\vert\lambda_{n+1}\right\vert \to 0$, which implies $T=\sum_{n=1}^\infty\lambda_nP_{E_n}$.
\end{proof}

\paragraph{Example 4.41} (Mercer). Let $K\in C([a,b]\times[a,b])$ be a conjugate symmetric function, i.e. $K(s,t)=\overline{K(t,s)}$ for all $s,t\in[a,b]$. Following \hyperref[example:3.37]{Example 3.37 (ii)} and \hyperref[example:4.31]{Example 4.31}, the Fredholm integral operator
\begin{align*}
	(T_Kf)(s) = \int_a^b K(s,t)f(t)\,dt,\ \forall s\in[a,b],\ f\in L^2([a,b])
\end{align*}
is a compact self-adjoint operator on $L^2([a,b])$. Using \hyperref[thm:4.39]{Theorem 4.39}, we choose an orthonormal basis $\mathscr{F}_1\cup\mathscr{F}_0$ of $H$, where $\mathscr{F}_1$ contains the eigenvectors associated with nonzero eigenvalues of $T_K$, and $\mathscr{F}_0$, possibly empty, is an orthonormal basis of $\ker(T_K)$. Clearly, $\mathscr{F}_1$ is countable. Since $L^2([a,b])$ is separable, $\mathscr{F}_0$ is chosen to be at most countable. Hence $\mathscr{F}_1\cup\mathscr{F}_0=\{\phi_n,n\in\mathbb{N}\}$ is a countable orthonormal basis of $L^2([a,b])$.

Let $\lambda_n$ be the eigenvalue of $T$ associated with $\phi_n$. Without generality, assume $\vert\lambda_1\vert\geq\vert\lambda_2\vert\geq\cdots\geq\vert\lambda_n\vert\geq\cdots$. Note that $\{\lambda_n,n\in\mathbb{N}\}$ may have finitely many nonzero elements. By \hyperref[thm:4.40]{Theorem 4.40}, we have \vspace{-0.1cm}
\begin{align*}
	T_K f = \sum_{n=1}^\infty \lambda_n\langle f,\phi_n\rangle \phi_n,\ f\in L^2([0,1]).
\end{align*}
Given $s\in[a,b]$, define $K_s(t)=\overline{K(s,t)}$ for all $t\in [a,b]$. Then \vspace{-0.05cm}
\begin{align*}
	\langle K_s,\phi_n\rangle = \int_a^b \overline{K(s,t)}\overline{\phi_n(t)}\,dt = \overline{(T_K\phi_n)(s)} = \overline{\lambda_n\phi_n(s)}
\end{align*}
By expanding $K_s$, we obtain the following representation of $K$: \vspace{-0.05cm}
\begin{align*}
	K(s,t) = \overline{K_s(t)} = \sum_{n=1}^\infty\overline{\langle K_s,\phi_n\rangle\phi_n(t)} = \sum_{n=1}^\infty\lambda_n\phi_n(s)\overline{\phi_n(t)}.\tag{4.8}\label{eq:4.8}
\end{align*}
Note that $K\in C([a,b]\times[a,b])\subset L^2([a,b]\times[a,b])$. Using \hyperref[eq:4.8]{(4.8)}, we have
\begin{align*}
	\int_a^b\int_a^b\vert K(s,t)\vert^2\,ds\,dt = \sum_{m=1}^\infty\sum_{n=1}^\infty \lambda_m\overline{\lambda_n}\int_a^b\phi_m(s)\overline{\phi_n(s)}\,ds\int_a^b\overline{\phi_m(t)}\phi_n(t)\,dt = \sum_{n=1}^\infty\vert\lambda_n\vert^2 < \infty.\vspace{-0.1cm}
\end{align*}
Then back in \hyperref[eq:4.8]{(4.8)}, the function series converges in $L^2$ sense.

\subsection{Spectral Measures}
\subsubsection{Projection Operators and Spectral Measures}
\paragraph{Theorem 4.42.\label{thm:4.42}}  Let $H$ be a Hilbert space, and $P\in\mathfrak{B}(H)$. Then $P$ is a projection if and only if $P$ is self-adjoint and idempotent, i.e. $P=P^*=P^2$.
\begin{proof}
Clearly, a projection $P$ is idempotent. Following \hyperref[example:3.40]{Example 3.40}, it is self-adjoint.

Conversely, if $P$ is self-adjoint and idempotent, let $L=\{x\in H:Px=x\}$. We claim that $P$ is a projection onto $L$. Clearly, $L$ is a closed subspace of $H$. Then it suffices to prove that $\langle Pv,v-Pv\rangle=0$ for all $v\in H$:
$\langle Pv,v-Pv\rangle = \langle Pv,v\rangle - \langle Pv,Pv\rangle = \langle Pv,v\rangle - \langle P^*Pv,v\rangle = \langle Pv,v\rangle - \langle P^2v,v\rangle = \langle Pv,v\rangle - \langle Pv,v\rangle = 0.$
\end{proof}

We denote by $\mathcal{P}(H)$ the set of all projections on a Hilbert space $H$, which has a nice structure.
\paragraph{Proposition 4.43.\label{prop:4.43}} Let $P_M,P_N\in\mathcal{P}(H)$, where $M$ and $N$ are closed subspaces of Hilbert space $H$.
\begin{itemize}
	\item[(i)] $P_MP_N\in\mathcal{P}(H)$ if and only if $P_MP_N=P_NP_M$. Furthermore, $P_MP_N=0$ if and only if $M\perp N$.
	\item[(ii)] $P_M+P_N\in\mathcal{P}(H)$ if and only if $M\perp N$. If so, $P_M+P_N$ is the projection onto $M\oplus N$.
	\item[(iii)] $P_M-P_N\in\mathcal{P}(H)$ if and only if $M\supset N$. If so, $P_M-P_N$ is the projection onto $M\ominus N:= M\cap N^\perp$.
	\item[(iv)] Let $P_n$ be a sequence of mutually orthogonal projections onto closed subspaces $M_n$, i.e. $P_nP_m=0$ for all $n\neq m$. Then $\sum_{n=1}^\infty P_n\overset{SOT}{\to} P\in\mathcal{P}(H)$, where $P$ is the projection onto $M=\overline{span}\left\{M_n\right\}_{n=1}^\infty$.
\end{itemize}
\begin{proof}
(i) The first statement is clear, since $P_MP_N=P_NP_M$ if and only if $P_MP_N$ is self-adjoint and idempotent. For the next statement, if $M\perp N$, then $P_N x\in N\subset M^\perp$ for all $x\in H$, which implies $P_MP_N=0$. Conversely, if $P_MP_N=0$, then $\langle x,y\rangle= \langle P_M x,P_N y\rangle = \langle x, P_MP_N y\rangle = 0$ for all $x\in M$ and all $y\in N$.

(ii) The sufficiency is clear. For the necessity, if $P_M+P_N\in\mathcal{P}(H)$, then
\begin{align*}
	P_M+P_N=(P_M+P_N)^2 &= P_M + P_N + P_MP_N + P_NP_M\ \Rightarrow\ P_MP_N+P_NP_M=0\\
	&\Rightarrow P_MP_N + P_MP_NP_M = 0 = P_MP_NP_M+P_NP_M\\
	&\Rightarrow P_MP_N=P_NP_M=0\ \Rightarrow M\perp N.
\end{align*} 

(iii) If $N\subset M$, then $P_MP_N=P_NP_M = P_N$, and
\begin{align*}
	(P_M-P_N)^2 = P_M + P_N - P_MP_N - P_NP_M = P_M-P_N.
\end{align*}

Conversely, if $P_M-P_N\in\mathcal{P}(H)$, let $L=\ker(I-P_M+P_N)$. Then $P_M-P_N=P_L$, and (ii) implies $L\perp N$. Hence for all $x\in N$, $0=P_L x= P_Mx-P_N x = P_M x - x$, which implies $x\in M$.

(iv) For all $x\in H$, note that
\begin{align*}
	\sum_{k=1}^n\Vert P_k x\Vert^2 = \left\Vert\sum_{k=1}^n P_k x\right\Vert^2 \leq\Vert x\Vert^2.
\end{align*}
Then $\bigl(\sum_{k=1}^n P_k x\bigr)_{n=1}^\infty$ is a Cauchy sequence. Define operator $T$ as the strong operator limit:
\begin{align*}
	 Px=\lim_{n\to\infty}\sum_{k=1}^n P_n x,\ \forall x\in H.
\end{align*}
One can easily verify that $P^2=P$. Furthermore, for all $x,y\in H$,
\begin{align*}
	\langle Px,y\rangle = \lim_{n\to\infty}\sum_{k=1}^n \langle P_k x,y\rangle = \lim_{n\to\infty}\sum_{k=1}^n \langle x,P_k y\rangle = \langle x,Py\rangle.
\end{align*}
Hence $P$ is self-adjoint, and $P$ is a projection operator. 

It remains to show $P=P_M$. If $x\in M^\perp$, then $P_nx=0$ for all $n\in\mathbb{N}$, which implies $Px=0$. If $x\in M_n$, then $Px=P_n x=x$, and $x\in M$. As a result, $\ker(I-P)$ contains each $x\in M$, hence contains $M$. Therefore $P$ is the projection onto $M$.
\end{proof}

\paragraph{Definition 4.44\label{def:4.44}} (Spectral measures). Let $\mathscr{B}(\mathbb{C})$ be the set of all Borel sets in $\mathbb{C}$. A \textit{spectral measure} is a function $E:\mathscr{B}(\mathbb{C})\to\mathcal{P}(H)$ satisfying the following conditions: 
\begin{itemize}
	\item[(i)] $E(\mathbb{C})=I$, where $I$ is the identity map on $H$; \item[(ii)] If $\{B_n\}_{n\in\mathbb{N}}$ is a collection of disjoint Borel sets in $\mathbb{C}$, then
	\begin{align*}
		E\left(\bigcup_{n=1}^\infty B_n\right) = \sum_{n=1}^\infty E(B_n)\quad\text{(convergence in SOT)}.
	\end{align*}
\end{itemize}
\paragraph{Remark.} We can apply standard techniques in complex-valued measures to derive many basic facts about spectral measures.
\begin{itemize}
\item[(i)] $E(\emptyset)=0$;
\item[(ii)] Following \hyperref[prop:4.43]{Proposition 4.43 (ii)}, if  $B_0$ and $B_1$ are disjoint Borel sets in $\mathbb{C}$, then $E(B_0)\perp E(B_1)$.
\item[(iii)] Following \hyperref[prop:4.43]{Proposition 4.43 (iii)}, if $B_0\subset B_1$, then $\Vert E(B_0)x\Vert\leq\Vert E(B_1)x\Vert$ for all $x\in H$.
\item[(iv)] Let $B_0$ and $B_1$ be Borel sets in $\mathbb{C}$. Then
\begin{align*}
	E(B_0)+E(B_1)=E(B_0\cup B_1) + E(B_0\cap B_1).
\end{align*}
Furthermore, observing that $E(B_0)E(B_0\cap B_1)=E(B_0\cap B_1)$ and $E(B_0)E(B_0\cup B_1)=E(B_0)$, we have $E(B_0)E(B_1)=E(B_0\cap B_1)$.
\end{itemize} 

\paragraph{Proposition 4.45.\label{prop:4.45}} Let $E:\mathcal{B}(\mathbb{C})\to\mathcal{P}(H)$ be a projection-valued function such that for all $x,y\in H$,
\begin{align*}
	\left\langle E\left(\bigcup_{n=1}^\infty B_n\right)x,y\right\rangle = \sum_{n=1}^\infty \langle E(B_n)x,y\rangle,\ \forall\ \text{sequence}\ \{B_n\}_{n=1}^\infty\ \text{of disjoint Borel sets in}\ \mathbb{C}
\end{align*}
and that $E(\mathbb{C})=1$. Then $E$ is a spectral measure.
\begin{proof}
We need to verify the second property in \hyperref[def:4.44]{Definition 4.44}. Let $\{B_n\}_{n=1}^\infty$ be a sequence of disjoint Borel sets in $\mathbb{C}$. By assumption,
\begin{align*}
	\left\langle \sum_{k=1}^n E(B_k)x,y\right\rangle = \sum_{k=1}^n\left\langle E(B_k)x,y\right\rangle = \left\langle E\left(\bigcup_{k=1}^n B_k\right)x,y\right\rangle,\ \forall x,y\in H.
\end{align*}
Then
\begin{align*}
\sum_{k=1}^n E(B_k)x = E\left(\bigcup_{k=1}^n B_k\right)x,\ \forall x\in H.\tag{4.9}\label{eq:4.9}
\end{align*}
Observing that
\begin{align*}
	\sum_{n=1}^\infty\Vert E(B_n)x\Vert^2 = \sum_{n=1}^\infty\langle E(B_n)x,x\rangle = \left\langle E\left(\bigcup_{n=1}^\infty B_n\right)x,x\right\rangle = \left\Vert E\left(\bigcup_{n=1}^\infty B_n\right)x\right\Vert^2,
\end{align*}
the sequence $x_n=E(B_n)x$ is summable. Let $n\to\infty$ in (4.9), we have $E\left(\bigcup_{n=1}^\infty B_n\right) \overset{SOT}{=} \sum_{n=1}^\infty E(B_n)$.
\end{proof}

\subsubsection{Spectral Integrals and their Associated Operators}
Let $H$ be a Hilbert space, and let $E$ be a spectral measure on $H$. Given two vectors $x,y\in H$, define
\begin{align*}
	E^*(B) = \langle E(B)x,y\rangle,\ \forall B\in\mathscr{B}(\mathbb{C}).
\end{align*}
By definition, $E^*$ is a complex-valued Borel measure on $\mathbb{C}$. Hence for all Borel-measurable function $f$ on $\mathbb{C}$, we can compute its Lebesgue-Stieltjes integral with respect to $E^*$. For brevity, we denote $E(\lambda)$ by $E_\lambda$.

\paragraph{Definition 4.46\label{def:4.46}} (Spectral integral). Let $E$ be a spectral measure on a Hilbert space $H$. We define the \textit{spectral integral} of the measurable function $f$ with respect to $x,y\in H$ to be the Riemann-Stieltjes integral
\begin{align*}
	\int f(\lambda)\,d\langle E_\lambda x,t\rangle,
\end{align*}
which we sometimes abbreviate $\int f(\lambda)\,dE$.

\paragraph{Definition 4.47\label{def:4.47}} (The spectrum of a spectral measure). Let $E$ be a spectral measure on a Hilbert space $H$. The \textit{spectrum} of $E$ is defined to be the set
\begin{align*}
	\sigma(E)=\mathbb{C}\backslash\left(\bigcup_{\alpha\in J} U_\alpha\right),
\end{align*}
where the union is taken over all open sets $U_\alpha$ such that $E(U_\alpha)=0$. We say $E$ is \textit{compact} if $\sigma(E)$ is compact.

\paragraph{Theorem 4.48.\label{thm:4.48}} Let $E$ be a compact spectral measure on a Hilbert space $H$. There is a unique normal operator $T$ such that $\int\lambda\,d\langle E_\lambda x,y\rangle=\langle Tx,y\rangle$ for all $x,y\in H$. For the sake of brevity, we write $T=\int\lambda\,dE$.
\begin{proof}
Since $\sigma(E)$ is compact, let $M=\max_{\lambda\in\sigma(E)}\vert\lambda\vert$. Define $\varphi(x,y)=\int\lambda\,d\langle E_\lambda x,y\rangle$. Clearly, $\varphi:H\times H\to\mathbb{C}$ is a sesquilinear form. Furthermore,
\begin{align*}
	\vert\varphi(x,x)\vert=\left\vert\int\lambda\,d\langle E_\lambda x,x\rangle\right\vert \leq M \int\left\vert d\langle E_\lambda x,x\rangle\right\vert = M \int d\left\Vert E_\lambda x \right\Vert^2\leq M\left\Vert x\right\Vert^2.
\end{align*} 
Use the parallelogram law,
\begin{align*}
	\vert\varphi(x,y)\vert\leq\frac{1}{4}M\left(\Vert x+y\Vert^2 + \Vert x+\i y\Vert^2 + \Vert x-y\Vert^2 + \Vert x-\i y\Vert^2\right) = M\left(\Vert x\Vert^2 + \Vert y\Vert^2\right).
\end{align*}
Set $\Vert x\Vert=\Vert y\Vert =1$, we have $\Vert\varphi\Vert \leq 2M$. By \hyperref[thm:2.15]{Theorem 2.15}, there exists a unique operator $T\in\mathfrak{B}(H)$ such that $\varphi(x,y)=\langle Tx,y\rangle$ for all $x,y\in H$.\vspace{0.1cm}

We now show that $T$ is a normal operator. Define $S=\int\overline{\lambda}\,dE$. Then
\begin{align*}
	\langle x,Sy\rangle = \overline{\langle Sy,x\rangle} = \overline{\int\overline{\lambda}\,d\langle E_\lambda y,x\rangle} = \int\lambda\, d\langle x,E_\lambda y\rangle = \int\lambda\, d\langle E_\lambda x, y\rangle = \langle Tx,y\rangle.
\end{align*}
Hence $S$ is the adjoint of $T$. Furthermore, for all $B\in\mathscr{B}(\mathbb{C})$,
\begin{align*}
	\langle E(B) x,Ty\rangle &= \overline{\langle Ty,E(B)x\rangle} = \overline{\int \lambda\, d\langle E_\lambda y,E(B)x\rangle} = \overline{\int \lambda\, d\langle E(B)E_\lambda y,x\rangle}\\
	&= \overline{\int \lambda\, d\langle E(B\cap\lambda) y,x\rangle}
	= \overline{\int_B \lambda\, d\langle E_\lambda y,x\rangle} = \int_B \overline{\lambda}\, d\langle x, E_\lambda y\rangle = \int_B \overline{\lambda}\, d\langle E_\lambda x,y\rangle. \tag{4.10}\label{eq:4.10}
\end{align*}
Given $x,y\in H$, by \hyperref[eq:4.10]{(4.10)}, we have
\begin{align*}
	\langle STx,y\rangle = \langle Tx,Ty\rangle = \int\lambda\,d\langle E_\lambda x,Ty\rangle = \int\lambda\cdot\overline{\lambda}\,d\langle E_\lambda x,y\rangle = \int\vert\lambda\vert^2\,dE.
\end{align*}
Similarly we have $\langle TSx,y\rangle=\int\vert\lambda\vert^2\,dE$. Since $x$ and $y$ are arbitrary, $T$ is a normal operator.
\end{proof}

\paragraph{Theorem 4.49.\label{thm:4.49}} If $E$ is a compact spectral measure on a Hilbert space $H$, and $T=\int\lambda\,dE$, then $\sigma(E)=\sigma(A)$.
\begin{proof}
Assume $\lambda_0\in\mathbb{C}\backslash\sigma(E)$. By definition, $\mathbb{C}\backslash\sigma(E)$ is open, so there exists $\epsilon>0$ such that $B(\lambda_0,\epsilon)\subset\mathbb{C}\backslash\sigma(E)$. Then $E(B(\lambda_0,\epsilon))=0$, and $T-\lambda_0 I=\int(\lambda-\lambda_0)\,dE$, and 
\begin{align*}
	\Vert Tx-\lambda_0 x\Vert^2 = \int\vert\lambda-\lambda_0\vert^2\,d\langle E_\lambda x,x\rangle = \int_{\mathbb{C}\backslash B(\lambda_0,\epsilon)}\vert\lambda-\lambda_0\vert^2\,d\langle E_\lambda x,x\rangle\geq \epsilon^2\left\Vert x\right\Vert^2.
\end{align*}
Hence $T-\lambda_0 I$ is bounded from below. Following \hyperref[thm:3.15]{Theorem 3.15}, if we $T_0=T-\lambda_0 I$ has dense range in $H$, then $\lambda_0\in\rho(T)$. Equivalently, we prove $\mathfrak{R}(T-\lambda_0 I)^\perp=0$: If $x\in\mathfrak{R}(T-\lambda_0 I)^\perp$, then $\langle T_0^* x,y\rangle = \langle x,T_0y\rangle = 0$ for all $y\in H$, which implies $T_0^*x=0$. Meanwhile, $T_0$ is normal by \hyperref[thm:4.48]{Theorem 4.48}, hence $\ker(T_0^*)=\ker(T_0)=0$. Therefore $x=0$.\vspace{0.1cm}

Conversely, assume $\lambda_1\in\sigma(E)$. Given $\eta>0$, we have $E(B(\lambda_1,\eta))\neq 0$. Since $E(B(\lambda_1,\eta))$ must maintain some unit vector $u\in H$, we have
\begin{align*}
	\Vert Tu-\lambda_1 u\Vert^2 = \int_{B(\lambda_1,\eta)}\vert\lambda-\lambda_1\vert^2\,d\langle E_\lambda u,u\rangle \leq \eta^2\left\Vert u\right\Vert^2.
\end{align*}
Because $\eta>0$ is arbitrary, $T-\lambda_1 I$ is not bounded below, hence is not invertible.
\end{proof}

\end{document}